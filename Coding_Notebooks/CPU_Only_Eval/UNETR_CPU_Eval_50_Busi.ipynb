{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\n",
        "# Cell 1/9 — Run identifiers, paths, and folders\n",
        "# ------------------------------------------------------------\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- run knobs (same style as yours) ----\n",
        "DATASET    = \"busi\"\n",
        "IMAGE_SIZE = 256\n",
        "SEED       = 42\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS     = 10\n",
        "AMP_ON     = True\n",
        "MODEL_TAG  = \"unetr_model\"\n",
        "RUN_NAME   = f\"{MODEL_TAG}_{DATASET}_IMG{IMAGE_SIZE}_SEED{SEED}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
        "CONFIG_PATH = \"configs/example.yaml\"\n",
        "\n",
        "# ---- standard folders ----\n",
        "root = Path(\"/content/drive/MyDrive/unetr_model_busi_Test\")\n",
        "for p in [\"logs\", \"checkpoints\", \"figures\", \"runs\", \"summary\"]:\n",
        "    (root / p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "summary_txt_path  = root / \"summary\" / f\"{RUN_NAME}_env.txt\"\n",
        "summary_json_path = root / \"summary\" / f\"{RUN_NAME}_env.json\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihJQ62HiGoV9",
        "outputId": "596e672c-e2fc-46dd-fd31-644798cc7e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 2/9 — Base imports & safe-import helper\n",
        "# ------------------------------------------------------------\n",
        "import os, sys, json, time, platform, importlib, random\n",
        "\n",
        "def try_import(name: str):\n",
        "    try:\n",
        "        mod = importlib.import_module(name)\n",
        "        ver = getattr(mod, \"__version__\", \"unknown\")\n",
        "        if name == \"PIL\": ver = getattr(mod, \"__version__\", ver)\n",
        "        if name == \"cv2\": ver = getattr(mod, \"__version__\", ver)\n",
        "        return mod, ver\n",
        "    except Exception as e:\n",
        "        return None, f\"NOT INSTALLED ({type(e).__name__})\"\n",
        "\n",
        "!pip -q install -U monai torchmetrics thop fvcore timm albumentations==1.4.4 psutil pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu1sollbGoeE",
        "outputId": "6737f930-3bcc-4687-c78a-c958c9b5fab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.4/150.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 3/9 — Import common stack (DL, data, viz, utils)\n",
        "# ------------------------------------------------------------\n",
        "# Core / data\n",
        "numpy, np_ver         = try_import(\"numpy\")\n",
        "pandas, pd_ver        = try_import(\"pandas\")\n",
        "\n",
        "# Deep Learning\n",
        "torch, torch_ver      = try_import(\"torch\")\n",
        "torchvision, tv_ver   = try_import(\"torchvision\")\n",
        "timm, timm_ver        = try_import(\"timm\")\n",
        "monai, monai_ver      = try_import(\"monai\")\n",
        "torchmetrics, tm_ver  = try_import(\"torchmetrics\")\n",
        "\n",
        "# Aug / IO / Viz\n",
        "albumentations, alb_ver = try_import(\"albumentations\")\n",
        "cv2, cv2_ver            = try_import(\"cv2\")\n",
        "PIL, pil_ver            = try_import(\"PIL\")\n",
        "matplotlib, mpl_ver     = try_import(\"matplotlib\")\n",
        "\n",
        "# Utils\n",
        "yaml, yaml_ver       = try_import(\"yaml\")\n",
        "sklearn, sk_ver      = try_import(\"sklearn\")\n",
        "psutil, psutil_ver   = try_import(\"psutil\")\n",
        "\n",
        "# Profiling\n",
        "thop, thop_ver       = try_import(\"thop\")\n",
        "fvcore, fvcore_ver   = try_import(\"fvcore\")\n"
      ],
      "metadata": {
        "id": "f5VnECLKGohb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 4/9 — Device, CUDA/cuDNN, and GPU VRAM discovery\n",
        "# ------------------------------------------------------------\n",
        "device         = \"cpu\"\n",
        "gpu_name       = \"N/A\"\n",
        "total_vram_mb  = \"N/A\"\n",
        "total_vram_gb  = \"N/A\"\n",
        "cuda_version   = \"N/A\"\n",
        "cudnn_version  = \"N/A\"\n",
        "\n",
        "if torch is not None:\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    device = \"cuda\" if cuda_available else \"cpu\"\n",
        "    cuda_version = getattr(torch.version, \"cuda\", \"N/A\")\n",
        "    try:\n",
        "        cudnn_version = str(torch.backends.cudnn.version()) if torch.backends.cudnn.is_available() else \"N/A\"\n",
        "    except Exception:\n",
        "        cudnn_version = \"N/A\"\n",
        "    if cuda_available:\n",
        "        try:\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            props = torch.cuda.get_device_properties(0)\n",
        "            total_vram_bytes = getattr(props, \"total_memory\", 0)\n",
        "            total_vram_mb = round(total_vram_bytes / (1024**2), 2)\n",
        "            total_vram_gb = round(total_vram_bytes / (1024**3), 2)\n",
        "        except Exception:\n",
        "            gpu_name = \"Unknown (query failed)\"\n",
        "            total_vram_mb = \"Unknown\"\n",
        "            total_vram_gb = \"Unknown\"\n"
      ],
      "metadata": {
        "id": "QVMvrGY_Gok0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 5/9 — Reproducibility (seeds + deterministic flags)\n",
        "# ------------------------------------------------------------\n",
        "random.seed(SEED)\n",
        "if numpy:\n",
        "    numpy.random.seed(SEED)\n",
        "\n",
        "if torch is not None:\n",
        "    torch.manual_seed(SEED)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(SEED)\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    except Exception:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "wqa1EkgIGooP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 6/9 — Assemble environment snapshot dict\n",
        "# ------------------------------------------------------------\n",
        "env_info = {\n",
        "    \"run\": {\n",
        "        \"run_name\": RUN_NAME,\n",
        "        \"datetime\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"dataset\": DATASET,\n",
        "        \"image_size\": IMAGE_SIZE,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"amp_on\": AMP_ON,\n",
        "        \"seed\": SEED,\n",
        "        \"config_path\": CONFIG_PATH if Path(CONFIG_PATH).exists() else f\"{CONFIG_PATH} (not found)\",\n",
        "    },\n",
        "    \"system\": {\n",
        "        \"python\": sys.version.split()[0],\n",
        "        \"platform\": platform.platform(),\n",
        "        \"device\": device,\n",
        "        \"gpu_name\": gpu_name,\n",
        "        \"gpu_total_vram_mb\": total_vram_mb,\n",
        "        \"gpu_total_vram_gb\": total_vram_gb,\n",
        "        \"cuda_version\": cuda_version,\n",
        "        \"cudnn_version\": cudnn_version,\n",
        "    },\n",
        "    \"libraries\": {\n",
        "        \"torch\": torch_ver,\n",
        "        \"torchvision\": tv_ver,\n",
        "        \"timm\": timm_ver,\n",
        "        \"monai\": monai_ver,\n",
        "        \"torchmetrics\": tm_ver,\n",
        "        \"numpy\": np_ver,\n",
        "        \"pandas\": pd_ver,\n",
        "        \"albumentations\": alb_ver,\n",
        "        \"opencv-python (cv2)\": cv2_ver,\n",
        "        \"Pillow (PIL)\": pil_ver,\n",
        "        \"matplotlib\": mpl_ver,\n",
        "        \"pyyaml\": yaml_ver,\n",
        "        \"scikit-learn\": sk_ver,\n",
        "        \"psutil\": psutil_ver,\n",
        "        \"thop\": thop_ver,\n",
        "        \"fvcore\": fvcore_ver,\n",
        "    },\n",
        "}\n"
      ],
      "metadata": {
        "id": "MGEigRc2Gorp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 7/9 — Pretty print snapshot to console\n",
        "# ------------------------------------------------------------\n",
        "border = \"=\" * 70\n",
        "print(border)\n",
        "print(\"STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\")\n",
        "print(border)\n",
        "print(f\"Run Name      : {env_info['run']['run_name']}\")\n",
        "print(f\"Date/Time     : {env_info['run']['datetime']}\")\n",
        "print(f\"Dataset       : {env_info['run']['dataset']}\")\n",
        "print(f\"Image Size    : {env_info['run']['image_size']}\")\n",
        "print(f\"Batch Size    : {env_info['run']['batch_size']}\")\n",
        "print(f\"Epochs        : {env_info['run']['epochs']}\")\n",
        "print(f\"AMP (mixed precision): {env_info['run']['amp_on']}\")\n",
        "print(f\"Seed          : {env_info['run']['seed']}\")\n",
        "print(f\"Config Path   : {env_info['run']['config_path']}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Python        : {env_info['system']['python']}\")\n",
        "print(f\"Platform      : {env_info['system']['platform']}\")\n",
        "print(f\"Device        : {env_info['system']['device']}\")\n",
        "print(f\"GPU           : {env_info['system']['gpu_name']}\")\n",
        "print(f\"GPU VRAM      : {env_info['system']['gpu_total_vram_mb']} MB ({env_info['system']['gpu_total_vram_gb']} GB)\")\n",
        "print(f\"CUDA / cuDNN  : {env_info['system']['cuda_version']} / {env_info['system']['cudnn_version']}\")\n",
        "print(\"-\" * 70)\n",
        "print(\"Libraries:\")\n",
        "for lib, ver in env_info[\"libraries\"].items():\n",
        "    print(f\"  - {lib:<24} {ver}\")\n",
        "print(border)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RCdGFiAGou1",
        "outputId": "2d1e080b-ea9f-4a88-c98e-1aa77b729575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\n",
            "======================================================================\n",
            "Run Name      : unetr_model_busi_IMG256_SEED42_2025-11-04_16-43-23\n",
            "Date/Time     : 2025-11-04T16:44:36\n",
            "Dataset       : busi\n",
            "Image Size    : 256\n",
            "Batch Size    : 8\n",
            "Epochs        : 10\n",
            "AMP (mixed precision): True\n",
            "Seed          : 42\n",
            "Config Path   : configs/example.yaml (not found)\n",
            "----------------------------------------------------------------------\n",
            "Python        : 3.12.12\n",
            "Platform      : Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "Device        : cpu\n",
            "GPU           : N/A\n",
            "GPU VRAM      : N/A MB (N/A GB)\n",
            "CUDA / cuDNN  : 12.6 / 91002\n",
            "----------------------------------------------------------------------\n",
            "Libraries:\n",
            "  - torch                    2.8.0+cu126\n",
            "  - torchvision              0.23.0+cu126\n",
            "  - timm                     1.0.21\n",
            "  - monai                    1.5.1\n",
            "  - torchmetrics             1.8.2\n",
            "  - numpy                    2.0.2\n",
            "  - pandas                   2.3.3\n",
            "  - albumentations           1.4.4\n",
            "  - opencv-python (cv2)      4.12.0\n",
            "  - Pillow (PIL)             11.3.0\n",
            "  - matplotlib               3.10.0\n",
            "  - pyyaml                   6.0.3\n",
            "  - scikit-learn             1.6.1\n",
            "  - psutil                   5.9.5\n",
            "  - thop                     0.1.1\n",
            "  - fvcore                   0.1.5.post20221221\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 8/9 — Save TXT + JSON environment snapshots\n",
        "# ------------------------------------------------------------\n",
        "with open(summary_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(border + \"\\n\")\n",
        "    f.write(\"STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\\n\")\n",
        "    f.write(border + \"\\n\")\n",
        "    for section, payload in env_info.items():\n",
        "        f.write(f\"[{section.UPPER()}]\\n\" if hasattr(section, 'UPPER') else f\"[{section.upper()}]\\n\")\n",
        "        if isinstance(payload, dict):\n",
        "            for k, v in payload.items():\n",
        "                if isinstance(v, dict):\n",
        "                    f.write(f\"  {k}:\\n\")\n",
        "                    for kk, vv in v.items():\n",
        "                        f.write(f\"    - {kk}: {vv}\\n\")\n",
        "                else:\n",
        "                    f.write(f\"  - {k}: {v}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "with open(summary_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(env_info, f, indent=2)\n",
        "\n",
        "print(f\"Saved environment snapshots to:\\n  • {summary_txt_path}\\n  • {summary_json_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeaNK1igGoyH",
        "outputId": "6d6888e1-767e-4cff-e9d5-2f48a13c4d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved environment snapshots to:\n",
            "  • /content/drive/MyDrive/unetr_model_busi_Test/summary/unetr_model_busi_IMG256_SEED42_2025-11-04_16-43-23_env.txt\n",
            "  • /content/drive/MyDrive/unetr_model_busi_Test/summary/unetr_model_busi_IMG256_SEED42_2025-11-04_16-43-23_env.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 9/9 — Initialize per-run CSV log header\n",
        "# ------------------------------------------------------------\n",
        "csv_path = root / \"logs\" / f\"{RUN_NAME}.csv\"\n",
        "if not csv_path.exists():\n",
        "    with open(csv_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"epoch,lr,train_loss,val_loss,train_dice,val_dice,train_iou,val_iou,epoch_time\\n\")\n",
        "print(f\"Initialized log CSV (if new): {csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4pE758CGo1K",
        "outputId": "275bdcdf-0880-459c-f3c5-dcca6d11e68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized log CSV (if new): /content/drive/MyDrive/unetr_model_busi_Test/logs/unetr_model_busi_IMG256_SEED42_2025-11-04_16-43-23.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD (BUSI, 256px) → MedSegBench cache\n",
        "# Cell 1/6 — Setup: cache dir, env var, and size\n",
        "# ------------------------------------------------------------\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "SIZE = 256\n",
        "cache_root = Path(\"/content/data/MedSegBenchCache\")\n",
        "cache_root.mkdir(parents=True, exist_ok=True)\n",
        "os.environ[\"MEDSEGBENCH_DIR\"] = str(cache_root)\n",
        "\n",
        "print(f\"[INFO] MEDSEGBENCH_DIR = {cache_root.resolve()}\")\n",
        "print(f\"[INFO] Target resolution = {SIZE}px\")\n",
        "\n",
        "!pip -q install medsegbench\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBl3jA_rMHZx",
        "outputId": "1d53bbb8-715a-4b57-9aff-477a6596f2eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] MEDSEGBENCH_DIR = /content/data/MedSegBenchCache\n",
            "[INFO] Target resolution = 256px\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 2/6 — Dataset source details (Zenodo v1 record)\n",
        "# ------------------------------------------------------------\n",
        "target_name = f\"busi_{SIZE}.npz\"\n",
        "target_path = cache_root / target_name\n",
        "\n",
        "url = f\"https://zenodo.org/records/13358372/files/{target_name}?download=1\"\n",
        "\n",
        "# ✅ Put your BUSI_256 MD5 here (you mentioned you have it)\n",
        "expected_md5 = \"198aea70968b71adf593b32c41a6e995\"\n",
        "\n",
        "print(f\"[INFO] Target file  : {target_name}\")\n",
        "print(f\"[INFO] Download URL : {url}\")\n",
        "print(f\"[INFO] Expected MD5 : {expected_md5}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6EcLSkJMHWk",
        "outputId": "5927735d-8c5a-4691-b458-90d45da434b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Target file  : busi_256.npz\n",
            "[INFO] Download URL : https://zenodo.org/records/13358372/files/busi_256.npz?download=1\n",
            "[INFO] Expected MD5 : 198aea70968b71adf593b32c41a6e995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 3/6 — Helpers (md5sum + download runners)\n",
        "# ------------------------------------------------------------\n",
        "import hashlib, subprocess, shutil\n",
        "\n",
        "def md5sum(path: Path) -> str:\n",
        "    h = hashlib.md5()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def download_file(url: str, out_path: Path) -> None:\n",
        "    curl = shutil.which(\"curl\")\n",
        "    if curl:\n",
        "        print(\"[INFO] Downloading with curl ...\")\n",
        "        subprocess.run([curl, \"-L\", \"-f\", url, \"-o\", str(out_path)], check=True)\n",
        "        return\n",
        "    wget = shutil.which(\"wget\")\n",
        "    if wget:\n",
        "        print(\"[INFO] curl not found; downloading with wget ...\")\n",
        "        subprocess.run([wget, \"-O\", str(out_path), url], check=True)\n",
        "        return\n",
        "    raise RuntimeError(\"Neither curl nor wget is available on PATH.\")\n"
      ],
      "metadata": {
        "id": "A8jRgZpiMHTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 4/6 — Download (idempotent)\n",
        "# ------------------------------------------------------------\n",
        "if not target_path.exists():\n",
        "    print(f\"[INFO] Downloading to {target_path} ...\")\n",
        "    try:\n",
        "        download_file(url, target_path)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        raise RuntimeError(f\"Downloader failed with return code {e.returncode}.\") from e\n",
        "else:\n",
        "    print(f\"[INFO] File already present: {target_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LhTqJv9MHQZ",
        "outputId": "cffc7adb-a05d-4497-a09c-348a090695c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Downloading to /content/data/MedSegBenchCache/busi_256.npz ...\n",
            "[INFO] Downloading with curl ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 5/6 — Integrity check (MD5)\n",
        "# ------------------------------------------------------------\n",
        "got = md5sum(target_path)\n",
        "print(f\"[INFO] MD5 (computed): {got}\")\n",
        "if expected_md5 and got != expected_md5:\n",
        "    raise RuntimeError(\n",
        "        f\"MD5 mismatch for {target_name}. Expected {expected_md5}, got {got}.\\n\"\n",
        "        \"Delete the file and rerun this step to redownload.\"\n",
        "    )\n",
        "print(f\"✅ Download + MD5 OK → {target_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gJTKINBMHNS",
        "outputId": "113ae084-b7ca-4d25-af9b-4a74403f4496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] MD5 (computed): 198aea70968b71adf593b32c41a6e995\n",
            "✅ Download + MD5 OK → /content/data/MedSegBenchCache/busi_256.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 6/6 — Ready message\n",
        "# ------------------------------------------------------------\n",
        "print(\"[READY] busi (256px) cached in MEDSEGBENCH_DIR.\")\n",
        "print(\"[NEXT] STEP 2: Reproducibility & Config Lock; STEP 3: load predefined splits and print counts.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSfXw79FMVUz",
        "outputId": "97ffde21-9571-416f-e292-8a974816a84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[READY] busi (256px) cached in MEDSEGBENCH_DIR.\n",
            "[NEXT] STEP 2: Reproducibility & Config Lock; STEP 3: load predefined splits and print counts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 1/5 — Resolve run knobs, paths, and dataset file\n",
        "# ------------------------------------------------------------\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "try: root\n",
        "except NameError: root = Path(\".\")\n",
        "\n",
        "DATASET    = globals().get(\"DATASET\", \"busi\")\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", 256))\n",
        "SEED       = int(globals().get(\"SEED\", 42))\n",
        "BATCH_SIZE = int(globals().get(\"BATCH_SIZE\", 8))\n",
        "EPOCHS     = int(globals().get(\"EPOCHS\", 10))\n",
        "AMP_ON     = bool(globals().get(\"AMP_ON\", True))\n",
        "MODEL_TAG  = globals().get(\"MODEL_TAG\", \"TransUNetLiteTiny_model\")\n",
        "RUN_NAME   = globals().get(\"RUN_NAME\", f\"{MODEL_TAG}_{DATASET}_IMG{IMAGE_SIZE}_SEED{SEED}\")\n",
        "CONFIG_PATH = globals().get(\"CONFIG_PATH\", \"configs/example.yaml\")\n",
        "\n",
        "RESOLUTION = int(globals().get(\"SIZE\", IMAGE_SIZE))\n",
        "\n",
        "msb_dir = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "busi_file = msb_dir / f\"busi_{RESOLUTION}.npz\"\n",
        "\n",
        "print(f\"[INFO] Artifacts root        : {root.resolve()}\")\n",
        "print(f\"[INFO] MEDSEGBENCH_DIR       : {msb_dir.resolve()}\")\n",
        "print(f\"[INFO] Expected busi file    : {busi_file}\")\n",
        "print(f\"[INFO] Run                   : {RUN_NAME}\")\n",
        "print(f\"[INFO] Model tag             : {MODEL_TAG}\")\n",
        "print(f\"[INFO] Seed / ImageSize      : {SEED} / {IMAGE_SIZE}\")\n",
        "print(f\"[INFO] Batch / Epochs / AMP  : {BATCH_SIZE} / {EPOCHS} / {AMP_ON}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyrNxgwAMVRp",
        "outputId": "30933346-bd9e-423a-94a4-5d96072ff349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Artifacts root        : /content/drive/MyDrive/unetr_model_busi_Test\n",
            "[INFO] MEDSEGBENCH_DIR       : /content/data/MedSegBenchCache\n",
            "[INFO] Expected busi file    : /content/data/MedSegBenchCache/busi_256.npz\n",
            "[INFO] Run                   : unetr_model_busi_IMG256_SEED42_2025-11-04_16-43-23\n",
            "[INFO] Model tag             : unetr_model\n",
            "[INFO] Seed / ImageSize      : 42 / 256\n",
            "[INFO] Batch / Epochs / AMP  : 8 / 10 / True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 2/5 — Seed + deterministic flags (re-assert)\n",
        "# ------------------------------------------------------------\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "    try: torch.use_deterministic_algorithms(True)\n",
        "    except Exception: pass\n",
        "    try:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    except Exception: pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "print(f\"[OK] Seeds set and deterministic flags applied (seed={SEED}).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH7NZHhtMVOy",
        "outputId": "99175edb-97cf-4b25-b55f-8b4e326ac190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Seeds set and deterministic flags applied (seed=42).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 3/5 — Build default config (if missing) and load it\n",
        "# ------------------------------------------------------------\n",
        "import yaml\n",
        "(root / \"configs\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "cfg_path = Path(CONFIG_PATH)\n",
        "if not cfg_path.exists():\n",
        "    cfg_path = root / \"configs\" / \"default_busi.yaml\"\n",
        "\n",
        "default_cfg = {\n",
        "    \"run\": {\"run_name\": RUN_NAME, \"seed\": SEED, \"amp_on\": AMP_ON},\n",
        "    \"data\": {\"dataset\": DATASET, \"resolution\": RESOLUTION, \"medsegbench_dir\": str(msb_dir), \"predefined_splits\": True},\n",
        "    \"train\": {\n",
        "        \"image_size\": IMAGE_SIZE, \"batch_size\": BATCH_SIZE, \"epochs\": EPOCHS, \"num_workers\": 4,\n",
        "        \"optimizer\": {\"name\": \"adamw\", \"lr\": 3e-4, \"weight_decay\": 1e-4},\n",
        "        \"scheduler\": {\"name\": \"cosine\", \"warmup_epochs\": 5},\n",
        "        \"early_stopping\": {\"monitor\": \"val_dice\", \"patience\": 20},\n",
        "        \"mixed_precision\": AMP_ON\n",
        "    },\n",
        "    \"augment\": {\n",
        "        \"geometric\": {\"flip\": True, \"rotate\": True, \"scale\": True, \"elastic\": False},\n",
        "        \"appearance\": {\"brightness_contrast\": True, \"blur_noise\": True},\n",
        "        \"probabilities\": {\"flip\": 0.5, \"rotate\": 0.3, \"scale\": 0.3, \"brightness_contrast\": 0.3, \"blur_noise\": 0.2}\n",
        "    },\n",
        "    \"loss\": {\"primary\": \"dice_bce\", \"weights\": {\"dice\": 0.7, \"bce\": 0.3}},\n",
        "    \"metrics\": {\"threshold\": 0.5, \"report\": [\"dice\", \"iou\"]},\n",
        "    \"logging\": {\n",
        "        \"artifacts_root\": str(root.resolve()),\n",
        "        \"print_per_epoch_fields\": [\"epoch\",\"lr\",\"train_loss\",\"val_loss\",\"train_dice\",\"val_dice\",\"train_iou\",\"val_iou\",\"epoch_time\"],\n",
        "        \"save_csv_per_epoch\": True,\n",
        "        \"save_best_by\": \"val_dice\"\n",
        "    },\n",
        "    \"model\": {\"name\": MODEL_TAG, \"scale\": \"auto\", \"params\": {}}\n",
        "}\n",
        "\n",
        "if not Path(CONFIG_PATH).exists():\n",
        "    with open(cfg_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        yaml.safe_dump(default_cfg, f, sort_keys=False)\n",
        "    print(f\"[INFO] Created default config at: {cfg_path.resolve()}\")\n",
        "else:\n",
        "    cfg_path = Path(CONFIG_PATH)\n",
        "\n",
        "with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "print(f\"[OK] Loaded config from: {cfg_path.resolve()}\")\n",
        "print(f\"[INFO] Config run_name: {cfg['run'].get('run_name')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6rnSmDxMeTZ",
        "outputId": "f49192ff-c9f6-4297-a444-9cb94e585cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Created default config at: /content/drive/MyDrive/unetr_model_busi_Test/configs/default_busi.yaml\n",
            "[OK] Loaded config from: /content/drive/MyDrive/unetr_model_busi_Test/configs/default_busi.yaml\n",
            "[INFO] Config run_name: unetr_model_busi_IMG256_SEED42_2025-11-04_16-43-23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 4/5 — Sanity checks: dataset presence & key fields\n",
        "# ------------------------------------------------------------\n",
        "problems = []\n",
        "\n",
        "if not busi_file.exists():\n",
        "    problems.append(f\"Missing dataset cache file: {busi_file}\")\n",
        "\n",
        "required_keys = [\n",
        "    (\"run\", \"seed\"), (\"data\", \"medsegbench_dir\"), (\"data\", \"resolution\"),\n",
        "    (\"train\", \"batch_size\"), (\"train\", \"epochs\"),\n",
        "    (\"loss\", \"primary\"), (\"metrics\", \"threshold\"), (\"model\", \"name\"),\n",
        "]\n",
        "for sect, key in required_keys:\n",
        "    if sect not in cfg or key not in cfg[sect]:\n",
        "        problems.append(f\"Config missing: {sect}.{key}\")\n",
        "\n",
        "if problems:\n",
        "    print(\"[WARN] Sanity check issues:\")\n",
        "    for p in problems: print(\" -\", p)\n",
        "else:\n",
        "    print(\"[OK] Dataset file present and config has required keys.\")\n",
        "\n",
        "print(f\"[ECHO] Using dataset cache: {busi_file}\")\n",
        "print(f\"[ECHO] MEDSEGBENCH_DIR   : {msb_dir}\")\n",
        "print(f\"[ECHO] Model name        : {cfg['model']['name']}\")\n",
        "print(f\"[ECHO] Loss              : {cfg['loss']['primary']} (weights={cfg['loss'].get('weights')})\")\n",
        "print(f\"[ECHO] Metrics threshold : {cfg['metrics']['threshold']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-0MG3hAMeQO",
        "outputId": "781e6b70-8a1a-4310-e3f6-aef813f4e751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Dataset file present and config has required keys.\n",
            "[ECHO] Using dataset cache: /content/data/MedSegBenchCache/busi_256.npz\n",
            "[ECHO] MEDSEGBENCH_DIR   : /content/data/MedSegBenchCache\n",
            "[ECHO] Model name        : unetr_model\n",
            "[ECHO] Loss              : dice_bce (weights={'dice': 0.7, 'bce': 0.3})\n",
            "[ECHO] Metrics threshold : 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 5/5 — Snapshot config for this run\n",
        "# ------------------------------------------------------------\n",
        "(root / \"summary\").mkdir(parents=True, exist_ok=True)\n",
        "cfg_snapshot = root / \"summary\" / f\"{RUN_NAME}_config.yaml\"\n",
        "with open(cfg_snapshot, \"w\", encoding=\"utf-8\") as f:\n",
        "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
        "\n",
        "print(f\"[OK] Saved config snapshot to: {cfg_snapshot.resolve()}\")\n",
        "print(\"[NEXT] STEP 3 will load MedSegBench predefined splits and print sample counts per set (no re-splitting).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_7dS00IMeNp",
        "outputId": "6bb97580-f075-4350-e1c8-963f37d5e570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved config snapshot to: /content/drive/MyDrive/unetr_model_busi_Test/summary/unetr_model_busi_IMG256_SEED42_2025-11-04_16-43-23_config.yaml\n",
            "[NEXT] STEP 3 will load MedSegBench predefined splits and print sample counts per set (no re-splitting).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 1/4 — Resolve paths and open the cached NPZ\n",
        "# ------------------------------------------------------------\n",
        "import numpy as np\n",
        "\n",
        "msb_dir = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "RESOLUTION = int(globals().get(\"RESOLUTION\", globals().get(\"SIZE\", 256)))\n",
        "busi_file = msb_dir / f\"busi_{RESOLUTION}.npz\"\n",
        "assert busi_file.exists(), f\"Expected dataset file not found: {busi_file}\"\n",
        "\n",
        "npz = np.load(busi_file, allow_pickle=True)\n",
        "keys = list(npz.keys())\n",
        "print(f\"[INFO] Loaded: {busi_file}\")\n",
        "print(f\"[ECHO] MEDSEGBENCH_DIR: {msb_dir.resolve()}\")\n",
        "print(f\"[INFO] NPZ keys ({len(keys)}): {keys[:12]}{'...' if len(keys)>12 else ''}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OWsTb-XMeKx",
        "outputId": "3f8eebcd-9ded-45af-e914-45aeb1989d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded: /content/data/MedSegBenchCache/busi_256.npz\n",
            "[ECHO] MEDSEGBENCH_DIR: /content/data/MedSegBenchCache\n",
            "[INFO] NPZ keys (18): ['train_images_C1', 'train_label_C1', 'train_images_C2', 'train_label_C2', 'test_images_C1', 'test_label_C1', 'test_images_C2', 'test_label_C2', 'val_images_C1', 'val_label_C1', 'val_images_C2', 'val_label_C2']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 2/4 — Infer split format (supports *_label/_labels)\n",
        "# ------------------------------------------------------------\n",
        "def _as_list(x):\n",
        "    if isinstance(x, np.ndarray): x = x.tolist()\n",
        "    return list(x) if isinstance(x, (list, tuple)) else [x]\n",
        "\n",
        "def infer_splits(npz_obj):\n",
        "    k = set(npz_obj.keys())\n",
        "\n",
        "    # Case A: per-split arrays (preferred)\n",
        "    def _find_lbl_key(split):\n",
        "        for suffix in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "            cand = f\"{split}_{suffix}\"\n",
        "            if cand in k: return cand\n",
        "        return None\n",
        "\n",
        "    have_all = True\n",
        "    meta = {}\n",
        "    for s in (\"train\",\"val\",\"test\"):\n",
        "        ik = f\"{s}_images\"; lk = _find_lbl_key(s)\n",
        "        if ik in k and lk in k and len(npz_obj[ik]) == len(npz_obj[lk]):\n",
        "            meta[s] = {\"n\": len(npz_obj[ik]), \"img_key\": ik, \"lbl_key\": lk}\n",
        "        else:\n",
        "            have_all = False; break\n",
        "    if have_all:\n",
        "        counts = {s: meta[s][\"n\"] for s in meta}\n",
        "        idx    = {s: list(range(meta[s][\"n\"])) for s in meta}\n",
        "        return counts, idx, \"A(images+labels)\"\n",
        "\n",
        "    # Case B: global arrays + explicit indices\n",
        "    for tri, vai, tei in [(\"train_idx\",\"val_idx\",\"test_idx\"),\n",
        "                          (\"train_indices\",\"val_indices\",\"test_indices\"),\n",
        "                          (\"split_train\",\"split_val\",\"split_test\")]:\n",
        "        if tri in k and vai in k and tei in k:\n",
        "            tr, va, te = _as_list(npz_obj[tri]), _as_list(npz_obj[vai]), _as_list(npz_obj[tei])\n",
        "            counts = {\"train\": len(tr), \"val\": len(va), \"test\": len(te)}\n",
        "            idx    = {\"train\": tr, \"val\": va, \"test\": te}\n",
        "            return counts, idx, \"B(indices)\"\n",
        "\n",
        "    raise RuntimeError(\"Could not infer predefined splits (need per-split arrays or *_idx lists).\")\n",
        "\n",
        "counts, split_idx, pattern = infer_splits(npz)\n",
        "print(f\"[OK] Split pattern detected: Case {pattern}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR2jkJQdMeH6",
        "outputId": "4ad8f2d9-7804-4ff2-b015-af3cb7086790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Split pattern detected: Case A(images+labels)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS (SPEED-UP, OPTIONAL)\n",
        "# Cell 2.5/4 — Materialize arrays to RAM and rebind `npz`\n",
        "# ------------------------------------------------------------\n",
        "npz_ram = {}\n",
        "for k in keys:\n",
        "    obj = npz[k]\n",
        "    try: npz_ram[k] = obj[:] if isinstance(obj, np.ndarray) else obj\n",
        "    except Exception: npz_ram[k] = obj\n",
        "\n",
        "try: npz.close()\n",
        "except Exception: pass\n",
        "npz = npz_ram\n",
        "\n",
        "def _shape(x): return getattr(x, \"shape\", None)\n",
        "print(\"[SPEED] NPZ materialized to RAM. Example shapes:\")\n",
        "for probe in [\"train_images\",\"train_label\",\"train_masks\",\"val_images\",\"val_label\",\"test_images\",\"test_label\"]:\n",
        "    if probe in npz:\n",
        "        print(f\"  • {probe}: {_shape(npz[probe])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwR2CDMlNEWg",
        "outputId": "86543e17-769c-4930-cfce-be3ba743013c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SPEED] NPZ materialized to RAM. Example shapes:\n",
            "  • train_images: (452, 256, 256)\n",
            "  • train_label: (452, 256, 256)\n",
            "  • val_images: (64, 256, 256)\n",
            "  • val_label: (64, 256, 256)\n",
            "  • test_images: (131, 256, 256)\n",
            "  • test_label: (131, 256, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 3/4 — Print counts per set\n",
        "# ------------------------------------------------------------\n",
        "print(\"[COUNTS] Samples per split (predefined by MedSegBench)\")\n",
        "print(f\"  • Train : {counts['train']}\")\n",
        "print(f\"  • Val   : {counts['val']}\")\n",
        "print(f\"  • Test  : {counts['test']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilq_e8DpNET1",
        "outputId": "806730a4-744b-4199-edc1-3bb1718d6828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[COUNTS] Samples per split (predefined by MedSegBench)\n",
            "  • Train : 452\n",
            "  • Val   : 64\n",
            "  • Test  : 131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 4/4 — Save IDs to disk for reproducibility\n",
        "# ------------------------------------------------------------\n",
        "summary_dir = Path(globals().get(\"root\", Path(\".\"))) / \"summary\"\n",
        "summary_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def write_list(path: Path, arr):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for x in arr: f.write(f\"{x}\\n\")\n",
        "\n",
        "train_ids_path = summary_dir / f\"busi_{RESOLUTION}_train_ids.txt\"\n",
        "val_ids_path   = summary_dir / f\"busi_{RESOLUTION}_val_ids.txt\"\n",
        "test_ids_path  = summary_dir / f\"busi_{RESOLUTION}_test_ids.txt\"\n",
        "\n",
        "write_list(train_ids_path, split_idx[\"train\"])\n",
        "write_list(val_ids_path,   split_idx[\"val\"])\n",
        "write_list(test_ids_path,  split_idx[\"test\"])\n",
        "\n",
        "print(\"[OK] Saved split ID lists:\")\n",
        "print(f\"  • {train_ids_path}\")\n",
        "print(f\"  • {val_ids_path}\")\n",
        "print(f\"  • {test_ids_path}\")\n",
        "print(\"[NEXT] STEP 4 will cover preprocessing pipeline (resize/normalize) and identical augmentations.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYL96afWNERC",
        "outputId": "cf69c9b1-ff9d-4997-f7ac-411c7ea64e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved split ID lists:\n",
            "  • /content/drive/MyDrive/unetr_model_busi_Test/summary/busi_256_train_ids.txt\n",
            "  • /content/drive/MyDrive/unetr_model_busi_Test/summary/busi_256_val_ids.txt\n",
            "  • /content/drive/MyDrive/unetr_model_busi_Test/summary/busi_256_test_ids.txt\n",
            "[NEXT] STEP 4 will cover preprocessing pipeline (resize/normalize) and identical augmentations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS (IDENTICAL POLICY)\n",
        "# Cell 1/5 — Imports, constants, and NPZ reload\n",
        "# ------------------------------------------------------------\n",
        "import numpy as np, torch\n",
        "from pathlib import Path\n",
        "\n",
        "RESOLUTION = int(globals().get(\"RESOLUTION\", globals().get(\"SIZE\", 256)))\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", RESOLUTION))\n",
        "BATCH_SIZE = int(globals().get(\"BATCH_SIZE\", 8))\n",
        "\n",
        "NORM_MEAN = (0.485, 0.456, 0.406)\n",
        "NORM_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "msb_dir   = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "busi_file = msb_dir / f\"busi_{RESOLUTION}.npz\"\n",
        "assert busi_file.exists(), f\"Expected dataset file not found: {busi_file}\"\n",
        "\n",
        "npz_l = np.load(busi_file, allow_pickle=True)\n",
        "\n",
        "def _as_list(x):\n",
        "    if isinstance(x, np.ndarray): x = x.tolist()\n",
        "    return list(x) if isinstance(x, (list, tuple)) else [x]\n",
        "\n",
        "def _infer_splits(npz_obj):\n",
        "    k = set(npz_obj.keys())\n",
        "    def _find_lbl_key(split):\n",
        "        for suffix in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "            cand = f\"{split}_{suffix}\"\n",
        "            if cand in k: return cand\n",
        "        return None\n",
        "    have_all = True\n",
        "    meta = {}\n",
        "    for s in (\"train\",\"val\",\"test\"):\n",
        "        ik = f\"{s}_images\"; lk = _find_lbl_key(s)\n",
        "        if ik in k and lk in k:\n",
        "            n = len(npz_obj[ik])\n",
        "            if n != len(npz_obj[lk]): raise RuntimeError(f\"{s}: images != labels length\")\n",
        "            meta[s] = {\"n\": n, \"img_key\": ik, \"lbl_key\": lk}\n",
        "        else:\n",
        "            have_all = False; break\n",
        "    if have_all:\n",
        "        return {s: meta[s][\"n\"] for s in meta}, {s: list(range(meta[s][\"n\"])) for s in meta}\n",
        "    for tri, vai, tei in [(\"train_idx\",\"val_idx\",\"test_idx\"),\n",
        "                          (\"train_indices\",\"val_indices\",\"test_indices\"),\n",
        "                          (\"split_train\",\"split_val\",\"split_test\")]:\n",
        "        if tri in k and vai in k and tei in k:\n",
        "            tr = _as_list(npz_obj[tri]); va = _as_list(npz_obj[vai]); te = _as_list(npz_obj[tei])\n",
        "            return {\"train\": len(tr), \"val\": len(va), \"test\": len(te)}, {\"train\": tr, \"val\": va, \"test\": te}\n",
        "    raise RuntimeError(\"Could not re-infer splits; ensure STEP 3 ran successfully.\")\n",
        "\n",
        "if \"counts\" in globals() and \"split_idx\" in globals():\n",
        "    _counts, _split_idx = counts, split_idx\n",
        "else:\n",
        "    _counts, _split_idx = _infer_splits(npz_l)\n",
        "\n",
        "print(f\"[INFO] Using NPZ: {busi_file}\")\n",
        "print(f\"[INFO] Image size policy: RESOLUTION={RESOLUTION} → NETWORK INPUT={IMAGE_SIZE}\")\n",
        "print(f\"[COUNTS] train={_counts['train']}  val={_counts['val']}  test={_counts['test']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCUg-BK-NEKg",
        "outputId": "29664790-a8f7-45c5-e40d-6add5b315257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using NPZ: /content/data/MedSegBenchCache/busi_256.npz\n",
            "[INFO] Image size policy: RESOLUTION=256 → NETWORK INPUT=256\n",
            "[COUNTS] train=452  val=64  test=131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 2/5 — Albumentations transforms (train/val/test)\n",
        "# ------------------------------------------------------------\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "resize_ops = []\n",
        "if IMAGE_SIZE != RESOLUTION:\n",
        "    resize_ops = [A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, interpolation=1)]  # 1=bilinear\n",
        "\n",
        "train_tf = A.Compose([\n",
        "    *resize_ops,\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.15, rotate_limit=15, border_mode=0, p=0.3),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.GaussianBlur(blur_limit=(3,5), p=0.15),\n",
        "    A.GaussNoise(var_limit=(5.0, 20.0), p=0.15),\n",
        "    A.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
        "    ToTensorV2(transpose_mask=True),\n",
        "])\n",
        "\n",
        "val_tf = A.Compose([\n",
        "    *resize_ops,\n",
        "    A.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
        "    ToTensorV2(transpose_mask=True),\n",
        "])\n",
        "\n",
        "test_tf = val_tf\n",
        "print(\"[OK] Transforms configured (train/val/test).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRltv3HENMhd",
        "outputId": "da2f7529-7ed3-429f-d1eb-2cb96e52e337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Transforms configured (train/val/test).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 3/5 — Dataset that memory-maps the NPZ (ISICNPZDataset-style)\n",
        "# ------------------------------------------------------------\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def _label_key_for(split, npz_obj_or_keys):\n",
        "    k = set(npz_obj_or_keys if isinstance(npz_obj_or_keys, (set,list,tuple)) else npz_obj_or_keys.keys())\n",
        "    for suf in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "        cand = f\"{split}_{suf}\"\n",
        "        if cand in k: return cand\n",
        "    raise KeyError(f\"No label key found for split={split}.\")\n",
        "\n",
        "class ISICNPZDataset(Dataset):\n",
        "    def __init__(self, npz_path, split: str, indices, transform=None):\n",
        "        super().__init__()\n",
        "        self.path = str(npz_path)\n",
        "        _peek = np.load(self.path, allow_pickle=True, mmap_mode=\"r\")\n",
        "        self.img_key = f\"{split}_images\"\n",
        "        self.lbl_key = _label_key_for(split, _peek)\n",
        "        self.length = len(_peek[self.img_key])\n",
        "        assert self.length == len(_peek[self.lbl_key]), \"Images/labels length mismatch.\"\n",
        "        _peek.close()\n",
        "\n",
        "        self.split = split\n",
        "        self.indices = list(indices)\n",
        "        self.transform = transform\n",
        "        self._npz = None\n",
        "\n",
        "    def _ensure_open(self):\n",
        "        if self._npz is None:\n",
        "            self._npz = np.load(self.path, allow_pickle=True, mmap_mode=\"r\")\n",
        "\n",
        "    def __len__(self): return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        self._ensure_open()\n",
        "        i = self.indices[idx]\n",
        "        img = self._npz[self.img_key][i]  # HxW or HxWx3\n",
        "        msk = self._npz[self.lbl_key][i]  # HxW\n",
        "\n",
        "        if img.ndim == 2: img = np.stack([img, img, img], axis=-1)\n",
        "        if msk.max() > 1: msk = (msk > 127).astype(np.uint8)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            out = self.transform(image=img, mask=msk)\n",
        "            img_t = out[\"image\"]\n",
        "            msk_t = out[\"mask\"].unsqueeze(0) if out[\"mask\"].ndim == 2 else out[\"mask\"]\n",
        "        else:\n",
        "            img_f = img.astype(np.float32) / 255.0\n",
        "            img_f = (img_f - np.array(NORM_MEAN)) / np.array(NORM_STD)\n",
        "            img_t = torch.from_numpy(img_f).permute(2,0,1).contiguous()\n",
        "            msk_t = torch.from_numpy(msk.astype(np.float32)).unsqueeze(0)\n",
        "\n",
        "        return img_t, msk_t\n",
        "\n",
        "    def __del__(self):\n",
        "        try:\n",
        "            if self._npz is not None: self._npz.close()\n",
        "        except Exception: pass\n"
      ],
      "metadata": {
        "id": "hDWGycNJNMej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 4/5 — DataLoaders with safe settings\n",
        "# ------------------------------------------------------------\n",
        "from torch.utils.data import DataLoader\n",
        "import torch, os\n",
        "\n",
        "train_ds = ISICNPZDataset(busi_file, \"train\", _split_idx[\"train\"], transform=train_tf)\n",
        "val_ds   = ISICNPZDataset(busi_file, \"val\",   _split_idx[\"val\"],   transform=val_tf)\n",
        "test_ds  = ISICNPZDataset(busi_file, \"test\",  _split_idx[\"test\"],  transform=test_tf)\n",
        "\n",
        "num_workers = 2\n",
        "pin = torch.cuda.is_available()\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=True, prefetch_factor=2, persistent_workers=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=False, prefetch_factor=2, persistent_workers=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=1, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=False, prefetch_factor=2, persistent_workers=True)\n",
        "\n",
        "xb, yb = next(iter(train_loader))\n",
        "print(f\"[OK] Train batch shapes: images={tuple(xb.shape)} masks={tuple(yb.shape)}\")\n",
        "print(f\"[INFO] num_workers={num_workers}, pin_memory={pin}, batch_size={BATCH_SIZE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JikBr2VLNMb4",
        "outputId": "f1eb31e4-a399-4878-8340-2443faada7a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Train batch shapes: images=(8, 3, 256, 256) masks=(8, 1, 256, 256)\n",
            "[INFO] num_workers=2, pin_memory=False, batch_size=8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 5/5 — Policy echo (for the paper/log)\n",
        "# ------------------------------------------------------------\n",
        "print(\"[POLICY] Preprocessing/Normalization\")\n",
        "print(f\"  • Resize to: {IMAGE_SIZE}x{IMAGE_SIZE} (if different from NPZ {RESOLUTION})\")\n",
        "print(f\"  • Normalize (ImageNet): mean={NORM_MEAN}, std={NORM_STD}\")\n",
        "print(\"[POLICY] Train augmentations\")\n",
        "print(\"  • HorizontalFlip p=0.5\")\n",
        "print(\"  • ShiftScaleRotate (±2% shift, ±15% scale, ±15° rotate) p=0.3\")\n",
        "print(\"  • Brightness/Contrast p=0.3\")\n",
        "print(\"  • GaussianBlur p=0.15, GaussNoise p=0.15\")\n",
        "print(\"[POLICY] Val/Test: no augmentations (only resize + normalize)\")\n",
        "print(\"[READY] DataLoaders prepared. Next: STEP 5 (Data sanity visuals).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu6Q26YTNMY6",
        "outputId": "25de0254-d508-41c6-cab7-5cce1cc37240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[POLICY] Preprocessing/Normalization\n",
            "  • Resize to: 256x256 (if different from NPZ 256)\n",
            "  • Normalize (ImageNet): mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
            "[POLICY] Train augmentations\n",
            "  • HorizontalFlip p=0.5\n",
            "  • ShiftScaleRotate (±2% shift, ±15% scale, ±15° rotate) p=0.3\n",
            "  • Brightness/Contrast p=0.3\n",
            "  • GaussianBlur p=0.15, GaussNoise p=0.15\n",
            "[POLICY] Val/Test: no augmentations (only resize + normalize)\n",
            "[READY] DataLoaders prepared. Next: STEP 5 (Data sanity visuals).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3RqUb60LNMWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# Cell 1/4\n",
        "# ------------------------------------------------------------\n",
        "# Goal:\n",
        "#   • Use a pretrained ViT-B/16 encoder (timm) and a U-Net decoder.\n",
        "#   • Keep helpers compatible with our pipeline (ConvBNReLU, UpBlock).\n",
        "# ============================================================\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "# Reuse helpers if already defined elsewhere\n",
        "if \"ConvBNReLU\" not in globals():\n",
        "    class ConvBNReLU(nn.Module):\n",
        "        def __init__(self, in_ch, out_ch, k=3, s=1, p=1):\n",
        "            super().__init__()\n",
        "            self.conv = nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)\n",
        "            self.bn   = nn.BatchNorm2d(out_ch)\n",
        "            self.act  = nn.ReLU(inplace=True)\n",
        "        def forward(self, x): return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "if \"UpBlock\" not in globals():\n",
        "    class UpBlock(nn.Module):\n",
        "        def __init__(self, in_ch, skip_ch, out_ch):\n",
        "            super().__init__()\n",
        "            self.conv1 = ConvBNReLU(in_ch + skip_ch, out_ch)\n",
        "            self.conv2 = ConvBNReLU(out_ch, out_ch)\n",
        "        def forward(self, x, skip):\n",
        "            # upsample x -> skip spatial size, then fuse\n",
        "            x = F.interpolate(x, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1)\n",
        "            return self.conv2(self.conv1(x))\n",
        "\n",
        "# ============================================================\n",
        "# STEP 6D — UNETR (paper-style) — Model definition\n",
        "# Cell 2/4\n",
        "# ------------------------------------------------------------\n",
        "# Design notes:\n",
        "#   • We tap 4 transformer depths (≈[3,6,9,12]) via hooks → tokens.\n",
        "#   • Convert tokens to 1/16 feature maps, then 1×1 project to widths:\n",
        "#         f0=96, f1=192, f2=384, f3=768  (all at 1/16 stride)\n",
        "#   • Decoder:\n",
        "#         l3: 768→384 (deep stream)\n",
        "#         up2: (384 ⊕ 192) → 192   @ 1/16 → up to 1/8\n",
        "#         up1: (192 ⊕  96) →  96   @ 1/8  → refine to 1/4 → head\n",
        "#   • This fixes channel mismatches and keeps shapes explicit.\n",
        "# ============================================================\n",
        "class UNETR_PaperStyle(nn.Module):\n",
        "    def __init__(self, img_size=256, depths=(3,6,9,12)):\n",
        "        super().__init__()\n",
        "        # Pretrained ViT-B/16 encoder\n",
        "        self.vit = timm.create_model(\n",
        "            \"vit_base_patch16_224\",\n",
        "            pretrained=True, num_classes=0, global_pool=\"\", img_size=img_size\n",
        "        )\n",
        "        self.embed_dim = getattr(self.vit, \"num_features\", 768)\n",
        "        self.patch     = 16\n",
        "        self.depths    = depths\n",
        "\n",
        "        # 1x1 projections for the 4 tapped stages (all maps are 1/16 stride)\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Conv2d(self.embed_dim,  96, 1, bias=False),  # stage @ depth≈3\n",
        "            nn.Conv2d(self.embed_dim, 192, 1, bias=False),  # depth≈6\n",
        "            nn.Conv2d(self.embed_dim, 384, 1, bias=False),  # depth≈9\n",
        "            nn.Conv2d(self.embed_dim, 768, 1, bias=False),  # depth≈12 (deep)\n",
        "        ])\n",
        "\n",
        "        # Lateral 1x1 to normalize decoder inputs (prevents channel mismatches)\n",
        "        self.l3 = nn.Conv2d(768, 384, 1, bias=False)  # deep stream → 384\n",
        "        self.l2 = nn.Conv2d(192, 192, 1, bias=False)  # mid skip     → 192\n",
        "        self.l1 = nn.Conv2d( 96,  96, 1, bias=False)  # shallow skip  →  96\n",
        "\n",
        "        # Decoder top-down\n",
        "        self.up2 = UpBlock(in_ch=384, skip_ch=192, out_ch=192)  # fuse @1/16 → (then we upsample to 1/8)\n",
        "        self.up1 = UpBlock(in_ch=192, skip_ch= 96, out_ch= 96)  # fuse @1/8  → output @1/8\n",
        "\n",
        "        # Refine @1/4 then go to full res\n",
        "        self.refine_quarter = ConvBNReLU(96, 96)\n",
        "        self.head = nn.Conv2d(96, 1, 1)\n",
        "\n",
        "        # storage for hooked transformer outputs (tokens)\n",
        "        self._feats = []\n",
        "        def make_hook():\n",
        "            def hook(module, inp, outp):\n",
        "                self._feats.append(outp)  # (B, N or 1+N, C)\n",
        "            return hook\n",
        "        for d in self.depths:\n",
        "            self.vit.blocks[d-1].register_forward_hook(make_hook())\n",
        "\n",
        "    def _tokens_to_map(self, t, H, W):\n",
        "        # t: (B, 1+N, C) or (B, N, C)  → (B, C, H/16, W/16)\n",
        "        if t.size(1) == (H//self.patch)*(W//self.patch) + 1:\n",
        "            t = t[:, 1:, :]\n",
        "        B, N, C = t.shape\n",
        "        gh, gw = H // self.patch, W // self.patch\n",
        "        return t.transpose(1, 2).contiguous().view(B, C, gh, gw)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, _, H, W = x.shape\n",
        "        self._feats.clear()\n",
        "\n",
        "        _ = self.vit.forward_features(x)  # triggers hooks at depths\n",
        "        assert len(self._feats) == 4, \"UNETR taps not captured (expected 4).\"\n",
        "\n",
        "        # Project all tapped token maps to 1/16 spatial features\n",
        "        fmap_1_16 = [ self._tokens_to_map(t, H, W) for t in self._feats ]  # all (B, C, H/16, W/16)\n",
        "        f0 = self.proj[0](fmap_1_16[0])   # 96   @1/16\n",
        "        f1 = self.proj[1](fmap_1_16[1])   # 192  @1/16\n",
        "        f2 = self.proj[2](fmap_1_16[2])   # 384  @1/16\n",
        "        f3 = self.proj[3](fmap_1_16[3])   # 768  @1/16  (deep)\n",
        "\n",
        "        # Decoder\n",
        "        x3 = self.l3(f3)                  # 384 @1/16\n",
        "        d2 = self.up2(x3, self.l2(f1))    # 192 @1/16\n",
        "        d2 = F.interpolate(d2, scale_factor=2, mode=\"bilinear\", align_corners=False)   # → 1/8\n",
        "\n",
        "        skip1 = F.interpolate(self.l1(f0), scale_factor=2, mode=\"bilinear\", align_corners=False)  # 96 @1/8\n",
        "        d1 = self.up1(d2, skip1)          # 96 @1/8\n",
        "\n",
        "        # refine at 1/4, then to H\n",
        "        d1_quarter = self.refine_quarter(F.interpolate(d1, scale_factor=2, mode=\"bilinear\", align_corners=False))  # 1/4\n",
        "        y = F.interpolate(d1_quarter, scale_factor=4, mode=\"bilinear\", align_corners=False)  # → H\n",
        "        logits = self.head(y)\n",
        "        return {\"logits\": logits}\n"
      ],
      "metadata": {
        "id": "tldnF90ENMTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# Cell 2/4 — CPU fairness + CKPT path + preload 50 RAW test samples\n",
        "# (SAFE: avoid set_num_interop_threads error if threads already started)\n",
        "# ------------------------------------------------------------\n",
        "import os, psutil, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# ---- CPU fairness (as requested) ----\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"MKL_NUM_THREADS\"]  = \"1\"\n",
        "\n",
        "import torch\n",
        "\n",
        "# Always safe at runtime:\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "# set_num_interop_threads must be called before any parallel work; try, else continue.\n",
        "try:\n",
        "    if hasattr(torch, \"set_num_interop_threads\"):\n",
        "        torch.set_num_interop_threads(1)\n",
        "except RuntimeError as e:\n",
        "    # Already started parallel work; keep current interop setting but log it.\n",
        "    print(f\"[WARN] {e} — continuing with interop_threads={getattr(torch, 'get_num_interop_threads', lambda: 'N/A')()}\")\n",
        "\n",
        "DEVICE = \"cpu\"\n",
        "print(f\"[CPU] threads={torch.get_num_threads()} \"\n",
        "      f\"interop={getattr(torch, 'get_num_interop_threads', lambda: 'N/A')()} \"\n",
        "      f\"OMP={os.getenv('OMP_NUM_THREADS')} MKL={os.getenv('MKL_NUM_THREADS')}\")\n",
        "\n",
        "# ---- threshold from cfg (fallback 0.5) ----\n",
        "THRESH = float(cfg.get(\"metrics\", {}).get(\"threshold\", 0.5)) if \"cfg\" in globals() else 0.5\n",
        "print(f\"[INFO] THRESH={THRESH}\")\n",
        "\n",
        "# ---- your exact trained checkpoint path ----\n",
        "from pathlib import Path\n",
        "CKPT_PATH = \"/content/drive/MyDrive/unetr_model_busi_IMG256_SEED42_2025-11-04_13-32-50_best.pt\"  # <<< EDIT THIS\n",
        "if not Path(CKPT_PATH).exists():\n",
        "    raise FileNotFoundError(f\"Checkpoint not found: {CKPT_PATH}\")\n",
        "\n",
        "# ---- build a 50-sample test index (first 50 of split) ----\n",
        "NUM_SAMPLES = 50\n",
        "WARMUP = 5\n",
        "test_ids = split_idx[\"test\"]\n",
        "if len(test_ids) < NUM_SAMPLES:\n",
        "    raise ValueError(f\"Test set has {len(test_ids)} samples; need at least {NUM_SAMPLES}.\")\n",
        "sel_ids = test_ids[:NUM_SAMPLES]\n",
        "\n",
        "# ---- preload RAW arrays (avoid disk I/O in timing) ----\n",
        "# Note: transforms/tensorization are INSIDE timing for end-to-end latency.\n",
        "test_img_key = \"test_images\"\n",
        "for lblk in (\"test_masks\",\"test_mask\",\"test_labels\",\"test_label\"):\n",
        "    if lblk in npz: test_lbl_key = lblk; break\n",
        "else:\n",
        "    raise KeyError(\"No test label key among {test_masks, test_mask, test_labels, test_label}.\")\n",
        "\n",
        "raw_samples = []\n",
        "for i in sel_ids:\n",
        "    img = npz[test_img_key][i]\n",
        "    msk = npz[test_lbl_key][i]\n",
        "    raw_samples.append((img, msk))\n",
        "print(f\"[OK] Preloaded RAW {len(raw_samples)} test samples into RAM.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlF04X77Nl7Y",
        "outputId": "80f565d0-f2f8-4982-90cc-2387e5f84951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CPU] threads=1 interop=1 OMP=1 MKL=1\n",
            "[INFO] THRESH=0.5\n",
            "[OK] Preloaded RAW 50 test samples into RAM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVAL\n",
        "# Cell 3/4 (REPLACED) — Instantiate model + CLEAN LOAD (CPU)\n",
        "# ------------------------------------------------------------\n",
        "from pathlib import Path\n",
        "import re, torch\n",
        "\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", 256))\n",
        "model = UNETR_PaperStyle(img_size=IMAGE_SIZE).to(\"cpu\")\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "\n",
        "def unwrap_state(d):\n",
        "    # common wrappers\n",
        "    for k in [\"model_state\",\"state_dict\",\"model\",\"net\",\"ema\",\"model_state_dict\"]:\n",
        "        if isinstance(d, dict) and k in d and isinstance(d[k], dict):\n",
        "            return d[k]\n",
        "    return d if isinstance(d, dict) else {}\n",
        "\n",
        "raw = unwrap_state(ckpt)\n",
        "\n",
        "# 1) strip 'module.' prefix\n",
        "clean = {}\n",
        "for k, v in raw.items():\n",
        "    nk = k[7:] if k.startswith(\"module.\") else k\n",
        "    clean[nk] = v\n",
        "\n",
        "# 2) drop profiling buffers (from thop/fvcore)\n",
        "def is_profile_key(k: str) -> bool:\n",
        "    return k.endswith(\".total_ops\") or k.endswith(\".total_params\")\n",
        "clean = {k:v for k,v in clean.items() if not is_profile_key(k)}\n",
        "\n",
        "# 3) optional prefix remaps (adapt if your training used different names)\n",
        "#    e.g., 'backbone.' -> 'vit.' , 'encoder.' -> 'vit.' , 'transformer.' -> 'vit.'\n",
        "remaps = [\n",
        "    (r\"^backbone\\.\", \"vit.\"),\n",
        "    (r\"^encoder\\.\",  \"vit.\"),\n",
        "    (r\"^transformer\\.\", \"vit.\"),\n",
        "]\n",
        "remapped = {}\n",
        "for k, v in clean.items():\n",
        "    nk = k\n",
        "    for pat, rep in remaps:\n",
        "        nk = re.sub(pat, rep, nk)\n",
        "    remapped[nk] = v\n",
        "clean = remapped\n",
        "\n",
        "# 4) keep only keys that exist in current model (exact-name intersection)\n",
        "model_sd = model.state_dict()\n",
        "intersect = {k:v for k,v in clean.items() if k in model_sd and v.shape == model_sd[k].shape}\n",
        "\n",
        "# 5) report coverage\n",
        "print(f\"[CKPT] total keys in state: {len(raw)}\")\n",
        "print(f\"[CKPT] after strip+drop:     {len(clean)}\")\n",
        "print(f\"[CKPT] intersect (name+shape): {len(intersect)} / model expects {len(model_sd)}\")\n",
        "\n",
        "# 6) load intersect only (others remain as initialized / DeiT pretrained)\n",
        "missing_before = set(model_sd.keys()) - set(intersect.keys())\n",
        "load_res = model_sd.copy()\n",
        "load_res.update(intersect)\n",
        "model.load_state_dict(load_res, strict=False)\n",
        "\n",
        "# sanity: print what we still miss (first 40)\n",
        "still_missing = list(set(model.state_dict().keys()) - set(intersect.keys()))\n",
        "print(f\"[LOAD] missing (after clean) ~ {len(still_missing)} (showing up to 40)\")\n",
        "print(still_missing[:40])\n",
        "\n",
        "model.eval()\n",
        "print(\"[OK] Cleaned checkpoint loaded into model on CPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "4c258520b7c9496789895b147fa4173e",
            "ba0630698a0b45c6ba93017f15c622a2",
            "7eb8fe78c46c40109b6da58c79a9c865",
            "450fc233834b4d69bf71a795915aeb81",
            "52d0d1c95136474384b8e53271d7685f",
            "ad6d4422e86f47748a5bbb63967654cb",
            "a12de94ca39248acafb481c89a5d3332",
            "76e607155e5447e0a6c59aec49b09bdb",
            "d671d91ea945401f8adaec0376e03014",
            "a9f973bbb05f4d5699507b0f6fdf770d",
            "8df1857eec64476585a28ccc7030f073"
          ]
        },
        "id": "zp39FVeBePV5",
        "outputId": "5f5ea56f-a4e3-4963-dd17-51ad1276f7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c258520b7c9496789895b147fa4173e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CKPT] total keys in state: 559\n",
            "[CKPT] after strip+drop:     191\n",
            "[CKPT] intersect (name+shape): 189 / model expects 189\n",
            "[LOAD] missing (after clean) ~ 0 (showing up to 40)\n",
            "[]\n",
            "[OK] Cleaned checkpoint loaded into model on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torch, re\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "\n",
        "def _unwrap_state(d):\n",
        "    # try common containers\n",
        "    for k in [\"state_dict\",\"model\",\"net\",\"ema\",\"model_state\"]:\n",
        "        if isinstance(d, dict) and k in d and isinstance(d[k], dict):\n",
        "            return d[k]\n",
        "    return d if isinstance(d, dict) else {}\n",
        "\n",
        "raw_state = _unwrap_state(ckpt)\n",
        "\n",
        "print(f\"[CKPT] top-level keys: {list(ckpt.keys())[:20]}\")\n",
        "print(f\"[CKPT] state len: {len(raw_state)}\")\n",
        "\n",
        "# Show a few parameter names to identify architecture/backbone\n",
        "sample_keys = list(raw_state.keys())[:40]\n",
        "print(\"[CKPT] sample param keys:\")\n",
        "for k in sample_keys:\n",
        "    print(\"  \", k)\n",
        "\n",
        "# Also show model keys to compare\n",
        "model_keys = list(model.state_dict().keys())\n",
        "print(f\"[MODEL] expects {len(model_keys)} tensors\")\n",
        "print(\"[MODEL] sample expected keys:\")\n",
        "for k in model_keys[:40]:\n",
        "    print(\"  \", k)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG20hJl3dpAi",
        "outputId": "eaea376c-cdce-48bd-f965-342baa70077f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CKPT] top-level keys: ['epoch', 'model_state', 'optimizer_state', 'val_dice', 'val_loss', 'cfg']\n",
            "[CKPT] state len: 559\n",
            "[CKPT] sample param keys:\n",
            "   total_ops\n",
            "   total_params\n",
            "   vit.cls_token\n",
            "   vit.pos_embed\n",
            "   vit.total_ops\n",
            "   vit.total_params\n",
            "   vit.patch_embed.total_ops\n",
            "   vit.patch_embed.total_params\n",
            "   vit.patch_embed.proj.weight\n",
            "   vit.patch_embed.proj.bias\n",
            "   vit.patch_embed.norm.total_ops\n",
            "   vit.patch_embed.norm.total_params\n",
            "   vit.patch_drop.total_ops\n",
            "   vit.patch_drop.total_params\n",
            "   vit.norm_pre.total_ops\n",
            "   vit.norm_pre.total_params\n",
            "   vit.blocks.0.total_ops\n",
            "   vit.blocks.0.total_params\n",
            "   vit.blocks.0.norm1.weight\n",
            "   vit.blocks.0.norm1.bias\n",
            "   vit.blocks.0.norm1.total_ops\n",
            "   vit.blocks.0.norm1.total_params\n",
            "   vit.blocks.0.attn.total_ops\n",
            "   vit.blocks.0.attn.total_params\n",
            "   vit.blocks.0.attn.qkv.weight\n",
            "   vit.blocks.0.attn.qkv.bias\n",
            "   vit.blocks.0.attn.q_norm.total_ops\n",
            "   vit.blocks.0.attn.q_norm.total_params\n",
            "   vit.blocks.0.attn.k_norm.total_ops\n",
            "   vit.blocks.0.attn.k_norm.total_params\n",
            "   vit.blocks.0.attn.norm.total_ops\n",
            "   vit.blocks.0.attn.norm.total_params\n",
            "   vit.blocks.0.attn.proj.weight\n",
            "   vit.blocks.0.attn.proj.bias\n",
            "   vit.blocks.0.ls1.total_ops\n",
            "   vit.blocks.0.ls1.total_params\n",
            "   vit.blocks.0.drop_path1.total_ops\n",
            "   vit.blocks.0.drop_path1.total_params\n",
            "   vit.blocks.0.norm2.weight\n",
            "   vit.blocks.0.norm2.bias\n",
            "[MODEL] expects 189 tensors\n",
            "[MODEL] sample expected keys:\n",
            "   vit.cls_token\n",
            "   vit.pos_embed\n",
            "   vit.patch_embed.proj.weight\n",
            "   vit.patch_embed.proj.bias\n",
            "   vit.blocks.0.norm1.weight\n",
            "   vit.blocks.0.norm1.bias\n",
            "   vit.blocks.0.attn.qkv.weight\n",
            "   vit.blocks.0.attn.qkv.bias\n",
            "   vit.blocks.0.attn.proj.weight\n",
            "   vit.blocks.0.attn.proj.bias\n",
            "   vit.blocks.0.norm2.weight\n",
            "   vit.blocks.0.norm2.bias\n",
            "   vit.blocks.0.mlp.fc1.weight\n",
            "   vit.blocks.0.mlp.fc1.bias\n",
            "   vit.blocks.0.mlp.fc2.weight\n",
            "   vit.blocks.0.mlp.fc2.bias\n",
            "   vit.blocks.1.norm1.weight\n",
            "   vit.blocks.1.norm1.bias\n",
            "   vit.blocks.1.attn.qkv.weight\n",
            "   vit.blocks.1.attn.qkv.bias\n",
            "   vit.blocks.1.attn.proj.weight\n",
            "   vit.blocks.1.attn.proj.bias\n",
            "   vit.blocks.1.norm2.weight\n",
            "   vit.blocks.1.norm2.bias\n",
            "   vit.blocks.1.mlp.fc1.weight\n",
            "   vit.blocks.1.mlp.fc1.bias\n",
            "   vit.blocks.1.mlp.fc2.weight\n",
            "   vit.blocks.1.mlp.fc2.bias\n",
            "   vit.blocks.2.norm1.weight\n",
            "   vit.blocks.2.norm1.bias\n",
            "   vit.blocks.2.attn.qkv.weight\n",
            "   vit.blocks.2.attn.qkv.bias\n",
            "   vit.blocks.2.attn.proj.weight\n",
            "   vit.blocks.2.attn.proj.bias\n",
            "   vit.blocks.2.norm2.weight\n",
            "   vit.blocks.2.norm2.bias\n",
            "   vit.blocks.2.mlp.fc1.weight\n",
            "   vit.blocks.2.mlp.fc1.bias\n",
            "   vit.blocks.2.mlp.fc2.weight\n",
            "   vit.blocks.2.mlp.fc2.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing, unexpected = model.load_state_dict(raw_state, strict=False)\n",
        "print(f\"[DIFF] missing ({len(missing)}):\")\n",
        "print(missing[:50])\n",
        "print(f\"[DIFF] unexpected ({len(unexpected)}):\")\n",
        "print(unexpected[:50])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuEkE7Rzd2HR",
        "outputId": "bbde0cda-f67f-4896-8102-d94e5f1c1a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DIFF] missing (0):\n",
            "[]\n",
            "[DIFF] unexpected (370):\n",
            "['total_ops', 'total_params', 'vit.total_ops', 'vit.total_params', 'vit.patch_embed.total_ops', 'vit.patch_embed.total_params', 'vit.patch_embed.norm.total_ops', 'vit.patch_embed.norm.total_params', 'vit.patch_drop.total_ops', 'vit.patch_drop.total_params', 'vit.norm_pre.total_ops', 'vit.norm_pre.total_params', 'vit.blocks.0.total_ops', 'vit.blocks.0.total_params', 'vit.blocks.0.norm1.total_ops', 'vit.blocks.0.norm1.total_params', 'vit.blocks.0.attn.total_ops', 'vit.blocks.0.attn.total_params', 'vit.blocks.0.attn.q_norm.total_ops', 'vit.blocks.0.attn.q_norm.total_params', 'vit.blocks.0.attn.k_norm.total_ops', 'vit.blocks.0.attn.k_norm.total_params', 'vit.blocks.0.attn.norm.total_ops', 'vit.blocks.0.attn.norm.total_params', 'vit.blocks.0.ls1.total_ops', 'vit.blocks.0.ls1.total_params', 'vit.blocks.0.drop_path1.total_ops', 'vit.blocks.0.drop_path1.total_params', 'vit.blocks.0.norm2.total_ops', 'vit.blocks.0.norm2.total_params', 'vit.blocks.0.mlp.total_ops', 'vit.blocks.0.mlp.total_params', 'vit.blocks.0.mlp.act.total_ops', 'vit.blocks.0.mlp.act.total_params', 'vit.blocks.0.mlp.norm.total_ops', 'vit.blocks.0.mlp.norm.total_params', 'vit.blocks.0.ls2.total_ops', 'vit.blocks.0.ls2.total_params', 'vit.blocks.0.drop_path2.total_ops', 'vit.blocks.0.drop_path2.total_params', 'vit.blocks.1.total_ops', 'vit.blocks.1.total_params', 'vit.blocks.1.norm1.total_ops', 'vit.blocks.1.norm1.total_params', 'vit.blocks.1.attn.total_ops', 'vit.blocks.1.attn.total_params', 'vit.blocks.1.attn.q_norm.total_ops', 'vit.blocks.1.attn.q_norm.total_params', 'vit.blocks.1.attn.k_norm.total_ops', 'vit.blocks.1.attn.k_norm.total_params']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# Cell 4/4 — Warm-up, timed run, metrics, save CSV+JSON\n",
        "# (FIX: added `import math`)\n",
        "# ------------------------------------------------------------\n",
        "import time, numpy as np, math, json, os, psutil, pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- helpers ----\n",
        "def apply_test_transform(img, msk):\n",
        "    # Ensure 3-ch image & binary mask; then apply test_tf (resize+norm+tensor)\n",
        "    if img.ndim == 2: img = np.stack([img, img, img], axis=-1)\n",
        "    if msk.max() > 1: msk = (msk > 127).astype(np.uint8)\n",
        "    out = test_tf(image=img, mask=msk)  # includes resize+normalize\n",
        "    x = out[\"image\"]                           # [C,H,W] float32\n",
        "    y = out[\"mask\"].unsqueeze(0) if out[\"mask\"].ndim==2 else out[\"mask\"]  # [1,H,W]\n",
        "    return x, y\n",
        "\n",
        "def binarize(prob, thr): return (prob >= thr).astype(np.uint8)\n",
        "\n",
        "def dice_iou(pred, mask, eps=1e-7):\n",
        "    inter = (pred & mask).sum()\n",
        "    union = (pred | mask).sum()\n",
        "    dice = (2*inter + eps) / (pred.sum() + mask.sum() + eps)\n",
        "    iou  = (inter + eps) / (union + eps)\n",
        "    return float(dice), float(iou)\n",
        "\n",
        "# ---- warm-up (excluded) ----\n",
        "with torch.no_grad():\n",
        "    for i in range(WARMUP):\n",
        "        img, msk = raw_samples[i]\n",
        "        x, y = apply_test_transform(img, msk)\n",
        "        _ = model(x.unsqueeze(0))\n",
        "\n",
        "# ---- timed run ----\n",
        "lat_ms, dices, ious = [], [], []\n",
        "cpu_hist, ram_hist  = [], []\n",
        "proc = psutil.Process(os.getpid())\n",
        "t_start = time.perf_counter()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(WARMUP, NUM_SAMPLES):\n",
        "        img, msk = raw_samples[i]\n",
        "\n",
        "        t0 = time.perf_counter()\n",
        "        x, y = apply_test_transform(img, msk)       # include resize+normalize in timing\n",
        "        out = model(x.unsqueeze(0))                 # forward\n",
        "        logits = out[\"logits\"] if isinstance(out, dict) and \"logits\" in out else out\n",
        "        prob = torch.sigmoid(logits).cpu().numpy().squeeze()\n",
        "        pred = binarize(prob, THRESH)\n",
        "        gt   = (y.squeeze().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        d, j = dice_iou(pred, gt)\n",
        "        t1 = time.perf_counter()\n",
        "\n",
        "        dices.append(d); ious.append(j)\n",
        "        lat_ms.append((t1 - t0) * 1000.0)\n",
        "        cpu_hist.append(psutil.cpu_percent(interval=None))\n",
        "        ram_hist.append(proc.memory_info().rss)\n",
        "\n",
        "t_end = time.perf_counter()\n",
        "\n",
        "# ---- summary ----\n",
        "def pct(vals, p):\n",
        "    if not vals: return float('nan')\n",
        "    a = sorted(vals)\n",
        "    k = (len(a)-1)*(p/100.0)\n",
        "    f,c = math.floor(k), math.ceil(k)\n",
        "    return a[int(k)] if f==c else a[f]*(c-k)+a[c]*(k-f)\n",
        "\n",
        "n = len(lat_ms)\n",
        "fps = (NUM_SAMPLES - WARMUP) / (t_end - t_start) if (t_end - t_start) > 0 else float('nan')\n",
        "summary = dict(\n",
        "    dice_mean=float(np.mean(dices)) if dices else float('nan'),\n",
        "    iou_mean=float(np.mean(ious)) if ious else float('nan'),\n",
        "    lat_median_ms=float(np.median(lat_ms)) if n else float('nan'),\n",
        "    lat_p90_ms=float(pct(lat_ms, 90)),\n",
        "    lat_p95_ms=float(pct(lat_ms, 95)),\n",
        "    lat_min_ms=float(np.min(lat_ms)) if n else float('nan'),\n",
        "    lat_max_ms=float(np.max(lat_ms)) if n else float('nan'),\n",
        "    wall_time_s=float(t_end - t_start),\n",
        "    fps=float(fps),\n",
        "    peak_ram_mb=float(max(ram_hist)/(1024*1024)) if ram_hist else float('nan'),\n",
        "    cpu_mean_pct=float(np.mean(cpu_hist)) if cpu_hist else float('nan'),\n",
        "    threshold=float(THRESH),\n",
        "    samples=int(NUM_SAMPLES - WARMUP),\n",
        "    threads=dict(\n",
        "        torch_num_threads=torch.get_num_threads(),\n",
        "        torch_num_interop=torch.get_num_interop_threads() if hasattr(torch, \"get_num_interop_threads\") else \"N/A\",\n",
        "        OMP_NUM_THREADS=os.getenv(\"OMP_NUM_THREADS\"),\n",
        "        MKL_NUM_THREADS=os.getenv(\"MKL_NUM_THREADS\"),\n",
        "    ),\n",
        "    ckpt=CKPT_PATH,\n",
        "    data=str(busi_file),\n",
        ")\n",
        "\n",
        "print(json.dumps(summary, indent=2))\n",
        "\n",
        "# ---- save artifacts ----\n",
        "outdir = Path(\"./cpu_eval_runs\"); outdir.mkdir(exist_ok=True, parents=True)\n",
        "stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "pd.DataFrame({\"idx\": list(range(n)), \"latency_ms\": lat_ms, \"dice\": dices, \"iou\": ious}).to_csv(outdir / f\"per_image_{stamp}.csv\", index=False)\n",
        "with open(outdir / f\"summary_{stamp}.json\",\"w\") as f: json.dump(summary, f, indent=2)\n",
        "print(\"Saved:\", outdir / f\"per_image_{stamp}.csv\", \"|\", outdir / f\"summary_{stamp}.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02TjETcyOl36",
        "outputId": "47d4e487-414e-460a-9647-85dd10cf0eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"dice_mean\": 0.6293409686141899,\n",
            "  \"iou_mean\": 0.5180267852453141,\n",
            "  \"lat_median_ms\": 717.4813509999467,\n",
            "  \"lat_p90_ms\": 883.691020999936,\n",
            "  \"lat_p95_ms\": 899.2539020000777,\n",
            "  \"lat_min_ms\": 692.3473820000936,\n",
            "  \"lat_max_ms\": 961.0881739999968,\n",
            "  \"wall_time_s\": 33.41650012899993,\n",
            "  \"fps\": 1.346640127669969,\n",
            "  \"peak_ram_mb\": 4210.1015625,\n",
            "  \"cpu_mean_pct\": 59.57777777777779,\n",
            "  \"threshold\": 0.5,\n",
            "  \"samples\": 45,\n",
            "  \"threads\": {\n",
            "    \"torch_num_threads\": 1,\n",
            "    \"torch_num_interop\": 1,\n",
            "    \"OMP_NUM_THREADS\": \"1\",\n",
            "    \"MKL_NUM_THREADS\": \"1\"\n",
            "  },\n",
            "  \"ckpt\": \"/content/drive/MyDrive/unetr_model_busi_IMG256_SEED42_2025-11-04_13-32-50_best.pt\",\n",
            "  \"data\": \"/content/data/MedSegBenchCache/busi_256.npz\"\n",
            "}\n",
            "Saved: cpu_eval_runs/per_image_20251104_165103.csv | cpu_eval_runs/summary_20251104_165103.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd; from pathlib import Path\n",
        "p = sorted(Path(\"cpu_eval_runs\").glob(\"per_image_*.csv\"))[-1]\n",
        "df = pd.read_csv(p)\n",
        "print(df.describe(percentiles=[.5,.9,.95]))\n",
        "print(\"Top 5 slowest:\\n\", df.sort_values(\"latency_ms\", ascending=False).head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAw3zscae5q3",
        "outputId": "1e22462d-0660-44b3-d15d-2dae27ae450e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             idx  latency_ms          dice           iou\n",
            "count  45.000000   45.000000  4.500000e+01  4.500000e+01\n",
            "mean   22.000000  742.264036  6.293410e-01  5.180268e-01\n",
            "std    13.133926   68.089516  2.947477e-01  2.834800e-01\n",
            "min     0.000000  692.347382  4.968203e-12  4.968203e-12\n",
            "50%    22.000000  717.481351  7.549119e-01  6.063120e-01\n",
            "90%    39.600000  883.691021  9.087899e-01  8.328336e-01\n",
            "95%    41.800000  899.253902  9.162268e-01  8.454083e-01\n",
            "max    44.000000  961.088174  9.529537e-01  9.101351e-01\n",
            "Top 5 slowest:\n",
            "     idx  latency_ms      dice       iou\n",
            "27   27  961.088174  0.842170  0.727369\n",
            "11   11  908.041226  0.754912  0.606312\n",
            "44   44  899.701846  0.873984  0.776174\n",
            "12   12  897.462126  0.841581  0.726491\n",
            "43   43  883.790197  0.460809  0.299384\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c258520b7c9496789895b147fa4173e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba0630698a0b45c6ba93017f15c622a2",
              "IPY_MODEL_7eb8fe78c46c40109b6da58c79a9c865",
              "IPY_MODEL_450fc233834b4d69bf71a795915aeb81"
            ],
            "layout": "IPY_MODEL_52d0d1c95136474384b8e53271d7685f"
          }
        },
        "ba0630698a0b45c6ba93017f15c622a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad6d4422e86f47748a5bbb63967654cb",
            "placeholder": "​",
            "style": "IPY_MODEL_a12de94ca39248acafb481c89a5d3332",
            "value": "model.safetensors: 100%"
          }
        },
        "7eb8fe78c46c40109b6da58c79a9c865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76e607155e5447e0a6c59aec49b09bdb",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d671d91ea945401f8adaec0376e03014",
            "value": 346284714
          }
        },
        "450fc233834b4d69bf71a795915aeb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f973bbb05f4d5699507b0f6fdf770d",
            "placeholder": "​",
            "style": "IPY_MODEL_8df1857eec64476585a28ccc7030f073",
            "value": " 346M/346M [00:05&lt;00:00, 54.0MB/s]"
          }
        },
        "52d0d1c95136474384b8e53271d7685f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6d4422e86f47748a5bbb63967654cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a12de94ca39248acafb481c89a5d3332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76e607155e5447e0a6c59aec49b09bdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d671d91ea945401f8adaec0376e03014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9f973bbb05f4d5699507b0f6fdf770d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df1857eec64476585a28ccc7030f073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}