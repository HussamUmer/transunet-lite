{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\n",
        "# Cell 1/9 — Run identifiers, paths, and folders\n",
        "# ------------------------------------------------------------\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- run knobs (same style as yours) ----\n",
        "DATASET    = \"busi\"\n",
        "IMAGE_SIZE = 256\n",
        "SEED       = 42\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS     = 10\n",
        "AMP_ON     = True\n",
        "MODEL_TAG  = \"TransUNetBaseline_model\"\n",
        "RUN_NAME   = f\"{MODEL_TAG}_{DATASET}_IMG{IMAGE_SIZE}_SEED{SEED}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
        "CONFIG_PATH = \"configs/example.yaml\"\n",
        "\n",
        "# ---- standard folders ----\n",
        "root = Path(\"/content/drive/MyDrive/TransUNetBaseline_model_busi_Test\")\n",
        "for p in [\"logs\", \"checkpoints\", \"figures\", \"runs\", \"summary\"]:\n",
        "    (root / p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "summary_txt_path  = root / \"summary\" / f\"{RUN_NAME}_env.txt\"\n",
        "summary_json_path = root / \"summary\" / f\"{RUN_NAME}_env.json\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihJQ62HiGoV9",
        "outputId": "9fc190d9-5a05-4fde-aa71-66f5d7c62814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 2/9 — Base imports & safe-import helper\n",
        "# ------------------------------------------------------------\n",
        "import os, sys, json, time, platform, importlib, random\n",
        "\n",
        "def try_import(name: str):\n",
        "    try:\n",
        "        mod = importlib.import_module(name)\n",
        "        ver = getattr(mod, \"__version__\", \"unknown\")\n",
        "        if name == \"PIL\": ver = getattr(mod, \"__version__\", ver)\n",
        "        if name == \"cv2\": ver = getattr(mod, \"__version__\", ver)\n",
        "        return mod, ver\n",
        "    except Exception as e:\n",
        "        return None, f\"NOT INSTALLED ({type(e).__name__})\"\n",
        "\n",
        "!pip -q install -U monai torchmetrics thop fvcore timm albumentations==1.4.4 psutil pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu1sollbGoeE",
        "outputId": "3c7866db-6a19-40bf-cd64-53645ec2adc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.4/150.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 3/9 — Import common stack (DL, data, viz, utils)\n",
        "# ------------------------------------------------------------\n",
        "# Core / data\n",
        "numpy, np_ver         = try_import(\"numpy\")\n",
        "pandas, pd_ver        = try_import(\"pandas\")\n",
        "\n",
        "# Deep Learning\n",
        "torch, torch_ver      = try_import(\"torch\")\n",
        "torchvision, tv_ver   = try_import(\"torchvision\")\n",
        "timm, timm_ver        = try_import(\"timm\")\n",
        "monai, monai_ver      = try_import(\"monai\")\n",
        "torchmetrics, tm_ver  = try_import(\"torchmetrics\")\n",
        "\n",
        "# Aug / IO / Viz\n",
        "albumentations, alb_ver = try_import(\"albumentations\")\n",
        "cv2, cv2_ver            = try_import(\"cv2\")\n",
        "PIL, pil_ver            = try_import(\"PIL\")\n",
        "matplotlib, mpl_ver     = try_import(\"matplotlib\")\n",
        "\n",
        "# Utils\n",
        "yaml, yaml_ver       = try_import(\"yaml\")\n",
        "sklearn, sk_ver      = try_import(\"sklearn\")\n",
        "psutil, psutil_ver   = try_import(\"psutil\")\n",
        "\n",
        "# Profiling\n",
        "thop, thop_ver       = try_import(\"thop\")\n",
        "fvcore, fvcore_ver   = try_import(\"fvcore\")\n"
      ],
      "metadata": {
        "id": "f5VnECLKGohb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 4/9 — Device, CUDA/cuDNN, and GPU VRAM discovery\n",
        "# ------------------------------------------------------------\n",
        "device         = \"cpu\"\n",
        "gpu_name       = \"N/A\"\n",
        "total_vram_mb  = \"N/A\"\n",
        "total_vram_gb  = \"N/A\"\n",
        "cuda_version   = \"N/A\"\n",
        "cudnn_version  = \"N/A\"\n",
        "\n",
        "if torch is not None:\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    device = \"cuda\" if cuda_available else \"cpu\"\n",
        "    cuda_version = getattr(torch.version, \"cuda\", \"N/A\")\n",
        "    try:\n",
        "        cudnn_version = str(torch.backends.cudnn.version()) if torch.backends.cudnn.is_available() else \"N/A\"\n",
        "    except Exception:\n",
        "        cudnn_version = \"N/A\"\n",
        "    if cuda_available:\n",
        "        try:\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            props = torch.cuda.get_device_properties(0)\n",
        "            total_vram_bytes = getattr(props, \"total_memory\", 0)\n",
        "            total_vram_mb = round(total_vram_bytes / (1024**2), 2)\n",
        "            total_vram_gb = round(total_vram_bytes / (1024**3), 2)\n",
        "        except Exception:\n",
        "            gpu_name = \"Unknown (query failed)\"\n",
        "            total_vram_mb = \"Unknown\"\n",
        "            total_vram_gb = \"Unknown\"\n"
      ],
      "metadata": {
        "id": "QVMvrGY_Gok0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 5/9 — Reproducibility (seeds + deterministic flags)\n",
        "# ------------------------------------------------------------\n",
        "random.seed(SEED)\n",
        "if numpy:\n",
        "    numpy.random.seed(SEED)\n",
        "\n",
        "if torch is not None:\n",
        "    torch.manual_seed(SEED)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(SEED)\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    except Exception:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "wqa1EkgIGooP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 6/9 — Assemble environment snapshot dict\n",
        "# ------------------------------------------------------------\n",
        "env_info = {\n",
        "    \"run\": {\n",
        "        \"run_name\": RUN_NAME,\n",
        "        \"datetime\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"dataset\": DATASET,\n",
        "        \"image_size\": IMAGE_SIZE,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"amp_on\": AMP_ON,\n",
        "        \"seed\": SEED,\n",
        "        \"config_path\": CONFIG_PATH if Path(CONFIG_PATH).exists() else f\"{CONFIG_PATH} (not found)\",\n",
        "    },\n",
        "    \"system\": {\n",
        "        \"python\": sys.version.split()[0],\n",
        "        \"platform\": platform.platform(),\n",
        "        \"device\": device,\n",
        "        \"gpu_name\": gpu_name,\n",
        "        \"gpu_total_vram_mb\": total_vram_mb,\n",
        "        \"gpu_total_vram_gb\": total_vram_gb,\n",
        "        \"cuda_version\": cuda_version,\n",
        "        \"cudnn_version\": cudnn_version,\n",
        "    },\n",
        "    \"libraries\": {\n",
        "        \"torch\": torch_ver,\n",
        "        \"torchvision\": tv_ver,\n",
        "        \"timm\": timm_ver,\n",
        "        \"monai\": monai_ver,\n",
        "        \"torchmetrics\": tm_ver,\n",
        "        \"numpy\": np_ver,\n",
        "        \"pandas\": pd_ver,\n",
        "        \"albumentations\": alb_ver,\n",
        "        \"opencv-python (cv2)\": cv2_ver,\n",
        "        \"Pillow (PIL)\": pil_ver,\n",
        "        \"matplotlib\": mpl_ver,\n",
        "        \"pyyaml\": yaml_ver,\n",
        "        \"scikit-learn\": sk_ver,\n",
        "        \"psutil\": psutil_ver,\n",
        "        \"thop\": thop_ver,\n",
        "        \"fvcore\": fvcore_ver,\n",
        "    },\n",
        "}\n"
      ],
      "metadata": {
        "id": "MGEigRc2Gorp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 7/9 — Pretty print snapshot to console\n",
        "# ------------------------------------------------------------\n",
        "border = \"=\" * 70\n",
        "print(border)\n",
        "print(\"STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\")\n",
        "print(border)\n",
        "print(f\"Run Name      : {env_info['run']['run_name']}\")\n",
        "print(f\"Date/Time     : {env_info['run']['datetime']}\")\n",
        "print(f\"Dataset       : {env_info['run']['dataset']}\")\n",
        "print(f\"Image Size    : {env_info['run']['image_size']}\")\n",
        "print(f\"Batch Size    : {env_info['run']['batch_size']}\")\n",
        "print(f\"Epochs        : {env_info['run']['epochs']}\")\n",
        "print(f\"AMP (mixed precision): {env_info['run']['amp_on']}\")\n",
        "print(f\"Seed          : {env_info['run']['seed']}\")\n",
        "print(f\"Config Path   : {env_info['run']['config_path']}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Python        : {env_info['system']['python']}\")\n",
        "print(f\"Platform      : {env_info['system']['platform']}\")\n",
        "print(f\"Device        : {env_info['system']['device']}\")\n",
        "print(f\"GPU           : {env_info['system']['gpu_name']}\")\n",
        "print(f\"GPU VRAM      : {env_info['system']['gpu_total_vram_mb']} MB ({env_info['system']['gpu_total_vram_gb']} GB)\")\n",
        "print(f\"CUDA / cuDNN  : {env_info['system']['cuda_version']} / {env_info['system']['cudnn_version']}\")\n",
        "print(\"-\" * 70)\n",
        "print(\"Libraries:\")\n",
        "for lib, ver in env_info[\"libraries\"].items():\n",
        "    print(f\"  - {lib:<24} {ver}\")\n",
        "print(border)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RCdGFiAGou1",
        "outputId": "4dd80d07-598a-4278-868f-0dc409d9fe3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\n",
            "======================================================================\n",
            "Run Name      : TransUNetBaseline_model_busi_IMG256_SEED42_2025-11-04_04-03-15\n",
            "Date/Time     : 2025-11-04T04:05:01\n",
            "Dataset       : busi\n",
            "Image Size    : 256\n",
            "Batch Size    : 8\n",
            "Epochs        : 10\n",
            "AMP (mixed precision): True\n",
            "Seed          : 42\n",
            "Config Path   : configs/example.yaml (not found)\n",
            "----------------------------------------------------------------------\n",
            "Python        : 3.12.12\n",
            "Platform      : Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "Device        : cpu\n",
            "GPU           : N/A\n",
            "GPU VRAM      : N/A MB (N/A GB)\n",
            "CUDA / cuDNN  : 12.6 / 91002\n",
            "----------------------------------------------------------------------\n",
            "Libraries:\n",
            "  - torch                    2.8.0+cu126\n",
            "  - torchvision              0.23.0+cu126\n",
            "  - timm                     1.0.21\n",
            "  - monai                    1.5.1\n",
            "  - torchmetrics             1.8.2\n",
            "  - numpy                    2.0.2\n",
            "  - pandas                   2.3.3\n",
            "  - albumentations           1.4.4\n",
            "  - opencv-python (cv2)      4.12.0\n",
            "  - Pillow (PIL)             11.3.0\n",
            "  - matplotlib               3.10.0\n",
            "  - pyyaml                   6.0.3\n",
            "  - scikit-learn             1.6.1\n",
            "  - psutil                   5.9.5\n",
            "  - thop                     0.1.1\n",
            "  - fvcore                   0.1.5.post20221221\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 8/9 — Save TXT + JSON environment snapshots\n",
        "# ------------------------------------------------------------\n",
        "with open(summary_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(border + \"\\n\")\n",
        "    f.write(\"STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\\n\")\n",
        "    f.write(border + \"\\n\")\n",
        "    for section, payload in env_info.items():\n",
        "        f.write(f\"[{section.UPPER()}]\\n\" if hasattr(section, 'UPPER') else f\"[{section.upper()}]\\n\")\n",
        "        if isinstance(payload, dict):\n",
        "            for k, v in payload.items():\n",
        "                if isinstance(v, dict):\n",
        "                    f.write(f\"  {k}:\\n\")\n",
        "                    for kk, vv in v.items():\n",
        "                        f.write(f\"    - {kk}: {vv}\\n\")\n",
        "                else:\n",
        "                    f.write(f\"  - {k}: {v}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "with open(summary_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(env_info, f, indent=2)\n",
        "\n",
        "print(f\"Saved environment snapshots to:\\n  • {summary_txt_path}\\n  • {summary_json_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeaNK1igGoyH",
        "outputId": "44007812-e241-4f87-aba0-5dca345309dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved environment snapshots to:\n",
            "  • /content/drive/MyDrive/TransUNetBaseline_model_busi_Test/summary/TransUNetBaseline_model_busi_IMG256_SEED42_2025-11-04_04-03-15_env.txt\n",
            "  • /content/drive/MyDrive/TransUNetBaseline_model_busi_Test/summary/TransUNetBaseline_model_busi_IMG256_SEED42_2025-11-04_04-03-15_env.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 9/9 — Initialize per-run CSV log header\n",
        "# ------------------------------------------------------------\n",
        "csv_path = root / \"logs\" / f\"{RUN_NAME}.csv\"\n",
        "if not csv_path.exists():\n",
        "    with open(csv_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"epoch,lr,train_loss,val_loss,train_dice,val_dice,train_iou,val_iou,epoch_time\\n\")\n",
        "print(f\"Initialized log CSV (if new): {csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4pE758CGo1K",
        "outputId": "cddf0f10-00e3-462a-b84b-83fd50c3bd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized log CSV (if new): /content/drive/MyDrive/TransUNetBaseline_model_busi_Test/logs/TransUNetBaseline_model_busi_IMG256_SEED42_2025-11-04_04-03-15.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD (BUSI, 256px) → MedSegBench cache\n",
        "# Cell 1/6 — Setup: cache dir, env var, and size\n",
        "# ------------------------------------------------------------\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "SIZE = 256\n",
        "cache_root = Path(\"/content/data/MedSegBenchCache\")\n",
        "cache_root.mkdir(parents=True, exist_ok=True)\n",
        "os.environ[\"MEDSEGBENCH_DIR\"] = str(cache_root)\n",
        "\n",
        "print(f\"[INFO] MEDSEGBENCH_DIR = {cache_root.resolve()}\")\n",
        "print(f\"[INFO] Target resolution = {SIZE}px\")\n",
        "\n",
        "!pip -q install medsegbench\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBl3jA_rMHZx",
        "outputId": "7257696d-7fd2-4a05-812e-b4ab7ad2d639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] MEDSEGBENCH_DIR = /content/data/MedSegBenchCache\n",
            "[INFO] Target resolution = 256px\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 2/6 — Dataset source details (Zenodo v1 record)\n",
        "# ------------------------------------------------------------\n",
        "target_name = f\"busi_{SIZE}.npz\"\n",
        "target_path = cache_root / target_name\n",
        "\n",
        "url = f\"https://zenodo.org/records/13358372/files/{target_name}?download=1\"\n",
        "\n",
        "# ✅ Put your BUSI_256 MD5 here (you mentioned you have it)\n",
        "expected_md5 = \"198aea70968b71adf593b32c41a6e995\"\n",
        "\n",
        "print(f\"[INFO] Target file  : {target_name}\")\n",
        "print(f\"[INFO] Download URL : {url}\")\n",
        "print(f\"[INFO] Expected MD5 : {expected_md5}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6EcLSkJMHWk",
        "outputId": "f73375bb-ebb8-4053-f034-46254444152c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Target file  : busi_256.npz\n",
            "[INFO] Download URL : https://zenodo.org/records/13358372/files/busi_256.npz?download=1\n",
            "[INFO] Expected MD5 : 198aea70968b71adf593b32c41a6e995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 3/6 — Helpers (md5sum + download runners)\n",
        "# ------------------------------------------------------------\n",
        "import hashlib, subprocess, shutil\n",
        "\n",
        "def md5sum(path: Path) -> str:\n",
        "    h = hashlib.md5()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def download_file(url: str, out_path: Path) -> None:\n",
        "    curl = shutil.which(\"curl\")\n",
        "    if curl:\n",
        "        print(\"[INFO] Downloading with curl ...\")\n",
        "        subprocess.run([curl, \"-L\", \"-f\", url, \"-o\", str(out_path)], check=True)\n",
        "        return\n",
        "    wget = shutil.which(\"wget\")\n",
        "    if wget:\n",
        "        print(\"[INFO] curl not found; downloading with wget ...\")\n",
        "        subprocess.run([wget, \"-O\", str(out_path), url], check=True)\n",
        "        return\n",
        "    raise RuntimeError(\"Neither curl nor wget is available on PATH.\")\n"
      ],
      "metadata": {
        "id": "A8jRgZpiMHTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 4/6 — Download (idempotent)\n",
        "# ------------------------------------------------------------\n",
        "if not target_path.exists():\n",
        "    print(f\"[INFO] Downloading to {target_path} ...\")\n",
        "    try:\n",
        "        download_file(url, target_path)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        raise RuntimeError(f\"Downloader failed with return code {e.returncode}.\") from e\n",
        "else:\n",
        "    print(f\"[INFO] File already present: {target_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LhTqJv9MHQZ",
        "outputId": "653a2798-9792-4537-a7b1-5c9bba913594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Downloading to /content/data/MedSegBenchCache/busi_256.npz ...\n",
            "[INFO] Downloading with curl ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 5/6 — Integrity check (MD5)\n",
        "# ------------------------------------------------------------\n",
        "got = md5sum(target_path)\n",
        "print(f\"[INFO] MD5 (computed): {got}\")\n",
        "if expected_md5 and got != expected_md5:\n",
        "    raise RuntimeError(\n",
        "        f\"MD5 mismatch for {target_name}. Expected {expected_md5}, got {got}.\\n\"\n",
        "        \"Delete the file and rerun this step to redownload.\"\n",
        "    )\n",
        "print(f\"✅ Download + MD5 OK → {target_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gJTKINBMHNS",
        "outputId": "5ec3862b-a84f-4a0e-c96a-a8188f591908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] MD5 (computed): 198aea70968b71adf593b32c41a6e995\n",
            "✅ Download + MD5 OK → /content/data/MedSegBenchCache/busi_256.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 6/6 — Ready message\n",
        "# ------------------------------------------------------------\n",
        "print(\"[READY] busi (256px) cached in MEDSEGBENCH_DIR.\")\n",
        "print(\"[NEXT] STEP 2: Reproducibility & Config Lock; STEP 3: load predefined splits and print counts.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSfXw79FMVUz",
        "outputId": "52c0c4c5-c30f-4219-9f34-cd0d49071898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[READY] busi (256px) cached in MEDSEGBENCH_DIR.\n",
            "[NEXT] STEP 2: Reproducibility & Config Lock; STEP 3: load predefined splits and print counts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 1/5 — Resolve run knobs, paths, and dataset file\n",
        "# ------------------------------------------------------------\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "try: root\n",
        "except NameError: root = Path(\".\")\n",
        "\n",
        "DATASET    = globals().get(\"DATASET\", \"busi\")\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", 256))\n",
        "SEED       = int(globals().get(\"SEED\", 42))\n",
        "BATCH_SIZE = int(globals().get(\"BATCH_SIZE\", 8))\n",
        "EPOCHS     = int(globals().get(\"EPOCHS\", 10))\n",
        "AMP_ON     = bool(globals().get(\"AMP_ON\", True))\n",
        "MODEL_TAG  = globals().get(\"MODEL_TAG\", \"TransUNetLiteTiny_model\")\n",
        "RUN_NAME   = globals().get(\"RUN_NAME\", f\"{MODEL_TAG}_{DATASET}_IMG{IMAGE_SIZE}_SEED{SEED}\")\n",
        "CONFIG_PATH = globals().get(\"CONFIG_PATH\", \"configs/example.yaml\")\n",
        "\n",
        "RESOLUTION = int(globals().get(\"SIZE\", IMAGE_SIZE))\n",
        "\n",
        "msb_dir = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "busi_file = msb_dir / f\"busi_{RESOLUTION}.npz\"\n",
        "\n",
        "print(f\"[INFO] Artifacts root        : {root.resolve()}\")\n",
        "print(f\"[INFO] MEDSEGBENCH_DIR       : {msb_dir.resolve()}\")\n",
        "print(f\"[INFO] Expected busi file    : {busi_file}\")\n",
        "print(f\"[INFO] Run                   : {RUN_NAME}\")\n",
        "print(f\"[INFO] Model tag             : {MODEL_TAG}\")\n",
        "print(f\"[INFO] Seed / ImageSize      : {SEED} / {IMAGE_SIZE}\")\n",
        "print(f\"[INFO] Batch / Epochs / AMP  : {BATCH_SIZE} / {EPOCHS} / {AMP_ON}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyrNxgwAMVRp",
        "outputId": "2c615706-1c3f-41f1-d3b1-02241d48794e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Artifacts root        : /content/drive/MyDrive/TransUNetBaseline_model_busi_Test\n",
            "[INFO] MEDSEGBENCH_DIR       : /content/data/MedSegBenchCache\n",
            "[INFO] Expected busi file    : /content/data/MedSegBenchCache/busi_256.npz\n",
            "[INFO] Run                   : TransUNetBaseline_model_busi_IMG256_SEED42_2025-11-04_04-03-15\n",
            "[INFO] Model tag             : TransUNetBaseline_model\n",
            "[INFO] Seed / ImageSize      : 42 / 256\n",
            "[INFO] Batch / Epochs / AMP  : 8 / 10 / True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 2/5 — Seed + deterministic flags (re-assert)\n",
        "# ------------------------------------------------------------\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "    try: torch.use_deterministic_algorithms(True)\n",
        "    except Exception: pass\n",
        "    try:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    except Exception: pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "print(f\"[OK] Seeds set and deterministic flags applied (seed={SEED}).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH7NZHhtMVOy",
        "outputId": "a872e832-3771-4f81-fdea-0b5c20f73b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Seeds set and deterministic flags applied (seed=42).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 3/5 — Build default config (if missing) and load it\n",
        "# ------------------------------------------------------------\n",
        "import yaml\n",
        "(root / \"configs\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "cfg_path = Path(CONFIG_PATH)\n",
        "if not cfg_path.exists():\n",
        "    cfg_path = root / \"configs\" / \"default_busi.yaml\"\n",
        "\n",
        "default_cfg = {\n",
        "    \"run\": {\"run_name\": RUN_NAME, \"seed\": SEED, \"amp_on\": AMP_ON},\n",
        "    \"data\": {\"dataset\": DATASET, \"resolution\": RESOLUTION, \"medsegbench_dir\": str(msb_dir), \"predefined_splits\": True},\n",
        "    \"train\": {\n",
        "        \"image_size\": IMAGE_SIZE, \"batch_size\": BATCH_SIZE, \"epochs\": EPOCHS, \"num_workers\": 4,\n",
        "        \"optimizer\": {\"name\": \"adamw\", \"lr\": 3e-4, \"weight_decay\": 1e-4},\n",
        "        \"scheduler\": {\"name\": \"cosine\", \"warmup_epochs\": 5},\n",
        "        \"early_stopping\": {\"monitor\": \"val_dice\", \"patience\": 20},\n",
        "        \"mixed_precision\": AMP_ON\n",
        "    },\n",
        "    \"augment\": {\n",
        "        \"geometric\": {\"flip\": True, \"rotate\": True, \"scale\": True, \"elastic\": False},\n",
        "        \"appearance\": {\"brightness_contrast\": True, \"blur_noise\": True},\n",
        "        \"probabilities\": {\"flip\": 0.5, \"rotate\": 0.3, \"scale\": 0.3, \"brightness_contrast\": 0.3, \"blur_noise\": 0.2}\n",
        "    },\n",
        "    \"loss\": {\"primary\": \"dice_bce\", \"weights\": {\"dice\": 0.7, \"bce\": 0.3}},\n",
        "    \"metrics\": {\"threshold\": 0.5, \"report\": [\"dice\", \"iou\"]},\n",
        "    \"logging\": {\n",
        "        \"artifacts_root\": str(root.resolve()),\n",
        "        \"print_per_epoch_fields\": [\"epoch\",\"lr\",\"train_loss\",\"val_loss\",\"train_dice\",\"val_dice\",\"train_iou\",\"val_iou\",\"epoch_time\"],\n",
        "        \"save_csv_per_epoch\": True,\n",
        "        \"save_best_by\": \"val_dice\"\n",
        "    },\n",
        "    \"model\": {\"name\": MODEL_TAG, \"scale\": \"auto\", \"params\": {}}\n",
        "}\n",
        "\n",
        "if not Path(CONFIG_PATH).exists():\n",
        "    with open(cfg_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        yaml.safe_dump(default_cfg, f, sort_keys=False)\n",
        "    print(f\"[INFO] Created default config at: {cfg_path.resolve()}\")\n",
        "else:\n",
        "    cfg_path = Path(CONFIG_PATH)\n",
        "\n",
        "with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "print(f\"[OK] Loaded config from: {cfg_path.resolve()}\")\n",
        "print(f\"[INFO] Config run_name: {cfg['run'].get('run_name')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6rnSmDxMeTZ",
        "outputId": "9ff58d7e-4776-4f48-b35d-39ab46ce0d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Created default config at: /content/drive/MyDrive/TransUNetBaseline_model_busi_Test/configs/default_busi.yaml\n",
            "[OK] Loaded config from: /content/drive/MyDrive/TransUNetBaseline_model_busi_Test/configs/default_busi.yaml\n",
            "[INFO] Config run_name: TransUNetBaseline_model_busi_IMG256_SEED42_2025-11-04_04-03-15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 4/5 — Sanity checks: dataset presence & key fields\n",
        "# ------------------------------------------------------------\n",
        "problems = []\n",
        "\n",
        "if not busi_file.exists():\n",
        "    problems.append(f\"Missing dataset cache file: {busi_file}\")\n",
        "\n",
        "required_keys = [\n",
        "    (\"run\", \"seed\"), (\"data\", \"medsegbench_dir\"), (\"data\", \"resolution\"),\n",
        "    (\"train\", \"batch_size\"), (\"train\", \"epochs\"),\n",
        "    (\"loss\", \"primary\"), (\"metrics\", \"threshold\"), (\"model\", \"name\"),\n",
        "]\n",
        "for sect, key in required_keys:\n",
        "    if sect not in cfg or key not in cfg[sect]:\n",
        "        problems.append(f\"Config missing: {sect}.{key}\")\n",
        "\n",
        "if problems:\n",
        "    print(\"[WARN] Sanity check issues:\")\n",
        "    for p in problems: print(\" -\", p)\n",
        "else:\n",
        "    print(\"[OK] Dataset file present and config has required keys.\")\n",
        "\n",
        "print(f\"[ECHO] Using dataset cache: {busi_file}\")\n",
        "print(f\"[ECHO] MEDSEGBENCH_DIR   : {msb_dir}\")\n",
        "print(f\"[ECHO] Model name        : {cfg['model']['name']}\")\n",
        "print(f\"[ECHO] Loss              : {cfg['loss']['primary']} (weights={cfg['loss'].get('weights')})\")\n",
        "print(f\"[ECHO] Metrics threshold : {cfg['metrics']['threshold']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-0MG3hAMeQO",
        "outputId": "190398ca-5139-4b2f-f556-12c51255c96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Dataset file present and config has required keys.\n",
            "[ECHO] Using dataset cache: /content/data/MedSegBenchCache/busi_256.npz\n",
            "[ECHO] MEDSEGBENCH_DIR   : /content/data/MedSegBenchCache\n",
            "[ECHO] Model name        : TransUNetBaseline_model\n",
            "[ECHO] Loss              : dice_bce (weights={'dice': 0.7, 'bce': 0.3})\n",
            "[ECHO] Metrics threshold : 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 5/5 — Snapshot config for this run\n",
        "# ------------------------------------------------------------\n",
        "(root / \"summary\").mkdir(parents=True, exist_ok=True)\n",
        "cfg_snapshot = root / \"summary\" / f\"{RUN_NAME}_config.yaml\"\n",
        "with open(cfg_snapshot, \"w\", encoding=\"utf-8\") as f:\n",
        "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
        "\n",
        "print(f\"[OK] Saved config snapshot to: {cfg_snapshot.resolve()}\")\n",
        "print(\"[NEXT] STEP 3 will load MedSegBench predefined splits and print sample counts per set (no re-splitting).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_7dS00IMeNp",
        "outputId": "1f3fd2b6-8547-484b-f0e2-5f65d2e6bb95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved config snapshot to: /content/drive/MyDrive/TransUNetBaseline_model_busi_Test/summary/TransUNetBaseline_model_busi_IMG256_SEED42_2025-11-04_04-03-15_config.yaml\n",
            "[NEXT] STEP 3 will load MedSegBench predefined splits and print sample counts per set (no re-splitting).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 1/4 — Resolve paths and open the cached NPZ\n",
        "# ------------------------------------------------------------\n",
        "import numpy as np\n",
        "\n",
        "msb_dir = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "RESOLUTION = int(globals().get(\"RESOLUTION\", globals().get(\"SIZE\", 256)))\n",
        "busi_file = msb_dir / f\"busi_{RESOLUTION}.npz\"\n",
        "assert busi_file.exists(), f\"Expected dataset file not found: {busi_file}\"\n",
        "\n",
        "npz = np.load(busi_file, allow_pickle=True)\n",
        "keys = list(npz.keys())\n",
        "print(f\"[INFO] Loaded: {busi_file}\")\n",
        "print(f\"[ECHO] MEDSEGBENCH_DIR: {msb_dir.resolve()}\")\n",
        "print(f\"[INFO] NPZ keys ({len(keys)}): {keys[:12]}{'...' if len(keys)>12 else ''}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OWsTb-XMeKx",
        "outputId": "975e4b0d-a576-4579-8395-34d0bbc0c63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded: /content/data/MedSegBenchCache/busi_256.npz\n",
            "[ECHO] MEDSEGBENCH_DIR: /content/data/MedSegBenchCache\n",
            "[INFO] NPZ keys (18): ['train_images_C1', 'train_label_C1', 'train_images_C2', 'train_label_C2', 'test_images_C1', 'test_label_C1', 'test_images_C2', 'test_label_C2', 'val_images_C1', 'val_label_C1', 'val_images_C2', 'val_label_C2']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 2/4 — Infer split format (supports *_label/_labels)\n",
        "# ------------------------------------------------------------\n",
        "def _as_list(x):\n",
        "    if isinstance(x, np.ndarray): x = x.tolist()\n",
        "    return list(x) if isinstance(x, (list, tuple)) else [x]\n",
        "\n",
        "def infer_splits(npz_obj):\n",
        "    k = set(npz_obj.keys())\n",
        "\n",
        "    # Case A: per-split arrays (preferred)\n",
        "    def _find_lbl_key(split):\n",
        "        for suffix in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "            cand = f\"{split}_{suffix}\"\n",
        "            if cand in k: return cand\n",
        "        return None\n",
        "\n",
        "    have_all = True\n",
        "    meta = {}\n",
        "    for s in (\"train\",\"val\",\"test\"):\n",
        "        ik = f\"{s}_images\"; lk = _find_lbl_key(s)\n",
        "        if ik in k and lk in k and len(npz_obj[ik]) == len(npz_obj[lk]):\n",
        "            meta[s] = {\"n\": len(npz_obj[ik]), \"img_key\": ik, \"lbl_key\": lk}\n",
        "        else:\n",
        "            have_all = False; break\n",
        "    if have_all:\n",
        "        counts = {s: meta[s][\"n\"] for s in meta}\n",
        "        idx    = {s: list(range(meta[s][\"n\"])) for s in meta}\n",
        "        return counts, idx, \"A(images+labels)\"\n",
        "\n",
        "    # Case B: global arrays + explicit indices\n",
        "    for tri, vai, tei in [(\"train_idx\",\"val_idx\",\"test_idx\"),\n",
        "                          (\"train_indices\",\"val_indices\",\"test_indices\"),\n",
        "                          (\"split_train\",\"split_val\",\"split_test\")]:\n",
        "        if tri in k and vai in k and tei in k:\n",
        "            tr, va, te = _as_list(npz_obj[tri]), _as_list(npz_obj[vai]), _as_list(npz_obj[tei])\n",
        "            counts = {\"train\": len(tr), \"val\": len(va), \"test\": len(te)}\n",
        "            idx    = {\"train\": tr, \"val\": va, \"test\": te}\n",
        "            return counts, idx, \"B(indices)\"\n",
        "\n",
        "    raise RuntimeError(\"Could not infer predefined splits (need per-split arrays or *_idx lists).\")\n",
        "\n",
        "counts, split_idx, pattern = infer_splits(npz)\n",
        "print(f\"[OK] Split pattern detected: Case {pattern}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR2jkJQdMeH6",
        "outputId": "a3e38efe-24ef-4a25-e5b4-3bf33d4b317b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Split pattern detected: Case A(images+labels)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS (SPEED-UP, OPTIONAL)\n",
        "# Cell 2.5/4 — Materialize arrays to RAM and rebind `npz`\n",
        "# ------------------------------------------------------------\n",
        "npz_ram = {}\n",
        "for k in keys:\n",
        "    obj = npz[k]\n",
        "    try: npz_ram[k] = obj[:] if isinstance(obj, np.ndarray) else obj\n",
        "    except Exception: npz_ram[k] = obj\n",
        "\n",
        "try: npz.close()\n",
        "except Exception: pass\n",
        "npz = npz_ram\n",
        "\n",
        "def _shape(x): return getattr(x, \"shape\", None)\n",
        "print(\"[SPEED] NPZ materialized to RAM. Example shapes:\")\n",
        "for probe in [\"train_images\",\"train_label\",\"train_masks\",\"val_images\",\"val_label\",\"test_images\",\"test_label\"]:\n",
        "    if probe in npz:\n",
        "        print(f\"  • {probe}: {_shape(npz[probe])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwR2CDMlNEWg",
        "outputId": "5466be14-12cc-4ff2-f779-2869e6f93c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SPEED] NPZ materialized to RAM. Example shapes:\n",
            "  • train_images: (452, 256, 256)\n",
            "  • train_label: (452, 256, 256)\n",
            "  • val_images: (64, 256, 256)\n",
            "  • val_label: (64, 256, 256)\n",
            "  • test_images: (131, 256, 256)\n",
            "  • test_label: (131, 256, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 3/4 — Print counts per set\n",
        "# ------------------------------------------------------------\n",
        "print(\"[COUNTS] Samples per split (predefined by MedSegBench)\")\n",
        "print(f\"  • Train : {counts['train']}\")\n",
        "print(f\"  • Val   : {counts['val']}\")\n",
        "print(f\"  • Test  : {counts['test']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilq_e8DpNET1",
        "outputId": "ef18d163-fd0b-4af4-feaa-47c04f4549f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[COUNTS] Samples per split (predefined by MedSegBench)\n",
            "  • Train : 452\n",
            "  • Val   : 64\n",
            "  • Test  : 131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 4/4 — Save IDs to disk for reproducibility\n",
        "# ------------------------------------------------------------\n",
        "summary_dir = Path(globals().get(\"root\", Path(\".\"))) / \"summary\"\n",
        "summary_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def write_list(path: Path, arr):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for x in arr: f.write(f\"{x}\\n\")\n",
        "\n",
        "train_ids_path = summary_dir / f\"busi_{RESOLUTION}_train_ids.txt\"\n",
        "val_ids_path   = summary_dir / f\"busi_{RESOLUTION}_val_ids.txt\"\n",
        "test_ids_path  = summary_dir / f\"busi_{RESOLUTION}_test_ids.txt\"\n",
        "\n",
        "write_list(train_ids_path, split_idx[\"train\"])\n",
        "write_list(val_ids_path,   split_idx[\"val\"])\n",
        "write_list(test_ids_path,  split_idx[\"test\"])\n",
        "\n",
        "print(\"[OK] Saved split ID lists:\")\n",
        "print(f\"  • {train_ids_path}\")\n",
        "print(f\"  • {val_ids_path}\")\n",
        "print(f\"  • {test_ids_path}\")\n",
        "print(\"[NEXT] STEP 4 will cover preprocessing pipeline (resize/normalize) and identical augmentations.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYL96afWNERC",
        "outputId": "28461e06-ce9f-465c-ead6-db87519b3ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved split ID lists:\n",
            "  • /content/drive/MyDrive/TransUNetBaseline_model_busi_Test/summary/busi_256_train_ids.txt\n",
            "  • /content/drive/MyDrive/TransUNetBaseline_model_busi_Test/summary/busi_256_val_ids.txt\n",
            "  • /content/drive/MyDrive/TransUNetBaseline_model_busi_Test/summary/busi_256_test_ids.txt\n",
            "[NEXT] STEP 4 will cover preprocessing pipeline (resize/normalize) and identical augmentations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS (IDENTICAL POLICY)\n",
        "# Cell 1/5 — Imports, constants, and NPZ reload\n",
        "# ------------------------------------------------------------\n",
        "import numpy as np, torch\n",
        "from pathlib import Path\n",
        "\n",
        "RESOLUTION = int(globals().get(\"RESOLUTION\", globals().get(\"SIZE\", 256)))\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", RESOLUTION))\n",
        "BATCH_SIZE = int(globals().get(\"BATCH_SIZE\", 8))\n",
        "\n",
        "NORM_MEAN = (0.485, 0.456, 0.406)\n",
        "NORM_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "msb_dir   = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "busi_file = msb_dir / f\"busi_{RESOLUTION}.npz\"\n",
        "assert busi_file.exists(), f\"Expected dataset file not found: {busi_file}\"\n",
        "\n",
        "npz_l = np.load(busi_file, allow_pickle=True)\n",
        "\n",
        "def _as_list(x):\n",
        "    if isinstance(x, np.ndarray): x = x.tolist()\n",
        "    return list(x) if isinstance(x, (list, tuple)) else [x]\n",
        "\n",
        "def _infer_splits(npz_obj):\n",
        "    k = set(npz_obj.keys())\n",
        "    def _find_lbl_key(split):\n",
        "        for suffix in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "            cand = f\"{split}_{suffix}\"\n",
        "            if cand in k: return cand\n",
        "        return None\n",
        "    have_all = True\n",
        "    meta = {}\n",
        "    for s in (\"train\",\"val\",\"test\"):\n",
        "        ik = f\"{s}_images\"; lk = _find_lbl_key(s)\n",
        "        if ik in k and lk in k:\n",
        "            n = len(npz_obj[ik])\n",
        "            if n != len(npz_obj[lk]): raise RuntimeError(f\"{s}: images != labels length\")\n",
        "            meta[s] = {\"n\": n, \"img_key\": ik, \"lbl_key\": lk}\n",
        "        else:\n",
        "            have_all = False; break\n",
        "    if have_all:\n",
        "        return {s: meta[s][\"n\"] for s in meta}, {s: list(range(meta[s][\"n\"])) for s in meta}\n",
        "    for tri, vai, tei in [(\"train_idx\",\"val_idx\",\"test_idx\"),\n",
        "                          (\"train_indices\",\"val_indices\",\"test_indices\"),\n",
        "                          (\"split_train\",\"split_val\",\"split_test\")]:\n",
        "        if tri in k and vai in k and tei in k:\n",
        "            tr = _as_list(npz_obj[tri]); va = _as_list(npz_obj[vai]); te = _as_list(npz_obj[tei])\n",
        "            return {\"train\": len(tr), \"val\": len(va), \"test\": len(te)}, {\"train\": tr, \"val\": va, \"test\": te}\n",
        "    raise RuntimeError(\"Could not re-infer splits; ensure STEP 3 ran successfully.\")\n",
        "\n",
        "if \"counts\" in globals() and \"split_idx\" in globals():\n",
        "    _counts, _split_idx = counts, split_idx\n",
        "else:\n",
        "    _counts, _split_idx = _infer_splits(npz_l)\n",
        "\n",
        "print(f\"[INFO] Using NPZ: {busi_file}\")\n",
        "print(f\"[INFO] Image size policy: RESOLUTION={RESOLUTION} → NETWORK INPUT={IMAGE_SIZE}\")\n",
        "print(f\"[COUNTS] train={_counts['train']}  val={_counts['val']}  test={_counts['test']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCUg-BK-NEKg",
        "outputId": "7d8a6936-0f70-450d-c6b7-5bb5f77b1206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using NPZ: /content/data/MedSegBenchCache/busi_256.npz\n",
            "[INFO] Image size policy: RESOLUTION=256 → NETWORK INPUT=256\n",
            "[COUNTS] train=452  val=64  test=131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 2/5 — Albumentations transforms (train/val/test)\n",
        "# ------------------------------------------------------------\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "resize_ops = []\n",
        "if IMAGE_SIZE != RESOLUTION:\n",
        "    resize_ops = [A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, interpolation=1)]  # 1=bilinear\n",
        "\n",
        "train_tf = A.Compose([\n",
        "    *resize_ops,\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.15, rotate_limit=15, border_mode=0, p=0.3),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.GaussianBlur(blur_limit=(3,5), p=0.15),\n",
        "    A.GaussNoise(var_limit=(5.0, 20.0), p=0.15),\n",
        "    A.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
        "    ToTensorV2(transpose_mask=True),\n",
        "])\n",
        "\n",
        "val_tf = A.Compose([\n",
        "    *resize_ops,\n",
        "    A.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
        "    ToTensorV2(transpose_mask=True),\n",
        "])\n",
        "\n",
        "test_tf = val_tf\n",
        "print(\"[OK] Transforms configured (train/val/test).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRltv3HENMhd",
        "outputId": "6fc8f46c-cbff-47e5-a023-6c564ab30059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Transforms configured (train/val/test).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 3/5 — Dataset that memory-maps the NPZ (ISICNPZDataset-style)\n",
        "# ------------------------------------------------------------\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def _label_key_for(split, npz_obj_or_keys):\n",
        "    k = set(npz_obj_or_keys if isinstance(npz_obj_or_keys, (set,list,tuple)) else npz_obj_or_keys.keys())\n",
        "    for suf in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "        cand = f\"{split}_{suf}\"\n",
        "        if cand in k: return cand\n",
        "    raise KeyError(f\"No label key found for split={split}.\")\n",
        "\n",
        "class ISICNPZDataset(Dataset):\n",
        "    def __init__(self, npz_path, split: str, indices, transform=None):\n",
        "        super().__init__()\n",
        "        self.path = str(npz_path)\n",
        "        _peek = np.load(self.path, allow_pickle=True, mmap_mode=\"r\")\n",
        "        self.img_key = f\"{split}_images\"\n",
        "        self.lbl_key = _label_key_for(split, _peek)\n",
        "        self.length = len(_peek[self.img_key])\n",
        "        assert self.length == len(_peek[self.lbl_key]), \"Images/labels length mismatch.\"\n",
        "        _peek.close()\n",
        "\n",
        "        self.split = split\n",
        "        self.indices = list(indices)\n",
        "        self.transform = transform\n",
        "        self._npz = None\n",
        "\n",
        "    def _ensure_open(self):\n",
        "        if self._npz is None:\n",
        "            self._npz = np.load(self.path, allow_pickle=True, mmap_mode=\"r\")\n",
        "\n",
        "    def __len__(self): return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        self._ensure_open()\n",
        "        i = self.indices[idx]\n",
        "        img = self._npz[self.img_key][i]  # HxW or HxWx3\n",
        "        msk = self._npz[self.lbl_key][i]  # HxW\n",
        "\n",
        "        if img.ndim == 2: img = np.stack([img, img, img], axis=-1)\n",
        "        if msk.max() > 1: msk = (msk > 127).astype(np.uint8)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            out = self.transform(image=img, mask=msk)\n",
        "            img_t = out[\"image\"]\n",
        "            msk_t = out[\"mask\"].unsqueeze(0) if out[\"mask\"].ndim == 2 else out[\"mask\"]\n",
        "        else:\n",
        "            img_f = img.astype(np.float32) / 255.0\n",
        "            img_f = (img_f - np.array(NORM_MEAN)) / np.array(NORM_STD)\n",
        "            img_t = torch.from_numpy(img_f).permute(2,0,1).contiguous()\n",
        "            msk_t = torch.from_numpy(msk.astype(np.float32)).unsqueeze(0)\n",
        "\n",
        "        return img_t, msk_t\n",
        "\n",
        "    def __del__(self):\n",
        "        try:\n",
        "            if self._npz is not None: self._npz.close()\n",
        "        except Exception: pass\n"
      ],
      "metadata": {
        "id": "hDWGycNJNMej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 4/5 — DataLoaders with safe settings\n",
        "# ------------------------------------------------------------\n",
        "from torch.utils.data import DataLoader\n",
        "import torch, os\n",
        "\n",
        "train_ds = ISICNPZDataset(busi_file, \"train\", _split_idx[\"train\"], transform=train_tf)\n",
        "val_ds   = ISICNPZDataset(busi_file, \"val\",   _split_idx[\"val\"],   transform=val_tf)\n",
        "test_ds  = ISICNPZDataset(busi_file, \"test\",  _split_idx[\"test\"],  transform=test_tf)\n",
        "\n",
        "num_workers = 2\n",
        "pin = torch.cuda.is_available()\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=True, prefetch_factor=2, persistent_workers=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=False, prefetch_factor=2, persistent_workers=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=1, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=False, prefetch_factor=2, persistent_workers=True)\n",
        "\n",
        "xb, yb = next(iter(train_loader))\n",
        "print(f\"[OK] Train batch shapes: images={tuple(xb.shape)} masks={tuple(yb.shape)}\")\n",
        "print(f\"[INFO] num_workers={num_workers}, pin_memory={pin}, batch_size={BATCH_SIZE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JikBr2VLNMb4",
        "outputId": "39e4ea3f-c6e5-4b78-c9ee-0ebc9f3331c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Train batch shapes: images=(8, 3, 256, 256) masks=(8, 1, 256, 256)\n",
            "[INFO] num_workers=2, pin_memory=False, batch_size=8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 5/5 — Policy echo (for the paper/log)\n",
        "# ------------------------------------------------------------\n",
        "print(\"[POLICY] Preprocessing/Normalization\")\n",
        "print(f\"  • Resize to: {IMAGE_SIZE}x{IMAGE_SIZE} (if different from NPZ {RESOLUTION})\")\n",
        "print(f\"  • Normalize (ImageNet): mean={NORM_MEAN}, std={NORM_STD}\")\n",
        "print(\"[POLICY] Train augmentations\")\n",
        "print(\"  • HorizontalFlip p=0.5\")\n",
        "print(\"  • ShiftScaleRotate (±2% shift, ±15% scale, ±15° rotate) p=0.3\")\n",
        "print(\"  • Brightness/Contrast p=0.3\")\n",
        "print(\"  • GaussianBlur p=0.15, GaussNoise p=0.15\")\n",
        "print(\"[POLICY] Val/Test: no augmentations (only resize + normalize)\")\n",
        "print(\"[READY] DataLoaders prepared. Next: STEP 5 (Data sanity visuals).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu6Q26YTNMY6",
        "outputId": "9d914e8e-e7a1-4409-ecf3-17b5b8eaf372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[POLICY] Preprocessing/Normalization\n",
            "  • Resize to: 256x256 (if different from NPZ 256)\n",
            "  • Normalize (ImageNet): mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
            "[POLICY] Train augmentations\n",
            "  • HorizontalFlip p=0.5\n",
            "  • ShiftScaleRotate (±2% shift, ±15% scale, ±15° rotate) p=0.3\n",
            "  • Brightness/Contrast p=0.3\n",
            "  • GaussianBlur p=0.15, GaussNoise p=0.15\n",
            "[POLICY] Val/Test: no augmentations (only resize + normalize)\n",
            "[READY] DataLoaders prepared. Next: STEP 5 (Data sanity visuals).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3RqUb60LNMWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# ============================================================\n",
        "# Cell 1/4 — Imports and shared helper modules (kept compatible)\n",
        "# ------------------------------------------------------------\n",
        "# Goal:\n",
        "#   • ResNet-50 provides skip maps at 1/4, 1/8, 1/16.\n",
        "#   • Pretrained ViT-B/16 runs on image tokens @ 1/16 grid.\n",
        "#   • U-Net decoder with 3 skip fusions; final upsample to full H×W.\n",
        "#   • forward(x) → {\"logits\": ...}  (same API as our pipeline).\n",
        "# ============================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Reuse your existing blocks if present\n",
        "if \"ConvBNReLU\" not in globals():\n",
        "    class ConvBNReLU(nn.Module):\n",
        "        def __init__(self, in_ch, out_ch, k=3, s=1, p=1):\n",
        "            super().__init__()\n",
        "            self.conv = nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)\n",
        "            self.bn   = nn.BatchNorm2d(out_ch)\n",
        "            self.act  = nn.ReLU(inplace=True)\n",
        "        def forward(self, x): return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "if \"UpBlock\" not in globals():\n",
        "    class UpBlock(nn.Module):\n",
        "        def __init__(self, in_ch, skip_ch, out_ch):\n",
        "            super().__init__()\n",
        "            self.conv1 = ConvBNReLU(in_ch + skip_ch, out_ch)\n",
        "            self.conv2 = ConvBNReLU(out_ch, out_ch)\n",
        "        def forward(self, x, skip):\n",
        "            x = F.interpolate(x, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1)\n",
        "            return self.conv2(self.conv1(x))\n",
        "\n",
        "# Cell 2/4 — Model definition (hybrid CNN→pretrained ViT→decoder)\n",
        "# ------------------------------------------------------------\n",
        "# Notes:\n",
        "#   • ResNet-50 (pretrained) yields skips: s1@H/4 (256), s2@H/8 (512), s3@H/16 (1024).\n",
        "#   • Pretrained ViT-B/16 (timm) runs on the input image; we reshape tokens to a 1/16 map (C=768).\n",
        "#   • Fuse ViT map with s3 at H/16, then decode with 3 up-blocks to H.\n",
        "# ============================================================\n",
        "from torchvision import models\n",
        "import timm\n",
        "\n",
        "class ResNet50Skips(nn.Module):\n",
        "    \"\"\"Return s1(H/4,256), s2(H/8,512), s3(H/16,1024) from ResNet-50 (pretrained if available).\"\"\"\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        try:\n",
        "            weights = models.ResNet50_Weights.IMAGENET1K_V2 if pretrained else None\n",
        "        except Exception:\n",
        "            weights = None\n",
        "        base = models.resnet50(weights=weights)\n",
        "        # Stem\n",
        "        self.conv1 = base.conv1; self.bn1 = base.bn1; self.relu = base.relu; self.maxpool = base.maxpool\n",
        "        # Stages\n",
        "        self.layer1 = base.layer1  # H/4,  256\n",
        "        self.layer2 = base.layer2  # H/8,  512\n",
        "        self.layer3 = base.layer3  # H/16, 1024\n",
        "        # Keep BN in eval mode for small datasets\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.eval()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x  = self.conv1(x); x = self.bn1(x); x = self.relu(x)  # H/2\n",
        "        x  = self.maxpool(x)                                    # H/4\n",
        "        s1 = self.layer1(x)                                     # H/4, 256\n",
        "        s2 = self.layer2(s1)                                    # H/8, 512\n",
        "        s3 = self.layer3(s2)                                    # H/16,1024\n",
        "        return s1, s2, s3\n",
        "\n",
        "class ViTB16_Pretrained(nn.Module):\n",
        "    \"\"\"Pretrained ViT-B/16 (timm). Returns a 1/16 feature map: (B,768,H/16,W/16).\"\"\"\n",
        "    def __init__(self, img_size=None):\n",
        "        super().__init__()\n",
        "        # timm handles pos-embed interpolation when img_size != 224\n",
        "        kwargs = dict(pretrained=True, num_classes=0, global_pool=\"\")\n",
        "        if img_size is not None:\n",
        "            kwargs[\"img_size\"] = int(img_size)\n",
        "        self.vit = timm.create_model(\"vit_base_patch16_224\", **kwargs)\n",
        "        self.embed_dim = getattr(self.vit, \"num_features\", 768)\n",
        "        self.patch = 16\n",
        "\n",
        "    def tokens_to_map(self, feats, H, W):\n",
        "        # feats: (B, 1+N, C) or (B, N, C) → (B, C, H/16, W/16)\n",
        "        if feats.dim() != 3: raise RuntimeError(\"ViT features must be (B, N, C) or (B, 1+N, C)\")\n",
        "        if feats.size(1) == (H // self.patch) * (W // self.patch) + 1:\n",
        "            feats = feats[:, 1:, :]  # drop cls token\n",
        "        B, N, C = feats.shape\n",
        "        gh, gw = H // self.patch, W // self.patch\n",
        "        assert N == gh * gw, f\"Token count {N} != {gh}*{gw} for H,W={H},{W}\"\n",
        "        return feats.transpose(1, 2).contiguous().view(B, C, gh, gw)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.vit.forward_features(x)  # (B, 1+N, 768)\n",
        "        B, _, H, W = x.shape\n",
        "        return self.tokens_to_map(feats, H, W)  # (B,768,H/16,W/16)\n",
        "\n",
        "class PaperTransUNet_R50_ViTB16(nn.Module):\n",
        "    def __init__(self, embed_dim=768, img_size=None):\n",
        "        super().__init__()\n",
        "        self.backbone = ResNet50Skips(pretrained=True)\n",
        "        self.vit      = ViTB16_Pretrained(img_size=img_size)     # ← pretrained ViT-B/16\n",
        "        # Project ViT channels if needed (keep 768); project s3 for fusion later in UpBlocks\n",
        "        # Decoder: fuse at H/16/H/8/H/4 and bring to H\n",
        "        self.up3  = UpBlock(self.vit.embed_dim, 1024, 512)       # H/16\n",
        "        self.up2  = UpBlock(512,               512,  256)        # H/8\n",
        "        self.up1  = UpBlock(256,               256,  128)        # H/4\n",
        "        self.final = ConvBNReLU(128, 64, k=3, s=1, p=1)\n",
        "        self.head  = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, _, H, W = x.shape\n",
        "        s1, s2, s3 = self.backbone(x)            # skips\n",
        "        b16 = self.vit(x)                        # (B,768,H/16,W/16) from pretrained ViT-B/16\n",
        "        d3  = self.up3(b16, s3)                  # H/16\n",
        "        d2  = self.up2(d3,  s2)                  # H/8\n",
        "        d1  = self.up1(d2,  s1)                  # H/4\n",
        "        d1  = F.interpolate(d1, scale_factor=4, mode=\"bilinear\", align_corners=False)  # → H\n",
        "        d1  = self.final(d1)\n",
        "        logits = self.head(d1)\n",
        "        return {\"logits\": logits}"
      ],
      "metadata": {
        "id": "tldnF90ENMTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# Cell 2/4 — CPU fairness + CKPT path + preload 50 RAW test samples\n",
        "# (SAFE: avoid set_num_interop_threads error if threads already started)\n",
        "# ------------------------------------------------------------\n",
        "import os, psutil, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# ---- CPU fairness (as requested) ----\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"MKL_NUM_THREADS\"]  = \"1\"\n",
        "\n",
        "import torch\n",
        "\n",
        "# Always safe at runtime:\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "# set_num_interop_threads must be called before any parallel work; try, else continue.\n",
        "try:\n",
        "    if hasattr(torch, \"set_num_interop_threads\"):\n",
        "        torch.set_num_interop_threads(1)\n",
        "except RuntimeError as e:\n",
        "    # Already started parallel work; keep current interop setting but log it.\n",
        "    print(f\"[WARN] {e} — continuing with interop_threads={getattr(torch, 'get_num_interop_threads', lambda: 'N/A')()}\")\n",
        "\n",
        "DEVICE = \"cpu\"\n",
        "print(f\"[CPU] threads={torch.get_num_threads()} \"\n",
        "      f\"interop={getattr(torch, 'get_num_interop_threads', lambda: 'N/A')()} \"\n",
        "      f\"OMP={os.getenv('OMP_NUM_THREADS')} MKL={os.getenv('MKL_NUM_THREADS')}\")\n",
        "\n",
        "# ---- threshold from cfg (fallback 0.5) ----\n",
        "THRESH = float(cfg.get(\"metrics\", {}).get(\"threshold\", 0.5)) if \"cfg\" in globals() else 0.5\n",
        "print(f\"[INFO] THRESH={THRESH}\")\n",
        "\n",
        "# ---- your exact trained checkpoint path ----\n",
        "from pathlib import Path\n",
        "CKPT_PATH = \"/content/drive/MyDrive/TransUNetbusi/checkpoints/TransUNetBaseline_busi_IMG256_SEED42_2025-11-03_03-42-24_best.pt\"  # <<< EDIT THIS\n",
        "if not Path(CKPT_PATH).exists():\n",
        "    raise FileNotFoundError(f\"Checkpoint not found: {CKPT_PATH}\")\n",
        "\n",
        "# ---- build a 50-sample test index (first 50 of split) ----\n",
        "NUM_SAMPLES = 50\n",
        "WARMUP = 5\n",
        "test_ids = split_idx[\"test\"]\n",
        "if len(test_ids) < NUM_SAMPLES:\n",
        "    raise ValueError(f\"Test set has {len(test_ids)} samples; need at least {NUM_SAMPLES}.\")\n",
        "sel_ids = test_ids[:NUM_SAMPLES]\n",
        "\n",
        "# ---- preload RAW arrays (avoid disk I/O in timing) ----\n",
        "# Note: transforms/tensorization are INSIDE timing for end-to-end latency.\n",
        "test_img_key = \"test_images\"\n",
        "for lblk in (\"test_masks\",\"test_mask\",\"test_labels\",\"test_label\"):\n",
        "    if lblk in npz: test_lbl_key = lblk; break\n",
        "else:\n",
        "    raise KeyError(\"No test label key among {test_masks, test_mask, test_labels, test_label}.\")\n",
        "\n",
        "raw_samples = []\n",
        "for i in sel_ids:\n",
        "    img = npz[test_img_key][i]\n",
        "    msk = npz[test_lbl_key][i]\n",
        "    raw_samples.append((img, msk))\n",
        "print(f\"[OK] Preloaded RAW {len(raw_samples)} test samples into RAM.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlF04X77Nl7Y",
        "outputId": "04040d56-d6f7-4db6-f537-f59070d875f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CPU] threads=1 interop=1 OMP=1 MKL=1\n",
            "[INFO] THRESH=0.5\n",
            "[OK] Preloaded RAW 50 test samples into RAM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVAL\n",
        "# Cell 3/4 (REPLACED) — Instantiate model + CLEAN LOAD (CPU)\n",
        "# ------------------------------------------------------------\n",
        "from pathlib import Path\n",
        "import re, torch\n",
        "\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", 256))\n",
        "LITE_B_C     = (64,128,192,256)                 # same tuple as before; first 3 used for skips\n",
        "_vit_name    = \"vit_small_patch16_224\"          # PRETRAINED small ViT (patch=16)\n",
        "\n",
        "model = PaperTransUNet_R50_ViTB16(embed_dim=768, img_size=IMAGE_SIZE).to(\"cpu\")\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "\n",
        "def unwrap_state(d):\n",
        "    # common wrappers\n",
        "    for k in [\"model_state\",\"state_dict\",\"model\",\"net\",\"ema\",\"model_state_dict\"]:\n",
        "        if isinstance(d, dict) and k in d and isinstance(d[k], dict):\n",
        "            return d[k]\n",
        "    return d if isinstance(d, dict) else {}\n",
        "\n",
        "raw = unwrap_state(ckpt)\n",
        "\n",
        "# 1) strip 'module.' prefix\n",
        "clean = {}\n",
        "for k, v in raw.items():\n",
        "    nk = k[7:] if k.startswith(\"module.\") else k\n",
        "    clean[nk] = v\n",
        "\n",
        "# 2) drop profiling buffers (from thop/fvcore)\n",
        "def is_profile_key(k: str) -> bool:\n",
        "    return k.endswith(\".total_ops\") or k.endswith(\".total_params\")\n",
        "clean = {k:v for k,v in clean.items() if not is_profile_key(k)}\n",
        "\n",
        "# 3) optional prefix remaps (adapt if your training used different names)\n",
        "#    e.g., 'backbone.' -> 'vit.' , 'encoder.' -> 'vit.' , 'transformer.' -> 'vit.'\n",
        "remaps = [\n",
        "    (r\"^backbone\\.\", \"vit.\"),\n",
        "    (r\"^encoder\\.\",  \"vit.\"),\n",
        "    (r\"^transformer\\.\", \"vit.\"),\n",
        "]\n",
        "remapped = {}\n",
        "for k, v in clean.items():\n",
        "    nk = k\n",
        "    for pat, rep in remaps:\n",
        "        nk = re.sub(pat, rep, nk)\n",
        "    remapped[nk] = v\n",
        "clean = remapped\n",
        "\n",
        "# 4) keep only keys that exist in current model (exact-name intersection)\n",
        "model_sd = model.state_dict()\n",
        "intersect = {k:v for k,v in clean.items() if k in model_sd and v.shape == model_sd[k].shape}\n",
        "\n",
        "# 5) report coverage\n",
        "print(f\"[CKPT] total keys in state: {len(raw)}\")\n",
        "print(f\"[CKPT] after strip+drop:     {len(clean)}\")\n",
        "print(f\"[CKPT] intersect (name+shape): {len(intersect)} / model expects {len(model_sd)}\")\n",
        "\n",
        "# 6) load intersect only (others remain as initialized / DeiT pretrained)\n",
        "missing_before = set(model_sd.keys()) - set(intersect.keys())\n",
        "load_res = model_sd.copy()\n",
        "load_res.update(intersect)\n",
        "model.load_state_dict(load_res, strict=False)\n",
        "\n",
        "# sanity: print what we still miss (first 40)\n",
        "still_missing = list(set(model.state_dict().keys()) - set(intersect.keys()))\n",
        "print(f\"[LOAD] missing (after clean) ~ {len(still_missing)} (showing up to 40)\")\n",
        "print(still_missing[:40])\n",
        "\n",
        "model.eval()\n",
        "print(\"[OK] Cleaned checkpoint loaded into model on CPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "f81db4f90ab74515ba3b4234b36db34b",
            "b0adf29aab934abc97cd1ce47f20d10b",
            "8f47092623f74ab89b67aa2c3beec7f7",
            "8d006e9bf86948059f082953099675d4",
            "0041691e0cd34d4ba19881e2142a8b3a",
            "fa8df18b80594df3ac9a52519b524622",
            "82a4dfbefc9641a48be561a3b6781583",
            "acb690da4689444197e5e7440d9ee78d",
            "3b8e732ce4ba4aa6a4159d67c47e413a",
            "9dea6219f26e4fc4a5af4c03a9cf4b7d",
            "129e5c20c7964f82a170471be26e39e5"
          ]
        },
        "id": "zp39FVeBePV5",
        "outputId": "4ec3ff37-5ab3-420b-c698-74d596d1e91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 53.6MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f81db4f90ab74515ba3b4234b36db34b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CKPT] total keys in state: 856\n",
            "[CKPT] after strip+drop:     454\n",
            "[CKPT] intersect (name+shape): 194 / model expects 452\n",
            "[LOAD] missing (after clean) ~ 258 (showing up to 40)\n",
            "['backbone.layer2.0.bn2.weight', 'backbone.layer2.2.bn2.weight', 'backbone.layer3.1.conv1.weight', 'backbone.layer3.4.bn3.num_batches_tracked', 'backbone.layer3.0.bn3.num_batches_tracked', 'backbone.layer1.2.bn3.num_batches_tracked', 'backbone.layer2.3.bn2.running_mean', 'backbone.layer2.2.bn3.bias', 'backbone.layer3.0.bn3.bias', 'backbone.layer1.1.bn1.running_var', 'backbone.layer2.3.bn2.weight', 'backbone.layer3.2.bn1.running_var', 'backbone.layer1.0.bn3.bias', 'backbone.layer3.2.conv1.weight', 'backbone.layer1.0.conv1.weight', 'backbone.layer3.5.bn1.running_mean', 'backbone.layer3.4.conv2.weight', 'backbone.bn1.running_var', 'backbone.layer1.2.bn1.running_var', 'backbone.layer2.2.bn3.running_var', 'backbone.layer3.2.bn3.num_batches_tracked', 'backbone.layer3.3.bn3.bias', 'backbone.layer2.2.bn3.weight', 'backbone.layer2.1.bn1.bias', 'backbone.layer3.2.bn1.num_batches_tracked', 'backbone.layer1.2.conv2.weight', 'backbone.layer3.3.bn3.num_batches_tracked', 'backbone.layer2.2.conv2.weight', 'backbone.layer1.2.conv1.weight', 'backbone.layer2.0.bn3.running_mean', 'backbone.layer3.0.downsample.1.num_batches_tracked', 'backbone.layer2.0.downsample.1.running_var', 'backbone.layer1.0.bn2.running_mean', 'backbone.layer2.2.bn2.bias', 'backbone.layer2.0.downsample.0.weight', 'backbone.layer3.4.conv3.weight', 'backbone.layer1.0.bn2.num_batches_tracked', 'backbone.layer2.0.downsample.1.num_batches_tracked', 'backbone.layer2.1.bn2.weight', 'backbone.layer3.0.conv1.weight']\n",
            "[OK] Cleaned checkpoint loaded into model on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torch, re\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "\n",
        "def _unwrap_state(d):\n",
        "    # try common containers\n",
        "    for k in [\"state_dict\",\"model\",\"net\",\"ema\",\"model_state\"]:\n",
        "        if isinstance(d, dict) and k in d and isinstance(d[k], dict):\n",
        "            return d[k]\n",
        "    return d if isinstance(d, dict) else {}\n",
        "\n",
        "raw_state = _unwrap_state(ckpt)\n",
        "\n",
        "print(f\"[CKPT] top-level keys: {list(ckpt.keys())[:20]}\")\n",
        "print(f\"[CKPT] state len: {len(raw_state)}\")\n",
        "\n",
        "# Show a few parameter names to identify architecture/backbone\n",
        "sample_keys = list(raw_state.keys())[:40]\n",
        "print(\"[CKPT] sample param keys:\")\n",
        "for k in sample_keys:\n",
        "    print(\"  \", k)\n",
        "\n",
        "# Also show model keys to compare\n",
        "model_keys = list(model.state_dict().keys())\n",
        "print(f\"[MODEL] expects {len(model_keys)} tensors\")\n",
        "print(\"[MODEL] sample expected keys:\")\n",
        "for k in model_keys[:40]:\n",
        "    print(\"  \", k)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG20hJl3dpAi",
        "outputId": "3bc6f6d3-be41-4190-af57-bdcb15c60e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CKPT] top-level keys: ['epoch', 'model_state', 'optimizer_state', 'val_dice', 'val_loss', 'cfg']\n",
            "[CKPT] state len: 856\n",
            "[CKPT] sample param keys:\n",
            "   total_ops\n",
            "   total_params\n",
            "   backbone.total_ops\n",
            "   backbone.total_params\n",
            "   backbone.conv1.weight\n",
            "   backbone.bn1.weight\n",
            "   backbone.bn1.bias\n",
            "   backbone.bn1.running_mean\n",
            "   backbone.bn1.running_var\n",
            "   backbone.bn1.num_batches_tracked\n",
            "   backbone.layer1.0.total_ops\n",
            "   backbone.layer1.0.total_params\n",
            "   backbone.layer1.0.conv1.weight\n",
            "   backbone.layer1.0.bn1.weight\n",
            "   backbone.layer1.0.bn1.bias\n",
            "   backbone.layer1.0.bn1.running_mean\n",
            "   backbone.layer1.0.bn1.running_var\n",
            "   backbone.layer1.0.bn1.num_batches_tracked\n",
            "   backbone.layer1.0.conv2.weight\n",
            "   backbone.layer1.0.bn2.weight\n",
            "   backbone.layer1.0.bn2.bias\n",
            "   backbone.layer1.0.bn2.running_mean\n",
            "   backbone.layer1.0.bn2.running_var\n",
            "   backbone.layer1.0.bn2.num_batches_tracked\n",
            "   backbone.layer1.0.conv3.weight\n",
            "   backbone.layer1.0.bn3.weight\n",
            "   backbone.layer1.0.bn3.bias\n",
            "   backbone.layer1.0.bn3.running_mean\n",
            "   backbone.layer1.0.bn3.running_var\n",
            "   backbone.layer1.0.bn3.num_batches_tracked\n",
            "   backbone.layer1.0.downsample.0.weight\n",
            "   backbone.layer1.0.downsample.1.weight\n",
            "   backbone.layer1.0.downsample.1.bias\n",
            "   backbone.layer1.0.downsample.1.running_mean\n",
            "   backbone.layer1.0.downsample.1.running_var\n",
            "   backbone.layer1.0.downsample.1.num_batches_tracked\n",
            "   backbone.layer1.1.total_ops\n",
            "   backbone.layer1.1.total_params\n",
            "   backbone.layer1.1.conv1.weight\n",
            "   backbone.layer1.1.bn1.weight\n",
            "[MODEL] expects 452 tensors\n",
            "[MODEL] sample expected keys:\n",
            "   backbone.conv1.weight\n",
            "   backbone.bn1.weight\n",
            "   backbone.bn1.bias\n",
            "   backbone.bn1.running_mean\n",
            "   backbone.bn1.running_var\n",
            "   backbone.bn1.num_batches_tracked\n",
            "   backbone.layer1.0.conv1.weight\n",
            "   backbone.layer1.0.bn1.weight\n",
            "   backbone.layer1.0.bn1.bias\n",
            "   backbone.layer1.0.bn1.running_mean\n",
            "   backbone.layer1.0.bn1.running_var\n",
            "   backbone.layer1.0.bn1.num_batches_tracked\n",
            "   backbone.layer1.0.conv2.weight\n",
            "   backbone.layer1.0.bn2.weight\n",
            "   backbone.layer1.0.bn2.bias\n",
            "   backbone.layer1.0.bn2.running_mean\n",
            "   backbone.layer1.0.bn2.running_var\n",
            "   backbone.layer1.0.bn2.num_batches_tracked\n",
            "   backbone.layer1.0.conv3.weight\n",
            "   backbone.layer1.0.bn3.weight\n",
            "   backbone.layer1.0.bn3.bias\n",
            "   backbone.layer1.0.bn3.running_mean\n",
            "   backbone.layer1.0.bn3.running_var\n",
            "   backbone.layer1.0.bn3.num_batches_tracked\n",
            "   backbone.layer1.0.downsample.0.weight\n",
            "   backbone.layer1.0.downsample.1.weight\n",
            "   backbone.layer1.0.downsample.1.bias\n",
            "   backbone.layer1.0.downsample.1.running_mean\n",
            "   backbone.layer1.0.downsample.1.running_var\n",
            "   backbone.layer1.0.downsample.1.num_batches_tracked\n",
            "   backbone.layer1.1.conv1.weight\n",
            "   backbone.layer1.1.bn1.weight\n",
            "   backbone.layer1.1.bn1.bias\n",
            "   backbone.layer1.1.bn1.running_mean\n",
            "   backbone.layer1.1.bn1.running_var\n",
            "   backbone.layer1.1.bn1.num_batches_tracked\n",
            "   backbone.layer1.1.conv2.weight\n",
            "   backbone.layer1.1.bn2.weight\n",
            "   backbone.layer1.1.bn2.bias\n",
            "   backbone.layer1.1.bn2.running_mean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing, unexpected = model.load_state_dict(raw_state, strict=False)\n",
        "print(f\"[DIFF] missing ({len(missing)}):\")\n",
        "print(missing[:50])\n",
        "print(f\"[DIFF] unexpected ({len(unexpected)}):\")\n",
        "print(unexpected[:50])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuEkE7Rzd2HR",
        "outputId": "5aae442b-190e-4308-c3c4-8eea7b322bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DIFF] missing (0):\n",
            "[]\n",
            "[DIFF] unexpected (404):\n",
            "['total_ops', 'total_params', 'backbone.total_ops', 'backbone.total_params', 'backbone.layer1.0.total_ops', 'backbone.layer1.0.total_params', 'backbone.layer1.1.total_ops', 'backbone.layer1.1.total_params', 'backbone.layer1.2.total_ops', 'backbone.layer1.2.total_params', 'backbone.layer2.0.total_ops', 'backbone.layer2.0.total_params', 'backbone.layer2.1.total_ops', 'backbone.layer2.1.total_params', 'backbone.layer2.2.total_ops', 'backbone.layer2.2.total_params', 'backbone.layer2.3.total_ops', 'backbone.layer2.3.total_params', 'backbone.layer3.0.total_ops', 'backbone.layer3.0.total_params', 'backbone.layer3.1.total_ops', 'backbone.layer3.1.total_params', 'backbone.layer3.2.total_ops', 'backbone.layer3.2.total_params', 'backbone.layer3.3.total_ops', 'backbone.layer3.3.total_params', 'backbone.layer3.4.total_ops', 'backbone.layer3.4.total_params', 'backbone.layer3.5.total_ops', 'backbone.layer3.5.total_params', 'vit.total_ops', 'vit.total_params', 'vit.vit.total_ops', 'vit.vit.total_params', 'vit.vit.patch_embed.total_ops', 'vit.vit.patch_embed.total_params', 'vit.vit.patch_embed.norm.total_ops', 'vit.vit.patch_embed.norm.total_params', 'vit.vit.patch_drop.total_ops', 'vit.vit.patch_drop.total_params', 'vit.vit.norm_pre.total_ops', 'vit.vit.norm_pre.total_params', 'vit.vit.blocks.0.total_ops', 'vit.vit.blocks.0.total_params', 'vit.vit.blocks.0.norm1.total_ops', 'vit.vit.blocks.0.norm1.total_params', 'vit.vit.blocks.0.attn.total_ops', 'vit.vit.blocks.0.attn.total_params', 'vit.vit.blocks.0.attn.q_norm.total_ops', 'vit.vit.blocks.0.attn.q_norm.total_params']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# Cell 4/4 — Warm-up, timed run, metrics, save CSV+JSON\n",
        "# (FIX: added `import math`)\n",
        "# ------------------------------------------------------------\n",
        "import time, numpy as np, math, json, os, psutil, pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- helpers ----\n",
        "def apply_test_transform(img, msk):\n",
        "    # Ensure 3-ch image & binary mask; then apply test_tf (resize+norm+tensor)\n",
        "    if img.ndim == 2: img = np.stack([img, img, img], axis=-1)\n",
        "    if msk.max() > 1: msk = (msk > 127).astype(np.uint8)\n",
        "    out = test_tf(image=img, mask=msk)  # includes resize+normalize\n",
        "    x = out[\"image\"]                           # [C,H,W] float32\n",
        "    y = out[\"mask\"].unsqueeze(0) if out[\"mask\"].ndim==2 else out[\"mask\"]  # [1,H,W]\n",
        "    return x, y\n",
        "\n",
        "def binarize(prob, thr): return (prob >= thr).astype(np.uint8)\n",
        "\n",
        "def dice_iou(pred, mask, eps=1e-7):\n",
        "    inter = (pred & mask).sum()\n",
        "    union = (pred | mask).sum()\n",
        "    dice = (2*inter + eps) / (pred.sum() + mask.sum() + eps)\n",
        "    iou  = (inter + eps) / (union + eps)\n",
        "    return float(dice), float(iou)\n",
        "\n",
        "# ---- warm-up (excluded) ----\n",
        "with torch.no_grad():\n",
        "    for i in range(WARMUP):\n",
        "        img, msk = raw_samples[i]\n",
        "        x, y = apply_test_transform(img, msk)\n",
        "        _ = model(x.unsqueeze(0))\n",
        "\n",
        "# ---- timed run ----\n",
        "lat_ms, dices, ious = [], [], []\n",
        "cpu_hist, ram_hist  = [], []\n",
        "proc = psutil.Process(os.getpid())\n",
        "t_start = time.perf_counter()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(WARMUP, NUM_SAMPLES):\n",
        "        img, msk = raw_samples[i]\n",
        "\n",
        "        t0 = time.perf_counter()\n",
        "        x, y = apply_test_transform(img, msk)       # include resize+normalize in timing\n",
        "        out = model(x.unsqueeze(0))                 # forward\n",
        "        logits = out[\"logits\"] if isinstance(out, dict) and \"logits\" in out else out\n",
        "        prob = torch.sigmoid(logits).cpu().numpy().squeeze()\n",
        "        pred = binarize(prob, THRESH)\n",
        "        gt   = (y.squeeze().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        d, j = dice_iou(pred, gt)\n",
        "        t1 = time.perf_counter()\n",
        "\n",
        "        dices.append(d); ious.append(j)\n",
        "        lat_ms.append((t1 - t0) * 1000.0)\n",
        "        cpu_hist.append(psutil.cpu_percent(interval=None))\n",
        "        ram_hist.append(proc.memory_info().rss)\n",
        "\n",
        "t_end = time.perf_counter()\n",
        "\n",
        "# ---- summary ----\n",
        "def pct(vals, p):\n",
        "    if not vals: return float('nan')\n",
        "    a = sorted(vals)\n",
        "    k = (len(a)-1)*(p/100.0)\n",
        "    f,c = math.floor(k), math.ceil(k)\n",
        "    return a[int(k)] if f==c else a[f]*(c-k)+a[c]*(k-f)\n",
        "\n",
        "n = len(lat_ms)\n",
        "fps = (NUM_SAMPLES - WARMUP) / (t_end - t_start) if (t_end - t_start) > 0 else float('nan')\n",
        "summary = dict(\n",
        "    dice_mean=float(np.mean(dices)) if dices else float('nan'),\n",
        "    iou_mean=float(np.mean(ious)) if ious else float('nan'),\n",
        "    lat_median_ms=float(np.median(lat_ms)) if n else float('nan'),\n",
        "    lat_p90_ms=float(pct(lat_ms, 90)),\n",
        "    lat_p95_ms=float(pct(lat_ms, 95)),\n",
        "    lat_min_ms=float(np.min(lat_ms)) if n else float('nan'),\n",
        "    lat_max_ms=float(np.max(lat_ms)) if n else float('nan'),\n",
        "    wall_time_s=float(t_end - t_start),\n",
        "    fps=float(fps),\n",
        "    peak_ram_mb=float(max(ram_hist)/(1024*1024)) if ram_hist else float('nan'),\n",
        "    cpu_mean_pct=float(np.mean(cpu_hist)) if cpu_hist else float('nan'),\n",
        "    threshold=float(THRESH),\n",
        "    samples=int(NUM_SAMPLES - WARMUP),\n",
        "    threads=dict(\n",
        "        torch_num_threads=torch.get_num_threads(),\n",
        "        torch_num_interop=torch.get_num_interop_threads() if hasattr(torch, \"get_num_interop_threads\") else \"N/A\",\n",
        "        OMP_NUM_THREADS=os.getenv(\"OMP_NUM_THREADS\"),\n",
        "        MKL_NUM_THREADS=os.getenv(\"MKL_NUM_THREADS\"),\n",
        "    ),\n",
        "    ckpt=CKPT_PATH,\n",
        "    data=str(busi_file),\n",
        ")\n",
        "\n",
        "print(json.dumps(summary, indent=2))\n",
        "\n",
        "# ---- save artifacts ----\n",
        "outdir = Path(\"./cpu_eval_runs\"); outdir.mkdir(exist_ok=True, parents=True)\n",
        "stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "pd.DataFrame({\"idx\": list(range(n)), \"latency_ms\": lat_ms, \"dice\": dices, \"iou\": ious}).to_csv(outdir / f\"per_image_{stamp}.csv\", index=False)\n",
        "with open(outdir / f\"summary_{stamp}.json\",\"w\") as f: json.dump(summary, f, indent=2)\n",
        "print(\"Saved:\", outdir / f\"per_image_{stamp}.csv\", \"|\", outdir / f\"summary_{stamp}.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02TjETcyOl36",
        "outputId": "a7f246ed-628e-42ac-9daa-da3a787e3066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"dice_mean\": 0.7698876104984966,\n",
            "  \"iou_mean\": 0.7046804413975714,\n",
            "  \"lat_median_ms\": 1849.6215819999406,\n",
            "  \"lat_p90_ms\": 3438.8891594000374,\n",
            "  \"lat_p95_ms\": 3686.3205070000504,\n",
            "  \"lat_min_ms\": 1743.217770000001,\n",
            "  \"lat_max_ms\": 4175.059469999951,\n",
            "  \"wall_time_s\": 100.93242670899997,\n",
            "  \"fps\": 0.44584284225861603,\n",
            "  \"peak_ram_mb\": 5070.4140625,\n",
            "  \"cpu_mean_pct\": 69.37111111111112,\n",
            "  \"threshold\": 0.5,\n",
            "  \"samples\": 45,\n",
            "  \"threads\": {\n",
            "    \"torch_num_threads\": 1,\n",
            "    \"torch_num_interop\": 1,\n",
            "    \"OMP_NUM_THREADS\": \"1\",\n",
            "    \"MKL_NUM_THREADS\": \"1\"\n",
            "  },\n",
            "  \"ckpt\": \"/content/drive/MyDrive/TransUNetbusi/checkpoints/TransUNetBaseline_busi_IMG256_SEED42_2025-11-03_03-42-24_best.pt\",\n",
            "  \"data\": \"/content/data/MedSegBenchCache/busi_256.npz\"\n",
            "}\n",
            "Saved: cpu_eval_runs/per_image_20251104_041047.csv | cpu_eval_runs/summary_20251104_041047.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd; from pathlib import Path\n",
        "p = sorted(Path(\"cpu_eval_runs\").glob(\"per_image_*.csv\"))[-1]\n",
        "df = pd.read_csv(p)\n",
        "print(df.describe(percentiles=[.5,.9,.95]))\n",
        "print(\"Top 5 slowest:\\n\", df.sort_values(\"latency_ms\", ascending=False).head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAw3zscae5q3",
        "outputId": "833872a7-ea38-47a8-bf87-61193339a201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             idx   latency_ms          dice           iou\n",
            "count  45.000000    45.000000  4.500000e+01  4.500000e+01\n",
            "mean   22.000000  2242.433579  7.698876e-01  7.046804e-01\n",
            "std    13.133926   680.111093  3.174171e-01  3.152729e-01\n",
            "min     0.000000  1743.217770  1.909490e-11  1.909490e-11\n",
            "50%    22.000000  1849.621582  9.237148e-01  8.582435e-01\n",
            "90%    39.600000  3438.889159  9.567614e-01  9.171072e-01\n",
            "95%    41.800000  3686.320507  9.648219e-01  9.320499e-01\n",
            "max    44.000000  4175.059470  9.711300e-01  9.438801e-01\n",
            "Top 5 slowest:\n",
            "     idx   latency_ms          dice           iou\n",
            "4     4  4175.059470  5.819369e-01  4.103745e-01\n",
            "35   35  3888.215443  9.125236e-01  8.391204e-01\n",
            "38   38  3701.108195  9.302038e-01  8.695150e-01\n",
            "39   39  3627.169755  8.899139e-01  8.016620e-01\n",
            "34   34  3620.887461  4.940711e-11  4.940711e-11\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f81db4f90ab74515ba3b4234b36db34b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0adf29aab934abc97cd1ce47f20d10b",
              "IPY_MODEL_8f47092623f74ab89b67aa2c3beec7f7",
              "IPY_MODEL_8d006e9bf86948059f082953099675d4"
            ],
            "layout": "IPY_MODEL_0041691e0cd34d4ba19881e2142a8b3a"
          }
        },
        "b0adf29aab934abc97cd1ce47f20d10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa8df18b80594df3ac9a52519b524622",
            "placeholder": "​",
            "style": "IPY_MODEL_82a4dfbefc9641a48be561a3b6781583",
            "value": "model.safetensors: 100%"
          }
        },
        "8f47092623f74ab89b67aa2c3beec7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb690da4689444197e5e7440d9ee78d",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b8e732ce4ba4aa6a4159d67c47e413a",
            "value": 346284714
          }
        },
        "8d006e9bf86948059f082953099675d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dea6219f26e4fc4a5af4c03a9cf4b7d",
            "placeholder": "​",
            "style": "IPY_MODEL_129e5c20c7964f82a170471be26e39e5",
            "value": " 346M/346M [00:05&lt;00:00, 155MB/s]"
          }
        },
        "0041691e0cd34d4ba19881e2142a8b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8df18b80594df3ac9a52519b524622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82a4dfbefc9641a48be561a3b6781583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acb690da4689444197e5e7440d9ee78d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b8e732ce4ba4aa6a4159d67c47e413a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dea6219f26e4fc4a5af4c03a9cf4b7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "129e5c20c7964f82a170471be26e39e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}