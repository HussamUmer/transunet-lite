{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\n",
        "# Cell 1/9 — Run identifiers, paths, and folders\n",
        "# ------------------------------------------------------------\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- run knobs (same style as yours) ----\n",
        "DATASET    = \"busi\"\n",
        "IMAGE_SIZE = 256\n",
        "SEED       = 42\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS     = 10\n",
        "AMP_ON     = True\n",
        "MODEL_TAG  = \"setr_model\"\n",
        "RUN_NAME   = f\"{MODEL_TAG}_{DATASET}_IMG{IMAGE_SIZE}_SEED{SEED}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
        "CONFIG_PATH = \"configs/example.yaml\"\n",
        "\n",
        "# ---- standard folders ----\n",
        "root = Path(\"/content/drive/MyDrive/setr_model_busi_Test\")\n",
        "for p in [\"logs\", \"checkpoints\", \"figures\", \"runs\", \"summary\"]:\n",
        "    (root / p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "summary_txt_path  = root / \"summary\" / f\"{RUN_NAME}_env.txt\"\n",
        "summary_json_path = root / \"summary\" / f\"{RUN_NAME}_env.json\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihJQ62HiGoV9",
        "outputId": "3acb95ce-b690-435e-d682-0a0b17a8775b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 2/9 — Base imports & safe-import helper\n",
        "# ------------------------------------------------------------\n",
        "import os, sys, json, time, platform, importlib, random\n",
        "\n",
        "def try_import(name: str):\n",
        "    try:\n",
        "        mod = importlib.import_module(name)\n",
        "        ver = getattr(mod, \"__version__\", \"unknown\")\n",
        "        if name == \"PIL\": ver = getattr(mod, \"__version__\", ver)\n",
        "        if name == \"cv2\": ver = getattr(mod, \"__version__\", ver)\n",
        "        return mod, ver\n",
        "    except Exception as e:\n",
        "        return None, f\"NOT INSTALLED ({type(e).__name__})\"\n",
        "\n",
        "!pip -q install -U monai torchmetrics thop fvcore timm albumentations==1.4.4 psutil pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu1sollbGoeE",
        "outputId": "b50660ae-0ab6-4e6c-ec73-317180a10fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.4/150.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 3/9 — Import common stack (DL, data, viz, utils)\n",
        "# ------------------------------------------------------------\n",
        "# Core / data\n",
        "numpy, np_ver         = try_import(\"numpy\")\n",
        "pandas, pd_ver        = try_import(\"pandas\")\n",
        "\n",
        "# Deep Learning\n",
        "torch, torch_ver      = try_import(\"torch\")\n",
        "torchvision, tv_ver   = try_import(\"torchvision\")\n",
        "timm, timm_ver        = try_import(\"timm\")\n",
        "monai, monai_ver      = try_import(\"monai\")\n",
        "torchmetrics, tm_ver  = try_import(\"torchmetrics\")\n",
        "\n",
        "# Aug / IO / Viz\n",
        "albumentations, alb_ver = try_import(\"albumentations\")\n",
        "cv2, cv2_ver            = try_import(\"cv2\")\n",
        "PIL, pil_ver            = try_import(\"PIL\")\n",
        "matplotlib, mpl_ver     = try_import(\"matplotlib\")\n",
        "\n",
        "# Utils\n",
        "yaml, yaml_ver       = try_import(\"yaml\")\n",
        "sklearn, sk_ver      = try_import(\"sklearn\")\n",
        "psutil, psutil_ver   = try_import(\"psutil\")\n",
        "\n",
        "# Profiling\n",
        "thop, thop_ver       = try_import(\"thop\")\n",
        "fvcore, fvcore_ver   = try_import(\"fvcore\")\n"
      ],
      "metadata": {
        "id": "f5VnECLKGohb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 4/9 — Device, CUDA/cuDNN, and GPU VRAM discovery\n",
        "# ------------------------------------------------------------\n",
        "device         = \"cpu\"\n",
        "gpu_name       = \"N/A\"\n",
        "total_vram_mb  = \"N/A\"\n",
        "total_vram_gb  = \"N/A\"\n",
        "cuda_version   = \"N/A\"\n",
        "cudnn_version  = \"N/A\"\n",
        "\n",
        "if torch is not None:\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    device = \"cuda\" if cuda_available else \"cpu\"\n",
        "    cuda_version = getattr(torch.version, \"cuda\", \"N/A\")\n",
        "    try:\n",
        "        cudnn_version = str(torch.backends.cudnn.version()) if torch.backends.cudnn.is_available() else \"N/A\"\n",
        "    except Exception:\n",
        "        cudnn_version = \"N/A\"\n",
        "    if cuda_available:\n",
        "        try:\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            props = torch.cuda.get_device_properties(0)\n",
        "            total_vram_bytes = getattr(props, \"total_memory\", 0)\n",
        "            total_vram_mb = round(total_vram_bytes / (1024**2), 2)\n",
        "            total_vram_gb = round(total_vram_bytes / (1024**3), 2)\n",
        "        except Exception:\n",
        "            gpu_name = \"Unknown (query failed)\"\n",
        "            total_vram_mb = \"Unknown\"\n",
        "            total_vram_gb = \"Unknown\"\n"
      ],
      "metadata": {
        "id": "QVMvrGY_Gok0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 5/9 — Reproducibility (seeds + deterministic flags)\n",
        "# ------------------------------------------------------------\n",
        "random.seed(SEED)\n",
        "if numpy:\n",
        "    numpy.random.seed(SEED)\n",
        "\n",
        "if torch is not None:\n",
        "    torch.manual_seed(SEED)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(SEED)\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    except Exception:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "wqa1EkgIGooP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 6/9 — Assemble environment snapshot dict\n",
        "# ------------------------------------------------------------\n",
        "env_info = {\n",
        "    \"run\": {\n",
        "        \"run_name\": RUN_NAME,\n",
        "        \"datetime\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"dataset\": DATASET,\n",
        "        \"image_size\": IMAGE_SIZE,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"amp_on\": AMP_ON,\n",
        "        \"seed\": SEED,\n",
        "        \"config_path\": CONFIG_PATH if Path(CONFIG_PATH).exists() else f\"{CONFIG_PATH} (not found)\",\n",
        "    },\n",
        "    \"system\": {\n",
        "        \"python\": sys.version.split()[0],\n",
        "        \"platform\": platform.platform(),\n",
        "        \"device\": device,\n",
        "        \"gpu_name\": gpu_name,\n",
        "        \"gpu_total_vram_mb\": total_vram_mb,\n",
        "        \"gpu_total_vram_gb\": total_vram_gb,\n",
        "        \"cuda_version\": cuda_version,\n",
        "        \"cudnn_version\": cudnn_version,\n",
        "    },\n",
        "    \"libraries\": {\n",
        "        \"torch\": torch_ver,\n",
        "        \"torchvision\": tv_ver,\n",
        "        \"timm\": timm_ver,\n",
        "        \"monai\": monai_ver,\n",
        "        \"torchmetrics\": tm_ver,\n",
        "        \"numpy\": np_ver,\n",
        "        \"pandas\": pd_ver,\n",
        "        \"albumentations\": alb_ver,\n",
        "        \"opencv-python (cv2)\": cv2_ver,\n",
        "        \"Pillow (PIL)\": pil_ver,\n",
        "        \"matplotlib\": mpl_ver,\n",
        "        \"pyyaml\": yaml_ver,\n",
        "        \"scikit-learn\": sk_ver,\n",
        "        \"psutil\": psutil_ver,\n",
        "        \"thop\": thop_ver,\n",
        "        \"fvcore\": fvcore_ver,\n",
        "    },\n",
        "}\n"
      ],
      "metadata": {
        "id": "MGEigRc2Gorp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 7/9 — Pretty print snapshot to console\n",
        "# ------------------------------------------------------------\n",
        "border = \"=\" * 70\n",
        "print(border)\n",
        "print(\"STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\")\n",
        "print(border)\n",
        "print(f\"Run Name      : {env_info['run']['run_name']}\")\n",
        "print(f\"Date/Time     : {env_info['run']['datetime']}\")\n",
        "print(f\"Dataset       : {env_info['run']['dataset']}\")\n",
        "print(f\"Image Size    : {env_info['run']['image_size']}\")\n",
        "print(f\"Batch Size    : {env_info['run']['batch_size']}\")\n",
        "print(f\"Epochs        : {env_info['run']['epochs']}\")\n",
        "print(f\"AMP (mixed precision): {env_info['run']['amp_on']}\")\n",
        "print(f\"Seed          : {env_info['run']['seed']}\")\n",
        "print(f\"Config Path   : {env_info['run']['config_path']}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Python        : {env_info['system']['python']}\")\n",
        "print(f\"Platform      : {env_info['system']['platform']}\")\n",
        "print(f\"Device        : {env_info['system']['device']}\")\n",
        "print(f\"GPU           : {env_info['system']['gpu_name']}\")\n",
        "print(f\"GPU VRAM      : {env_info['system']['gpu_total_vram_mb']} MB ({env_info['system']['gpu_total_vram_gb']} GB)\")\n",
        "print(f\"CUDA / cuDNN  : {env_info['system']['cuda_version']} / {env_info['system']['cudnn_version']}\")\n",
        "print(\"-\" * 70)\n",
        "print(\"Libraries:\")\n",
        "for lib, ver in env_info[\"libraries\"].items():\n",
        "    print(f\"  - {lib:<24} {ver}\")\n",
        "print(border)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RCdGFiAGou1",
        "outputId": "834307e7-f385-4847-dc96-c925bb11f3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\n",
            "======================================================================\n",
            "Run Name      : setr_model_busi_IMG256_SEED42_2025-11-04_15-45-47\n",
            "Date/Time     : 2025-11-04T15:47:19\n",
            "Dataset       : busi\n",
            "Image Size    : 256\n",
            "Batch Size    : 8\n",
            "Epochs        : 10\n",
            "AMP (mixed precision): True\n",
            "Seed          : 42\n",
            "Config Path   : configs/example.yaml (not found)\n",
            "----------------------------------------------------------------------\n",
            "Python        : 3.12.12\n",
            "Platform      : Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "Device        : cpu\n",
            "GPU           : N/A\n",
            "GPU VRAM      : N/A MB (N/A GB)\n",
            "CUDA / cuDNN  : 12.6 / 91002\n",
            "----------------------------------------------------------------------\n",
            "Libraries:\n",
            "  - torch                    2.8.0+cu126\n",
            "  - torchvision              0.23.0+cu126\n",
            "  - timm                     1.0.21\n",
            "  - monai                    1.5.1\n",
            "  - torchmetrics             1.8.2\n",
            "  - numpy                    2.0.2\n",
            "  - pandas                   2.3.3\n",
            "  - albumentations           1.4.4\n",
            "  - opencv-python (cv2)      4.12.0\n",
            "  - Pillow (PIL)             11.3.0\n",
            "  - matplotlib               3.10.0\n",
            "  - pyyaml                   6.0.3\n",
            "  - scikit-learn             1.6.1\n",
            "  - psutil                   5.9.5\n",
            "  - thop                     0.1.1\n",
            "  - fvcore                   0.1.5.post20221221\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 8/9 — Save TXT + JSON environment snapshots\n",
        "# ------------------------------------------------------------\n",
        "with open(summary_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(border + \"\\n\")\n",
        "    f.write(\"STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\\n\")\n",
        "    f.write(border + \"\\n\")\n",
        "    for section, payload in env_info.items():\n",
        "        f.write(f\"[{section.UPPER()}]\\n\" if hasattr(section, 'UPPER') else f\"[{section.upper()}]\\n\")\n",
        "        if isinstance(payload, dict):\n",
        "            for k, v in payload.items():\n",
        "                if isinstance(v, dict):\n",
        "                    f.write(f\"  {k}:\\n\")\n",
        "                    for kk, vv in v.items():\n",
        "                        f.write(f\"    - {kk}: {vv}\\n\")\n",
        "                else:\n",
        "                    f.write(f\"  - {k}: {v}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "with open(summary_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(env_info, f, indent=2)\n",
        "\n",
        "print(f\"Saved environment snapshots to:\\n  • {summary_txt_path}\\n  • {summary_json_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeaNK1igGoyH",
        "outputId": "76eb868c-05f2-421f-89fb-93135717295d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved environment snapshots to:\n",
            "  • /content/drive/MyDrive/setr_model_busi_Test/summary/setr_model_busi_IMG256_SEED42_2025-11-04_15-45-47_env.txt\n",
            "  • /content/drive/MyDrive/setr_model_busi_Test/summary/setr_model_busi_IMG256_SEED42_2025-11-04_15-45-47_env.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 9/9 — Initialize per-run CSV log header\n",
        "# ------------------------------------------------------------\n",
        "csv_path = root / \"logs\" / f\"{RUN_NAME}.csv\"\n",
        "if not csv_path.exists():\n",
        "    with open(csv_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"epoch,lr,train_loss,val_loss,train_dice,val_dice,train_iou,val_iou,epoch_time\\n\")\n",
        "print(f\"Initialized log CSV (if new): {csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4pE758CGo1K",
        "outputId": "b1ff05aa-5c5d-4bc0-888c-14a23e72dd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized log CSV (if new): /content/drive/MyDrive/setr_model_busi_Test/logs/setr_model_busi_IMG256_SEED42_2025-11-04_15-45-47.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD (BUSI, 256px) → MedSegBench cache\n",
        "# Cell 1/6 — Setup: cache dir, env var, and size\n",
        "# ------------------------------------------------------------\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "SIZE = 256\n",
        "cache_root = Path(\"/content/data/MedSegBenchCache\")\n",
        "cache_root.mkdir(parents=True, exist_ok=True)\n",
        "os.environ[\"MEDSEGBENCH_DIR\"] = str(cache_root)\n",
        "\n",
        "print(f\"[INFO] MEDSEGBENCH_DIR = {cache_root.resolve()}\")\n",
        "print(f\"[INFO] Target resolution = {SIZE}px\")\n",
        "\n",
        "!pip -q install medsegbench\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBl3jA_rMHZx",
        "outputId": "e2a0f5cc-2de3-4336-de43-d617a3ad85e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] MEDSEGBENCH_DIR = /content/data/MedSegBenchCache\n",
            "[INFO] Target resolution = 256px\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 2/6 — Dataset source details (Zenodo v1 record)\n",
        "# ------------------------------------------------------------\n",
        "target_name = f\"busi_{SIZE}.npz\"\n",
        "target_path = cache_root / target_name\n",
        "\n",
        "url = f\"https://zenodo.org/records/13358372/files/{target_name}?download=1\"\n",
        "\n",
        "# ✅ Put your BUSI_256 MD5 here (you mentioned you have it)\n",
        "expected_md5 = \"198aea70968b71adf593b32c41a6e995\"\n",
        "\n",
        "print(f\"[INFO] Target file  : {target_name}\")\n",
        "print(f\"[INFO] Download URL : {url}\")\n",
        "print(f\"[INFO] Expected MD5 : {expected_md5}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6EcLSkJMHWk",
        "outputId": "cbe05468-cc36-4b7b-fa4c-8b36e0beeb3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Target file  : busi_256.npz\n",
            "[INFO] Download URL : https://zenodo.org/records/13358372/files/busi_256.npz?download=1\n",
            "[INFO] Expected MD5 : 198aea70968b71adf593b32c41a6e995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 3/6 — Helpers (md5sum + download runners)\n",
        "# ------------------------------------------------------------\n",
        "import hashlib, subprocess, shutil\n",
        "\n",
        "def md5sum(path: Path) -> str:\n",
        "    h = hashlib.md5()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def download_file(url: str, out_path: Path) -> None:\n",
        "    curl = shutil.which(\"curl\")\n",
        "    if curl:\n",
        "        print(\"[INFO] Downloading with curl ...\")\n",
        "        subprocess.run([curl, \"-L\", \"-f\", url, \"-o\", str(out_path)], check=True)\n",
        "        return\n",
        "    wget = shutil.which(\"wget\")\n",
        "    if wget:\n",
        "        print(\"[INFO] curl not found; downloading with wget ...\")\n",
        "        subprocess.run([wget, \"-O\", str(out_path), url], check=True)\n",
        "        return\n",
        "    raise RuntimeError(\"Neither curl nor wget is available on PATH.\")\n"
      ],
      "metadata": {
        "id": "A8jRgZpiMHTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 4/6 — Download (idempotent)\n",
        "# ------------------------------------------------------------\n",
        "if not target_path.exists():\n",
        "    print(f\"[INFO] Downloading to {target_path} ...\")\n",
        "    try:\n",
        "        download_file(url, target_path)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        raise RuntimeError(f\"Downloader failed with return code {e.returncode}.\") from e\n",
        "else:\n",
        "    print(f\"[INFO] File already present: {target_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LhTqJv9MHQZ",
        "outputId": "4f84abd0-ebe3-4532-df8d-96d3365da40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Downloading to /content/data/MedSegBenchCache/busi_256.npz ...\n",
            "[INFO] Downloading with curl ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 5/6 — Integrity check (MD5)\n",
        "# ------------------------------------------------------------\n",
        "got = md5sum(target_path)\n",
        "print(f\"[INFO] MD5 (computed): {got}\")\n",
        "if expected_md5 and got != expected_md5:\n",
        "    raise RuntimeError(\n",
        "        f\"MD5 mismatch for {target_name}. Expected {expected_md5}, got {got}.\\n\"\n",
        "        \"Delete the file and rerun this step to redownload.\"\n",
        "    )\n",
        "print(f\"✅ Download + MD5 OK → {target_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gJTKINBMHNS",
        "outputId": "c4d9f639-24ff-4dc7-8f1a-11f6e62074f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] MD5 (computed): 198aea70968b71adf593b32c41a6e995\n",
            "✅ Download + MD5 OK → /content/data/MedSegBenchCache/busi_256.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 6/6 — Ready message\n",
        "# ------------------------------------------------------------\n",
        "print(\"[READY] busi (256px) cached in MEDSEGBENCH_DIR.\")\n",
        "print(\"[NEXT] STEP 2: Reproducibility & Config Lock; STEP 3: load predefined splits and print counts.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSfXw79FMVUz",
        "outputId": "69c8c3ce-a056-40b5-da22-01a7772875ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[READY] busi (256px) cached in MEDSEGBENCH_DIR.\n",
            "[NEXT] STEP 2: Reproducibility & Config Lock; STEP 3: load predefined splits and print counts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 1/5 — Resolve run knobs, paths, and dataset file\n",
        "# ------------------------------------------------------------\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "try: root\n",
        "except NameError: root = Path(\".\")\n",
        "\n",
        "DATASET    = globals().get(\"DATASET\", \"busi\")\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", 256))\n",
        "SEED       = int(globals().get(\"SEED\", 42))\n",
        "BATCH_SIZE = int(globals().get(\"BATCH_SIZE\", 8))\n",
        "EPOCHS     = int(globals().get(\"EPOCHS\", 10))\n",
        "AMP_ON     = bool(globals().get(\"AMP_ON\", True))\n",
        "MODEL_TAG  = globals().get(\"MODEL_TAG\", \"TransUNetLiteTiny_model\")\n",
        "RUN_NAME   = globals().get(\"RUN_NAME\", f\"{MODEL_TAG}_{DATASET}_IMG{IMAGE_SIZE}_SEED{SEED}\")\n",
        "CONFIG_PATH = globals().get(\"CONFIG_PATH\", \"configs/example.yaml\")\n",
        "\n",
        "RESOLUTION = int(globals().get(\"SIZE\", IMAGE_SIZE))\n",
        "\n",
        "msb_dir = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "busi_file = msb_dir / f\"busi_{RESOLUTION}.npz\"\n",
        "\n",
        "print(f\"[INFO] Artifacts root        : {root.resolve()}\")\n",
        "print(f\"[INFO] MEDSEGBENCH_DIR       : {msb_dir.resolve()}\")\n",
        "print(f\"[INFO] Expected busi file    : {busi_file}\")\n",
        "print(f\"[INFO] Run                   : {RUN_NAME}\")\n",
        "print(f\"[INFO] Model tag             : {MODEL_TAG}\")\n",
        "print(f\"[INFO] Seed / ImageSize      : {SEED} / {IMAGE_SIZE}\")\n",
        "print(f\"[INFO] Batch / Epochs / AMP  : {BATCH_SIZE} / {EPOCHS} / {AMP_ON}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyrNxgwAMVRp",
        "outputId": "77590571-5a2d-489e-965e-a9572ad16dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Artifacts root        : /content/drive/MyDrive/setr_model_busi_Test\n",
            "[INFO] MEDSEGBENCH_DIR       : /content/data/MedSegBenchCache\n",
            "[INFO] Expected busi file    : /content/data/MedSegBenchCache/busi_256.npz\n",
            "[INFO] Run                   : setr_model_busi_IMG256_SEED42_2025-11-04_15-45-47\n",
            "[INFO] Model tag             : setr_model\n",
            "[INFO] Seed / ImageSize      : 42 / 256\n",
            "[INFO] Batch / Epochs / AMP  : 8 / 10 / True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 2/5 — Seed + deterministic flags (re-assert)\n",
        "# ------------------------------------------------------------\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "    try: torch.use_deterministic_algorithms(True)\n",
        "    except Exception: pass\n",
        "    try:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    except Exception: pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "print(f\"[OK] Seeds set and deterministic flags applied (seed={SEED}).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH7NZHhtMVOy",
        "outputId": "ea0dda48-b1a9-4039-f080-87d6f6830141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Seeds set and deterministic flags applied (seed=42).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 3/5 — Build default config (if missing) and load it\n",
        "# ------------------------------------------------------------\n",
        "import yaml\n",
        "(root / \"configs\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "cfg_path = Path(CONFIG_PATH)\n",
        "if not cfg_path.exists():\n",
        "    cfg_path = root / \"configs\" / \"default_busi.yaml\"\n",
        "\n",
        "default_cfg = {\n",
        "    \"run\": {\"run_name\": RUN_NAME, \"seed\": SEED, \"amp_on\": AMP_ON},\n",
        "    \"data\": {\"dataset\": DATASET, \"resolution\": RESOLUTION, \"medsegbench_dir\": str(msb_dir), \"predefined_splits\": True},\n",
        "    \"train\": {\n",
        "        \"image_size\": IMAGE_SIZE, \"batch_size\": BATCH_SIZE, \"epochs\": EPOCHS, \"num_workers\": 4,\n",
        "        \"optimizer\": {\"name\": \"adamw\", \"lr\": 3e-4, \"weight_decay\": 1e-4},\n",
        "        \"scheduler\": {\"name\": \"cosine\", \"warmup_epochs\": 5},\n",
        "        \"early_stopping\": {\"monitor\": \"val_dice\", \"patience\": 20},\n",
        "        \"mixed_precision\": AMP_ON\n",
        "    },\n",
        "    \"augment\": {\n",
        "        \"geometric\": {\"flip\": True, \"rotate\": True, \"scale\": True, \"elastic\": False},\n",
        "        \"appearance\": {\"brightness_contrast\": True, \"blur_noise\": True},\n",
        "        \"probabilities\": {\"flip\": 0.5, \"rotate\": 0.3, \"scale\": 0.3, \"brightness_contrast\": 0.3, \"blur_noise\": 0.2}\n",
        "    },\n",
        "    \"loss\": {\"primary\": \"dice_bce\", \"weights\": {\"dice\": 0.7, \"bce\": 0.3}},\n",
        "    \"metrics\": {\"threshold\": 0.5, \"report\": [\"dice\", \"iou\"]},\n",
        "    \"logging\": {\n",
        "        \"artifacts_root\": str(root.resolve()),\n",
        "        \"print_per_epoch_fields\": [\"epoch\",\"lr\",\"train_loss\",\"val_loss\",\"train_dice\",\"val_dice\",\"train_iou\",\"val_iou\",\"epoch_time\"],\n",
        "        \"save_csv_per_epoch\": True,\n",
        "        \"save_best_by\": \"val_dice\"\n",
        "    },\n",
        "    \"model\": {\"name\": MODEL_TAG, \"scale\": \"auto\", \"params\": {}}\n",
        "}\n",
        "\n",
        "if not Path(CONFIG_PATH).exists():\n",
        "    with open(cfg_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        yaml.safe_dump(default_cfg, f, sort_keys=False)\n",
        "    print(f\"[INFO] Created default config at: {cfg_path.resolve()}\")\n",
        "else:\n",
        "    cfg_path = Path(CONFIG_PATH)\n",
        "\n",
        "with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "print(f\"[OK] Loaded config from: {cfg_path.resolve()}\")\n",
        "print(f\"[INFO] Config run_name: {cfg['run'].get('run_name')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6rnSmDxMeTZ",
        "outputId": "f6cf11e0-df1e-4f70-cab6-331e09571acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Created default config at: /content/drive/MyDrive/setr_model_busi_Test/configs/default_busi.yaml\n",
            "[OK] Loaded config from: /content/drive/MyDrive/setr_model_busi_Test/configs/default_busi.yaml\n",
            "[INFO] Config run_name: setr_model_busi_IMG256_SEED42_2025-11-04_15-45-47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 4/5 — Sanity checks: dataset presence & key fields\n",
        "# ------------------------------------------------------------\n",
        "problems = []\n",
        "\n",
        "if not busi_file.exists():\n",
        "    problems.append(f\"Missing dataset cache file: {busi_file}\")\n",
        "\n",
        "required_keys = [\n",
        "    (\"run\", \"seed\"), (\"data\", \"medsegbench_dir\"), (\"data\", \"resolution\"),\n",
        "    (\"train\", \"batch_size\"), (\"train\", \"epochs\"),\n",
        "    (\"loss\", \"primary\"), (\"metrics\", \"threshold\"), (\"model\", \"name\"),\n",
        "]\n",
        "for sect, key in required_keys:\n",
        "    if sect not in cfg or key not in cfg[sect]:\n",
        "        problems.append(f\"Config missing: {sect}.{key}\")\n",
        "\n",
        "if problems:\n",
        "    print(\"[WARN] Sanity check issues:\")\n",
        "    for p in problems: print(\" -\", p)\n",
        "else:\n",
        "    print(\"[OK] Dataset file present and config has required keys.\")\n",
        "\n",
        "print(f\"[ECHO] Using dataset cache: {busi_file}\")\n",
        "print(f\"[ECHO] MEDSEGBENCH_DIR   : {msb_dir}\")\n",
        "print(f\"[ECHO] Model name        : {cfg['model']['name']}\")\n",
        "print(f\"[ECHO] Loss              : {cfg['loss']['primary']} (weights={cfg['loss'].get('weights')})\")\n",
        "print(f\"[ECHO] Metrics threshold : {cfg['metrics']['threshold']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-0MG3hAMeQO",
        "outputId": "41b9bf97-5712-4dcb-97bf-6343977bfd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Dataset file present and config has required keys.\n",
            "[ECHO] Using dataset cache: /content/data/MedSegBenchCache/busi_256.npz\n",
            "[ECHO] MEDSEGBENCH_DIR   : /content/data/MedSegBenchCache\n",
            "[ECHO] Model name        : setr_model\n",
            "[ECHO] Loss              : dice_bce (weights={'dice': 0.7, 'bce': 0.3})\n",
            "[ECHO] Metrics threshold : 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 5/5 — Snapshot config for this run\n",
        "# ------------------------------------------------------------\n",
        "(root / \"summary\").mkdir(parents=True, exist_ok=True)\n",
        "cfg_snapshot = root / \"summary\" / f\"{RUN_NAME}_config.yaml\"\n",
        "with open(cfg_snapshot, \"w\", encoding=\"utf-8\") as f:\n",
        "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
        "\n",
        "print(f\"[OK] Saved config snapshot to: {cfg_snapshot.resolve()}\")\n",
        "print(\"[NEXT] STEP 3 will load MedSegBench predefined splits and print sample counts per set (no re-splitting).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_7dS00IMeNp",
        "outputId": "544118b9-f5c8-4fb7-c479-98651e7026dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved config snapshot to: /content/drive/MyDrive/setr_model_busi_Test/summary/setr_model_busi_IMG256_SEED42_2025-11-04_15-45-47_config.yaml\n",
            "[NEXT] STEP 3 will load MedSegBench predefined splits and print sample counts per set (no re-splitting).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 1/4 — Resolve paths and open the cached NPZ\n",
        "# ------------------------------------------------------------\n",
        "import numpy as np\n",
        "\n",
        "msb_dir = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "RESOLUTION = int(globals().get(\"RESOLUTION\", globals().get(\"SIZE\", 256)))\n",
        "busi_file = msb_dir / f\"busi_{RESOLUTION}.npz\"\n",
        "assert busi_file.exists(), f\"Expected dataset file not found: {busi_file}\"\n",
        "\n",
        "npz = np.load(busi_file, allow_pickle=True)\n",
        "keys = list(npz.keys())\n",
        "print(f\"[INFO] Loaded: {busi_file}\")\n",
        "print(f\"[ECHO] MEDSEGBENCH_DIR: {msb_dir.resolve()}\")\n",
        "print(f\"[INFO] NPZ keys ({len(keys)}): {keys[:12]}{'...' if len(keys)>12 else ''}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OWsTb-XMeKx",
        "outputId": "4e711655-c24d-4781-e711-46bd3380e7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded: /content/data/MedSegBenchCache/busi_256.npz\n",
            "[ECHO] MEDSEGBENCH_DIR: /content/data/MedSegBenchCache\n",
            "[INFO] NPZ keys (18): ['train_images_C1', 'train_label_C1', 'train_images_C2', 'train_label_C2', 'test_images_C1', 'test_label_C1', 'test_images_C2', 'test_label_C2', 'val_images_C1', 'val_label_C1', 'val_images_C2', 'val_label_C2']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 2/4 — Infer split format (supports *_label/_labels)\n",
        "# ------------------------------------------------------------\n",
        "def _as_list(x):\n",
        "    if isinstance(x, np.ndarray): x = x.tolist()\n",
        "    return list(x) if isinstance(x, (list, tuple)) else [x]\n",
        "\n",
        "def infer_splits(npz_obj):\n",
        "    k = set(npz_obj.keys())\n",
        "\n",
        "    # Case A: per-split arrays (preferred)\n",
        "    def _find_lbl_key(split):\n",
        "        for suffix in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "            cand = f\"{split}_{suffix}\"\n",
        "            if cand in k: return cand\n",
        "        return None\n",
        "\n",
        "    have_all = True\n",
        "    meta = {}\n",
        "    for s in (\"train\",\"val\",\"test\"):\n",
        "        ik = f\"{s}_images\"; lk = _find_lbl_key(s)\n",
        "        if ik in k and lk in k and len(npz_obj[ik]) == len(npz_obj[lk]):\n",
        "            meta[s] = {\"n\": len(npz_obj[ik]), \"img_key\": ik, \"lbl_key\": lk}\n",
        "        else:\n",
        "            have_all = False; break\n",
        "    if have_all:\n",
        "        counts = {s: meta[s][\"n\"] for s in meta}\n",
        "        idx    = {s: list(range(meta[s][\"n\"])) for s in meta}\n",
        "        return counts, idx, \"A(images+labels)\"\n",
        "\n",
        "    # Case B: global arrays + explicit indices\n",
        "    for tri, vai, tei in [(\"train_idx\",\"val_idx\",\"test_idx\"),\n",
        "                          (\"train_indices\",\"val_indices\",\"test_indices\"),\n",
        "                          (\"split_train\",\"split_val\",\"split_test\")]:\n",
        "        if tri in k and vai in k and tei in k:\n",
        "            tr, va, te = _as_list(npz_obj[tri]), _as_list(npz_obj[vai]), _as_list(npz_obj[tei])\n",
        "            counts = {\"train\": len(tr), \"val\": len(va), \"test\": len(te)}\n",
        "            idx    = {\"train\": tr, \"val\": va, \"test\": te}\n",
        "            return counts, idx, \"B(indices)\"\n",
        "\n",
        "    raise RuntimeError(\"Could not infer predefined splits (need per-split arrays or *_idx lists).\")\n",
        "\n",
        "counts, split_idx, pattern = infer_splits(npz)\n",
        "print(f\"[OK] Split pattern detected: Case {pattern}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR2jkJQdMeH6",
        "outputId": "0528727e-de75-4e01-aa37-048f8bf0e8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Split pattern detected: Case A(images+labels)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS (SPEED-UP, OPTIONAL)\n",
        "# Cell 2.5/4 — Materialize arrays to RAM and rebind `npz`\n",
        "# ------------------------------------------------------------\n",
        "npz_ram = {}\n",
        "for k in keys:\n",
        "    obj = npz[k]\n",
        "    try: npz_ram[k] = obj[:] if isinstance(obj, np.ndarray) else obj\n",
        "    except Exception: npz_ram[k] = obj\n",
        "\n",
        "try: npz.close()\n",
        "except Exception: pass\n",
        "npz = npz_ram\n",
        "\n",
        "def _shape(x): return getattr(x, \"shape\", None)\n",
        "print(\"[SPEED] NPZ materialized to RAM. Example shapes:\")\n",
        "for probe in [\"train_images\",\"train_label\",\"train_masks\",\"val_images\",\"val_label\",\"test_images\",\"test_label\"]:\n",
        "    if probe in npz:\n",
        "        print(f\"  • {probe}: {_shape(npz[probe])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwR2CDMlNEWg",
        "outputId": "54d35c1f-8257-410c-b449-0b0942779f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SPEED] NPZ materialized to RAM. Example shapes:\n",
            "  • train_images: (452, 256, 256)\n",
            "  • train_label: (452, 256, 256)\n",
            "  • val_images: (64, 256, 256)\n",
            "  • val_label: (64, 256, 256)\n",
            "  • test_images: (131, 256, 256)\n",
            "  • test_label: (131, 256, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 3/4 — Print counts per set\n",
        "# ------------------------------------------------------------\n",
        "print(\"[COUNTS] Samples per split (predefined by MedSegBench)\")\n",
        "print(f\"  • Train : {counts['train']}\")\n",
        "print(f\"  • Val   : {counts['val']}\")\n",
        "print(f\"  • Test  : {counts['test']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilq_e8DpNET1",
        "outputId": "7fea23c6-8049-4d92-b651-5c4ccc49fd5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[COUNTS] Samples per split (predefined by MedSegBench)\n",
            "  • Train : 452\n",
            "  • Val   : 64\n",
            "  • Test  : 131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 4/4 — Save IDs to disk for reproducibility\n",
        "# ------------------------------------------------------------\n",
        "summary_dir = Path(globals().get(\"root\", Path(\".\"))) / \"summary\"\n",
        "summary_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def write_list(path: Path, arr):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for x in arr: f.write(f\"{x}\\n\")\n",
        "\n",
        "train_ids_path = summary_dir / f\"busi_{RESOLUTION}_train_ids.txt\"\n",
        "val_ids_path   = summary_dir / f\"busi_{RESOLUTION}_val_ids.txt\"\n",
        "test_ids_path  = summary_dir / f\"busi_{RESOLUTION}_test_ids.txt\"\n",
        "\n",
        "write_list(train_ids_path, split_idx[\"train\"])\n",
        "write_list(val_ids_path,   split_idx[\"val\"])\n",
        "write_list(test_ids_path,  split_idx[\"test\"])\n",
        "\n",
        "print(\"[OK] Saved split ID lists:\")\n",
        "print(f\"  • {train_ids_path}\")\n",
        "print(f\"  • {val_ids_path}\")\n",
        "print(f\"  • {test_ids_path}\")\n",
        "print(\"[NEXT] STEP 4 will cover preprocessing pipeline (resize/normalize) and identical augmentations.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYL96afWNERC",
        "outputId": "c7908811-4869-4e24-c77a-fd7a26e4917c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved split ID lists:\n",
            "  • /content/drive/MyDrive/setr_model_busi_Test/summary/busi_256_train_ids.txt\n",
            "  • /content/drive/MyDrive/setr_model_busi_Test/summary/busi_256_val_ids.txt\n",
            "  • /content/drive/MyDrive/setr_model_busi_Test/summary/busi_256_test_ids.txt\n",
            "[NEXT] STEP 4 will cover preprocessing pipeline (resize/normalize) and identical augmentations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS (IDENTICAL POLICY)\n",
        "# Cell 1/5 — Imports, constants, and NPZ reload\n",
        "# ------------------------------------------------------------\n",
        "import numpy as np, torch\n",
        "from pathlib import Path\n",
        "\n",
        "RESOLUTION = int(globals().get(\"RESOLUTION\", globals().get(\"SIZE\", 256)))\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", RESOLUTION))\n",
        "BATCH_SIZE = int(globals().get(\"BATCH_SIZE\", 8))\n",
        "\n",
        "NORM_MEAN = (0.485, 0.456, 0.406)\n",
        "NORM_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "msb_dir   = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "busi_file = msb_dir / f\"busi_{RESOLUTION}.npz\"\n",
        "assert busi_file.exists(), f\"Expected dataset file not found: {busi_file}\"\n",
        "\n",
        "npz_l = np.load(busi_file, allow_pickle=True)\n",
        "\n",
        "def _as_list(x):\n",
        "    if isinstance(x, np.ndarray): x = x.tolist()\n",
        "    return list(x) if isinstance(x, (list, tuple)) else [x]\n",
        "\n",
        "def _infer_splits(npz_obj):\n",
        "    k = set(npz_obj.keys())\n",
        "    def _find_lbl_key(split):\n",
        "        for suffix in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "            cand = f\"{split}_{suffix}\"\n",
        "            if cand in k: return cand\n",
        "        return None\n",
        "    have_all = True\n",
        "    meta = {}\n",
        "    for s in (\"train\",\"val\",\"test\"):\n",
        "        ik = f\"{s}_images\"; lk = _find_lbl_key(s)\n",
        "        if ik in k and lk in k:\n",
        "            n = len(npz_obj[ik])\n",
        "            if n != len(npz_obj[lk]): raise RuntimeError(f\"{s}: images != labels length\")\n",
        "            meta[s] = {\"n\": n, \"img_key\": ik, \"lbl_key\": lk}\n",
        "        else:\n",
        "            have_all = False; break\n",
        "    if have_all:\n",
        "        return {s: meta[s][\"n\"] for s in meta}, {s: list(range(meta[s][\"n\"])) for s in meta}\n",
        "    for tri, vai, tei in [(\"train_idx\",\"val_idx\",\"test_idx\"),\n",
        "                          (\"train_indices\",\"val_indices\",\"test_indices\"),\n",
        "                          (\"split_train\",\"split_val\",\"split_test\")]:\n",
        "        if tri in k and vai in k and tei in k:\n",
        "            tr = _as_list(npz_obj[tri]); va = _as_list(npz_obj[vai]); te = _as_list(npz_obj[tei])\n",
        "            return {\"train\": len(tr), \"val\": len(va), \"test\": len(te)}, {\"train\": tr, \"val\": va, \"test\": te}\n",
        "    raise RuntimeError(\"Could not re-infer splits; ensure STEP 3 ran successfully.\")\n",
        "\n",
        "if \"counts\" in globals() and \"split_idx\" in globals():\n",
        "    _counts, _split_idx = counts, split_idx\n",
        "else:\n",
        "    _counts, _split_idx = _infer_splits(npz_l)\n",
        "\n",
        "print(f\"[INFO] Using NPZ: {busi_file}\")\n",
        "print(f\"[INFO] Image size policy: RESOLUTION={RESOLUTION} → NETWORK INPUT={IMAGE_SIZE}\")\n",
        "print(f\"[COUNTS] train={_counts['train']}  val={_counts['val']}  test={_counts['test']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCUg-BK-NEKg",
        "outputId": "c3e2ea63-1ab6-4058-80b7-c8b6dbd27fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using NPZ: /content/data/MedSegBenchCache/busi_256.npz\n",
            "[INFO] Image size policy: RESOLUTION=256 → NETWORK INPUT=256\n",
            "[COUNTS] train=452  val=64  test=131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 2/5 — Albumentations transforms (train/val/test)\n",
        "# ------------------------------------------------------------\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "resize_ops = []\n",
        "if IMAGE_SIZE != RESOLUTION:\n",
        "    resize_ops = [A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, interpolation=1)]  # 1=bilinear\n",
        "\n",
        "train_tf = A.Compose([\n",
        "    *resize_ops,\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.15, rotate_limit=15, border_mode=0, p=0.3),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.GaussianBlur(blur_limit=(3,5), p=0.15),\n",
        "    A.GaussNoise(var_limit=(5.0, 20.0), p=0.15),\n",
        "    A.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
        "    ToTensorV2(transpose_mask=True),\n",
        "])\n",
        "\n",
        "val_tf = A.Compose([\n",
        "    *resize_ops,\n",
        "    A.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
        "    ToTensorV2(transpose_mask=True),\n",
        "])\n",
        "\n",
        "test_tf = val_tf\n",
        "print(\"[OK] Transforms configured (train/val/test).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRltv3HENMhd",
        "outputId": "fdc8a43a-664c-4b69-fddf-f61c57dc56c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Transforms configured (train/val/test).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 3/5 — Dataset that memory-maps the NPZ (ISICNPZDataset-style)\n",
        "# ------------------------------------------------------------\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def _label_key_for(split, npz_obj_or_keys):\n",
        "    k = set(npz_obj_or_keys if isinstance(npz_obj_or_keys, (set,list,tuple)) else npz_obj_or_keys.keys())\n",
        "    for suf in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "        cand = f\"{split}_{suf}\"\n",
        "        if cand in k: return cand\n",
        "    raise KeyError(f\"No label key found for split={split}.\")\n",
        "\n",
        "class ISICNPZDataset(Dataset):\n",
        "    def __init__(self, npz_path, split: str, indices, transform=None):\n",
        "        super().__init__()\n",
        "        self.path = str(npz_path)\n",
        "        _peek = np.load(self.path, allow_pickle=True, mmap_mode=\"r\")\n",
        "        self.img_key = f\"{split}_images\"\n",
        "        self.lbl_key = _label_key_for(split, _peek)\n",
        "        self.length = len(_peek[self.img_key])\n",
        "        assert self.length == len(_peek[self.lbl_key]), \"Images/labels length mismatch.\"\n",
        "        _peek.close()\n",
        "\n",
        "        self.split = split\n",
        "        self.indices = list(indices)\n",
        "        self.transform = transform\n",
        "        self._npz = None\n",
        "\n",
        "    def _ensure_open(self):\n",
        "        if self._npz is None:\n",
        "            self._npz = np.load(self.path, allow_pickle=True, mmap_mode=\"r\")\n",
        "\n",
        "    def __len__(self): return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        self._ensure_open()\n",
        "        i = self.indices[idx]\n",
        "        img = self._npz[self.img_key][i]  # HxW or HxWx3\n",
        "        msk = self._npz[self.lbl_key][i]  # HxW\n",
        "\n",
        "        if img.ndim == 2: img = np.stack([img, img, img], axis=-1)\n",
        "        if msk.max() > 1: msk = (msk > 127).astype(np.uint8)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            out = self.transform(image=img, mask=msk)\n",
        "            img_t = out[\"image\"]\n",
        "            msk_t = out[\"mask\"].unsqueeze(0) if out[\"mask\"].ndim == 2 else out[\"mask\"]\n",
        "        else:\n",
        "            img_f = img.astype(np.float32) / 255.0\n",
        "            img_f = (img_f - np.array(NORM_MEAN)) / np.array(NORM_STD)\n",
        "            img_t = torch.from_numpy(img_f).permute(2,0,1).contiguous()\n",
        "            msk_t = torch.from_numpy(msk.astype(np.float32)).unsqueeze(0)\n",
        "\n",
        "        return img_t, msk_t\n",
        "\n",
        "    def __del__(self):\n",
        "        try:\n",
        "            if self._npz is not None: self._npz.close()\n",
        "        except Exception: pass\n"
      ],
      "metadata": {
        "id": "hDWGycNJNMej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 4/5 — DataLoaders with safe settings\n",
        "# ------------------------------------------------------------\n",
        "from torch.utils.data import DataLoader\n",
        "import torch, os\n",
        "\n",
        "train_ds = ISICNPZDataset(busi_file, \"train\", _split_idx[\"train\"], transform=train_tf)\n",
        "val_ds   = ISICNPZDataset(busi_file, \"val\",   _split_idx[\"val\"],   transform=val_tf)\n",
        "test_ds  = ISICNPZDataset(busi_file, \"test\",  _split_idx[\"test\"],  transform=test_tf)\n",
        "\n",
        "num_workers = 2\n",
        "pin = torch.cuda.is_available()\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=True, prefetch_factor=2, persistent_workers=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=False, prefetch_factor=2, persistent_workers=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=1, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=False, prefetch_factor=2, persistent_workers=True)\n",
        "\n",
        "xb, yb = next(iter(train_loader))\n",
        "print(f\"[OK] Train batch shapes: images={tuple(xb.shape)} masks={tuple(yb.shape)}\")\n",
        "print(f\"[INFO] num_workers={num_workers}, pin_memory={pin}, batch_size={BATCH_SIZE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JikBr2VLNMb4",
        "outputId": "3e67c769-3df7-4fb1-9b44-7e4b0443ddcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Train batch shapes: images=(8, 3, 256, 256) masks=(8, 1, 256, 256)\n",
            "[INFO] num_workers=2, pin_memory=False, batch_size=8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 5/5 — Policy echo (for the paper/log)\n",
        "# ------------------------------------------------------------\n",
        "print(\"[POLICY] Preprocessing/Normalization\")\n",
        "print(f\"  • Resize to: {IMAGE_SIZE}x{IMAGE_SIZE} (if different from NPZ {RESOLUTION})\")\n",
        "print(f\"  • Normalize (ImageNet): mean={NORM_MEAN}, std={NORM_STD}\")\n",
        "print(\"[POLICY] Train augmentations\")\n",
        "print(\"  • HorizontalFlip p=0.5\")\n",
        "print(\"  • ShiftScaleRotate (±2% shift, ±15% scale, ±15° rotate) p=0.3\")\n",
        "print(\"  • Brightness/Contrast p=0.3\")\n",
        "print(\"  • GaussianBlur p=0.15, GaussNoise p=0.15\")\n",
        "print(\"[POLICY] Val/Test: no augmentations (only resize + normalize)\")\n",
        "print(\"[READY] DataLoaders prepared. Next: STEP 5 (Data sanity visuals).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu6Q26YTNMY6",
        "outputId": "b7a45b40-c12a-41a2-8750-d7447b2cf222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[POLICY] Preprocessing/Normalization\n",
            "  • Resize to: 256x256 (if different from NPZ 256)\n",
            "  • Normalize (ImageNet): mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
            "[POLICY] Train augmentations\n",
            "  • HorizontalFlip p=0.5\n",
            "  • ShiftScaleRotate (±2% shift, ±15% scale, ±15° rotate) p=0.3\n",
            "  • Brightness/Contrast p=0.3\n",
            "  • GaussianBlur p=0.15, GaussNoise p=0.15\n",
            "[POLICY] Val/Test: no augmentations (only resize + normalize)\n",
            "[READY] DataLoaders prepared. Next: STEP 5 (Data sanity visuals).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3RqUb60LNMWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# Cell 1/4\n",
        "# ------------------------------------------------------------\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "if \"ConvBNReLU\" not in globals():\n",
        "    class ConvBNReLU(nn.Module):\n",
        "        def __init__(self, in_ch, out_ch, k=3, s=1, p=1):\n",
        "            super().__init__()\n",
        "            self.conv = nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)\n",
        "            self.bn   = nn.BatchNorm2d(out_ch)\n",
        "            self.act  = nn.ReLU(inplace=True)\n",
        "        def forward(self, x): return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class SETR_PUP(nn.Module):\n",
        "    \"\"\"\n",
        "    Paper-style SETR (Zheng et al.): pure ViT encoder + Progressive UPsampling (PUP) decoder.\n",
        "      • ViT-B/16 pretrained → tokens @ 1/16 grid (C=768).\n",
        "      • PUP: a stack of conv+upsample stages to reach H×W without CNN encoder skips.\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=256, embed_dim=768):\n",
        "        super().__init__()\n",
        "        self.vit = timm.create_model(\"vit_base_patch16_224\", pretrained=True,\n",
        "                                     num_classes=0, global_pool=\"\", img_size=img_size)\n",
        "        self.embed_dim = getattr(self.vit, \"num_features\", embed_dim)\n",
        "        self.patch = 16\n",
        "\n",
        "        # PUP decoder (progressive upsampling)\n",
        "        self.dec16 = ConvBNReLU(self.embed_dim, 512, 3, 1, 1)   # H/16\n",
        "        self.dec8  = ConvBNReLU(512, 256, 3, 1, 1)              # H/8\n",
        "        self.dec4  = ConvBNReLU(256, 128, 3, 1, 1)              # H/4\n",
        "        self.dec2  = ConvBNReLU(128,  64, 3, 1, 1)              # H/2\n",
        "        self.head  = nn.Conv2d(64, 1, 1)\n",
        "\n",
        "    def _tokens_to_map(self, feats, H, W):\n",
        "        if feats.size(1) == (H//self.patch)*(W//self.patch) + 1:\n",
        "            feats = feats[:, 1:, :]\n",
        "        B, N, C = feats.shape\n",
        "        gh, gw = H//self.patch, W//self.patch\n",
        "        return feats.transpose(1, 2).contiguous().view(B, C, gh, gw)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, _, H, W = x.shape\n",
        "        feats = self.vit.forward_features(x)           # (B, 1+N, 768)\n",
        "        f16  = self._tokens_to_map(feats, H, W)        # (B,768,H/16,W/16)\n",
        "\n",
        "        y = self.dec16(f16)                            # H/16\n",
        "        y = F.interpolate(y, scale_factor=2, mode=\"bilinear\", align_corners=False)  # → H/8\n",
        "        y = self.dec8(y)\n",
        "        y = F.interpolate(y, scale_factor=2, mode=\"bilinear\", align_corners=False)  # → H/4\n",
        "        y = self.dec4(y)\n",
        "        y = F.interpolate(y, scale_factor=2, mode=\"bilinear\", align_corners=False)  # → H/2\n",
        "        y = self.dec2(y)\n",
        "        y = F.interpolate(y, scale_factor=2, mode=\"bilinear\", align_corners=False)  # → H\n",
        "        logits = self.head(y)\n",
        "        return {\"logits\": logits}\n",
        "\n"
      ],
      "metadata": {
        "id": "tldnF90ENMTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# Cell 2/4 — CPU fairness + CKPT path + preload 50 RAW test samples\n",
        "# (SAFE: avoid set_num_interop_threads error if threads already started)\n",
        "# ------------------------------------------------------------\n",
        "import os, psutil, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# ---- CPU fairness (as requested) ----\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"MKL_NUM_THREADS\"]  = \"1\"\n",
        "\n",
        "import torch\n",
        "\n",
        "# Always safe at runtime:\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "# set_num_interop_threads must be called before any parallel work; try, else continue.\n",
        "try:\n",
        "    if hasattr(torch, \"set_num_interop_threads\"):\n",
        "        torch.set_num_interop_threads(1)\n",
        "except RuntimeError as e:\n",
        "    # Already started parallel work; keep current interop setting but log it.\n",
        "    print(f\"[WARN] {e} — continuing with interop_threads={getattr(torch, 'get_num_interop_threads', lambda: 'N/A')()}\")\n",
        "\n",
        "DEVICE = \"cpu\"\n",
        "print(f\"[CPU] threads={torch.get_num_threads()} \"\n",
        "      f\"interop={getattr(torch, 'get_num_interop_threads', lambda: 'N/A')()} \"\n",
        "      f\"OMP={os.getenv('OMP_NUM_THREADS')} MKL={os.getenv('MKL_NUM_THREADS')}\")\n",
        "\n",
        "# ---- threshold from cfg (fallback 0.5) ----\n",
        "THRESH = float(cfg.get(\"metrics\", {}).get(\"threshold\", 0.5)) if \"cfg\" in globals() else 0.5\n",
        "print(f\"[INFO] THRESH={THRESH}\")\n",
        "\n",
        "# ---- your exact trained checkpoint path ----\n",
        "from pathlib import Path\n",
        "CKPT_PATH = \"/content/drive/MyDrive/setr_model_busi_2/checkpoints/setr_model_busi_IMG256_SEED42_2025-11-04_15-02-28_best.pt\"  # <<< EDIT THIS\n",
        "if not Path(CKPT_PATH).exists():\n",
        "    raise FileNotFoundError(f\"Checkpoint not found: {CKPT_PATH}\")\n",
        "\n",
        "# ---- build a 50-sample test index (first 50 of split) ----\n",
        "NUM_SAMPLES = 50\n",
        "WARMUP = 5\n",
        "test_ids = split_idx[\"test\"]\n",
        "if len(test_ids) < NUM_SAMPLES:\n",
        "    raise ValueError(f\"Test set has {len(test_ids)} samples; need at least {NUM_SAMPLES}.\")\n",
        "sel_ids = test_ids[:NUM_SAMPLES]\n",
        "\n",
        "# ---- preload RAW arrays (avoid disk I/O in timing) ----\n",
        "# Note: transforms/tensorization are INSIDE timing for end-to-end latency.\n",
        "test_img_key = \"test_images\"\n",
        "for lblk in (\"test_masks\",\"test_mask\",\"test_labels\",\"test_label\"):\n",
        "    if lblk in npz: test_lbl_key = lblk; break\n",
        "else:\n",
        "    raise KeyError(\"No test label key among {test_masks, test_mask, test_labels, test_label}.\")\n",
        "\n",
        "raw_samples = []\n",
        "for i in sel_ids:\n",
        "    img = npz[test_img_key][i]\n",
        "    msk = npz[test_lbl_key][i]\n",
        "    raw_samples.append((img, msk))\n",
        "print(f\"[OK] Preloaded RAW {len(raw_samples)} test samples into RAM.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlF04X77Nl7Y",
        "outputId": "7c996021-a7d1-4b3b-ba4e-a02369cb3a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CPU] threads=1 interop=1 OMP=1 MKL=1\n",
            "[INFO] THRESH=0.5\n",
            "[OK] Preloaded RAW 50 test samples into RAM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVAL\n",
        "# Cell 3/4 (REPLACED) — Instantiate model + CLEAN LOAD (CPU)\n",
        "# ------------------------------------------------------------\n",
        "from pathlib import Path\n",
        "import re, torch\n",
        "\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", 256))\n",
        "model = SETR_PUP(img_size=IMAGE_SIZE, embed_dim=768).to(\"cpu\")\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "\n",
        "def unwrap_state(d):\n",
        "    # common wrappers\n",
        "    for k in [\"model_state\",\"state_dict\",\"model\",\"net\",\"ema\",\"model_state_dict\"]:\n",
        "        if isinstance(d, dict) and k in d and isinstance(d[k], dict):\n",
        "            return d[k]\n",
        "    return d if isinstance(d, dict) else {}\n",
        "\n",
        "raw = unwrap_state(ckpt)\n",
        "\n",
        "# 1) strip 'module.' prefix\n",
        "clean = {}\n",
        "for k, v in raw.items():\n",
        "    nk = k[7:] if k.startswith(\"module.\") else k\n",
        "    clean[nk] = v\n",
        "\n",
        "# 2) drop profiling buffers (from thop/fvcore)\n",
        "def is_profile_key(k: str) -> bool:\n",
        "    return k.endswith(\".total_ops\") or k.endswith(\".total_params\")\n",
        "clean = {k:v for k,v in clean.items() if not is_profile_key(k)}\n",
        "\n",
        "# 3) optional prefix remaps (adapt if your training used different names)\n",
        "#    e.g., 'backbone.' -> 'vit.' , 'encoder.' -> 'vit.' , 'transformer.' -> 'vit.'\n",
        "remaps = [\n",
        "    (r\"^backbone\\.\", \"vit.\"),\n",
        "    (r\"^encoder\\.\",  \"vit.\"),\n",
        "    (r\"^transformer\\.\", \"vit.\"),\n",
        "]\n",
        "remapped = {}\n",
        "for k, v in clean.items():\n",
        "    nk = k\n",
        "    for pat, rep in remaps:\n",
        "        nk = re.sub(pat, rep, nk)\n",
        "    remapped[nk] = v\n",
        "clean = remapped\n",
        "\n",
        "# 4) keep only keys that exist in current model (exact-name intersection)\n",
        "model_sd = model.state_dict()\n",
        "intersect = {k:v for k,v in clean.items() if k in model_sd and v.shape == model_sd[k].shape}\n",
        "\n",
        "# 5) report coverage\n",
        "print(f\"[CKPT] total keys in state: {len(raw)}\")\n",
        "print(f\"[CKPT] after strip+drop:     {len(clean)}\")\n",
        "print(f\"[CKPT] intersect (name+shape): {len(intersect)} / model expects {len(model_sd)}\")\n",
        "\n",
        "# 6) load intersect only (others remain as initialized / DeiT pretrained)\n",
        "missing_before = set(model_sd.keys()) - set(intersect.keys())\n",
        "load_res = model_sd.copy()\n",
        "load_res.update(intersect)\n",
        "model.load_state_dict(load_res, strict=False)\n",
        "\n",
        "# sanity: print what we still miss (first 40)\n",
        "still_missing = list(set(model.state_dict().keys()) - set(intersect.keys()))\n",
        "print(f\"[LOAD] missing (after clean) ~ {len(still_missing)} (showing up to 40)\")\n",
        "print(still_missing[:40])\n",
        "\n",
        "model.eval()\n",
        "print(\"[OK] Cleaned checkpoint loaded into model on CPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "08538750e62d4f1ab0a611407cf0759e",
            "f14c17e672a0417f95c2cdaa7e103c28",
            "a4b2613e43d740c9bbe5da8bc370512f",
            "dce4d7995f8041078ec19bb82c9bb838",
            "a26b5b830cee42c9a3b4e1932807c121",
            "f32e7b612266440482c90c38a62590c8",
            "525717ead1f54775868cfcdd24f31558",
            "b47782afb74042859b01133e35a7694c",
            "b2bca01242c441f2840b5b264b03d021",
            "0626350e47b1458e921691818e258ea8",
            "782a24ec3dea497d8beedc5c2768a703"
          ]
        },
        "id": "zp39FVeBePV5",
        "outputId": "c928f9d8-fcb0-4e9e-94ec-9373b0eaf7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08538750e62d4f1ab0a611407cf0759e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CKPT] total keys in state: 538\n",
            "[CKPT] after strip+drop:     178\n",
            "[CKPT] intersect (name+shape): 176 / model expects 176\n",
            "[LOAD] missing (after clean) ~ 0 (showing up to 40)\n",
            "[]\n",
            "[OK] Cleaned checkpoint loaded into model on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCydKFFfijn4",
        "outputId": "10d82197-589f-4cfa-c97d-e676e28d36cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torch, re\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "\n",
        "def _unwrap_state(d):\n",
        "    # try common containers\n",
        "    for k in [\"state_dict\",\"model\",\"net\",\"ema\",\"model_state\"]:\n",
        "        if isinstance(d, dict) and k in d and isinstance(d[k], dict):\n",
        "            return d[k]\n",
        "    return d if isinstance(d, dict) else {}\n",
        "\n",
        "raw_state = _unwrap_state(ckpt)\n",
        "\n",
        "print(f\"[CKPT] top-level keys: {list(ckpt.keys())[:20]}\")\n",
        "print(f\"[CKPT] state len: {len(raw_state)}\")\n",
        "\n",
        "# Show a few parameter names to identify architecture/backbone\n",
        "sample_keys = list(raw_state.keys())[:40]\n",
        "print(\"[CKPT] sample param keys:\")\n",
        "for k in sample_keys:\n",
        "    print(\"  \", k)\n",
        "\n",
        "# Also show model keys to compare\n",
        "model_keys = list(model.state_dict().keys())\n",
        "print(f\"[MODEL] expects {len(model_keys)} tensors\")\n",
        "print(\"[MODEL] sample expected keys:\")\n",
        "for k in model_keys[:40]:\n",
        "    print(\"  \", k)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG20hJl3dpAi",
        "outputId": "672ea54b-e88b-416f-fcf7-a5791bb320d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CKPT] top-level keys: ['epoch', 'model_state', 'optimizer_state', 'val_dice', 'val_loss', 'cfg']\n",
            "[CKPT] state len: 538\n",
            "[CKPT] sample param keys:\n",
            "   total_ops\n",
            "   total_params\n",
            "   vit.cls_token\n",
            "   vit.pos_embed\n",
            "   vit.total_ops\n",
            "   vit.total_params\n",
            "   vit.patch_embed.total_ops\n",
            "   vit.patch_embed.total_params\n",
            "   vit.patch_embed.proj.weight\n",
            "   vit.patch_embed.proj.bias\n",
            "   vit.patch_embed.norm.total_ops\n",
            "   vit.patch_embed.norm.total_params\n",
            "   vit.patch_drop.total_ops\n",
            "   vit.patch_drop.total_params\n",
            "   vit.norm_pre.total_ops\n",
            "   vit.norm_pre.total_params\n",
            "   vit.blocks.0.total_ops\n",
            "   vit.blocks.0.total_params\n",
            "   vit.blocks.0.norm1.weight\n",
            "   vit.blocks.0.norm1.bias\n",
            "   vit.blocks.0.norm1.total_ops\n",
            "   vit.blocks.0.norm1.total_params\n",
            "   vit.blocks.0.attn.total_ops\n",
            "   vit.blocks.0.attn.total_params\n",
            "   vit.blocks.0.attn.qkv.weight\n",
            "   vit.blocks.0.attn.qkv.bias\n",
            "   vit.blocks.0.attn.q_norm.total_ops\n",
            "   vit.blocks.0.attn.q_norm.total_params\n",
            "   vit.blocks.0.attn.k_norm.total_ops\n",
            "   vit.blocks.0.attn.k_norm.total_params\n",
            "   vit.blocks.0.attn.norm.total_ops\n",
            "   vit.blocks.0.attn.norm.total_params\n",
            "   vit.blocks.0.attn.proj.weight\n",
            "   vit.blocks.0.attn.proj.bias\n",
            "   vit.blocks.0.ls1.total_ops\n",
            "   vit.blocks.0.ls1.total_params\n",
            "   vit.blocks.0.drop_path1.total_ops\n",
            "   vit.blocks.0.drop_path1.total_params\n",
            "   vit.blocks.0.norm2.weight\n",
            "   vit.blocks.0.norm2.bias\n",
            "[MODEL] expects 176 tensors\n",
            "[MODEL] sample expected keys:\n",
            "   vit.cls_token\n",
            "   vit.pos_embed\n",
            "   vit.patch_embed.proj.weight\n",
            "   vit.patch_embed.proj.bias\n",
            "   vit.blocks.0.norm1.weight\n",
            "   vit.blocks.0.norm1.bias\n",
            "   vit.blocks.0.attn.qkv.weight\n",
            "   vit.blocks.0.attn.qkv.bias\n",
            "   vit.blocks.0.attn.proj.weight\n",
            "   vit.blocks.0.attn.proj.bias\n",
            "   vit.blocks.0.norm2.weight\n",
            "   vit.blocks.0.norm2.bias\n",
            "   vit.blocks.0.mlp.fc1.weight\n",
            "   vit.blocks.0.mlp.fc1.bias\n",
            "   vit.blocks.0.mlp.fc2.weight\n",
            "   vit.blocks.0.mlp.fc2.bias\n",
            "   vit.blocks.1.norm1.weight\n",
            "   vit.blocks.1.norm1.bias\n",
            "   vit.blocks.1.attn.qkv.weight\n",
            "   vit.blocks.1.attn.qkv.bias\n",
            "   vit.blocks.1.attn.proj.weight\n",
            "   vit.blocks.1.attn.proj.bias\n",
            "   vit.blocks.1.norm2.weight\n",
            "   vit.blocks.1.norm2.bias\n",
            "   vit.blocks.1.mlp.fc1.weight\n",
            "   vit.blocks.1.mlp.fc1.bias\n",
            "   vit.blocks.1.mlp.fc2.weight\n",
            "   vit.blocks.1.mlp.fc2.bias\n",
            "   vit.blocks.2.norm1.weight\n",
            "   vit.blocks.2.norm1.bias\n",
            "   vit.blocks.2.attn.qkv.weight\n",
            "   vit.blocks.2.attn.qkv.bias\n",
            "   vit.blocks.2.attn.proj.weight\n",
            "   vit.blocks.2.attn.proj.bias\n",
            "   vit.blocks.2.norm2.weight\n",
            "   vit.blocks.2.norm2.bias\n",
            "   vit.blocks.2.mlp.fc1.weight\n",
            "   vit.blocks.2.mlp.fc1.bias\n",
            "   vit.blocks.2.mlp.fc2.weight\n",
            "   vit.blocks.2.mlp.fc2.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing, unexpected = model.load_state_dict(raw_state, strict=False)\n",
        "print(f\"[DIFF] missing ({len(missing)}):\")\n",
        "print(missing[:50])\n",
        "print(f\"[DIFF] unexpected ({len(unexpected)}):\")\n",
        "print(unexpected[:50])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuEkE7Rzd2HR",
        "outputId": "d2e00ca0-10d5-4a0c-f198-407b115ef02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DIFF] missing (0):\n",
            "[]\n",
            "[DIFF] unexpected (362):\n",
            "['total_ops', 'total_params', 'vit.total_ops', 'vit.total_params', 'vit.patch_embed.total_ops', 'vit.patch_embed.total_params', 'vit.patch_embed.norm.total_ops', 'vit.patch_embed.norm.total_params', 'vit.patch_drop.total_ops', 'vit.patch_drop.total_params', 'vit.norm_pre.total_ops', 'vit.norm_pre.total_params', 'vit.blocks.0.total_ops', 'vit.blocks.0.total_params', 'vit.blocks.0.norm1.total_ops', 'vit.blocks.0.norm1.total_params', 'vit.blocks.0.attn.total_ops', 'vit.blocks.0.attn.total_params', 'vit.blocks.0.attn.q_norm.total_ops', 'vit.blocks.0.attn.q_norm.total_params', 'vit.blocks.0.attn.k_norm.total_ops', 'vit.blocks.0.attn.k_norm.total_params', 'vit.blocks.0.attn.norm.total_ops', 'vit.blocks.0.attn.norm.total_params', 'vit.blocks.0.ls1.total_ops', 'vit.blocks.0.ls1.total_params', 'vit.blocks.0.drop_path1.total_ops', 'vit.blocks.0.drop_path1.total_params', 'vit.blocks.0.norm2.total_ops', 'vit.blocks.0.norm2.total_params', 'vit.blocks.0.mlp.total_ops', 'vit.blocks.0.mlp.total_params', 'vit.blocks.0.mlp.act.total_ops', 'vit.blocks.0.mlp.act.total_params', 'vit.blocks.0.mlp.norm.total_ops', 'vit.blocks.0.mlp.norm.total_params', 'vit.blocks.0.ls2.total_ops', 'vit.blocks.0.ls2.total_params', 'vit.blocks.0.drop_path2.total_ops', 'vit.blocks.0.drop_path2.total_params', 'vit.blocks.1.total_ops', 'vit.blocks.1.total_params', 'vit.blocks.1.norm1.total_ops', 'vit.blocks.1.norm1.total_params', 'vit.blocks.1.attn.total_ops', 'vit.blocks.1.attn.total_params', 'vit.blocks.1.attn.q_norm.total_ops', 'vit.blocks.1.attn.q_norm.total_params', 'vit.blocks.1.attn.k_norm.total_ops', 'vit.blocks.1.attn.k_norm.total_params']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# Cell 4/4 — Warm-up, timed run, metrics, save CSV+JSON\n",
        "# (FIX: added `import math`)\n",
        "# ------------------------------------------------------------\n",
        "import time, numpy as np, math, json, os, psutil, pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- helpers ----\n",
        "def apply_test_transform(img, msk):\n",
        "    # Ensure 3-ch image & binary mask; then apply test_tf (resize+norm+tensor)\n",
        "    if img.ndim == 2: img = np.stack([img, img, img], axis=-1)\n",
        "    if msk.max() > 1: msk = (msk > 127).astype(np.uint8)\n",
        "    out = test_tf(image=img, mask=msk)  # includes resize+normalize\n",
        "    x = out[\"image\"]                           # [C,H,W] float32\n",
        "    y = out[\"mask\"].unsqueeze(0) if out[\"mask\"].ndim==2 else out[\"mask\"]  # [1,H,W]\n",
        "    return x, y\n",
        "\n",
        "def binarize(prob, thr): return (prob >= thr).astype(np.uint8)\n",
        "\n",
        "def dice_iou(pred, mask, eps=1e-7):\n",
        "    inter = (pred & mask).sum()\n",
        "    union = (pred | mask).sum()\n",
        "    dice = (2*inter + eps) / (pred.sum() + mask.sum() + eps)\n",
        "    iou  = (inter + eps) / (union + eps)\n",
        "    return float(dice), float(iou)\n",
        "\n",
        "# ---- warm-up (excluded) ----\n",
        "with torch.no_grad():\n",
        "    for i in range(WARMUP):\n",
        "        img, msk = raw_samples[i]\n",
        "        x, y = apply_test_transform(img, msk)\n",
        "        _ = model(x.unsqueeze(0))\n",
        "\n",
        "# ---- timed run ----\n",
        "lat_ms, dices, ious = [], [], []\n",
        "cpu_hist, ram_hist  = [], []\n",
        "proc = psutil.Process(os.getpid())\n",
        "t_start = time.perf_counter()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(WARMUP, NUM_SAMPLES):\n",
        "        img, msk = raw_samples[i]\n",
        "\n",
        "        t0 = time.perf_counter()\n",
        "        x, y = apply_test_transform(img, msk)       # include resize+normalize in timing\n",
        "        out = model(x.unsqueeze(0))                 # forward\n",
        "        logits = out[\"logits\"] if isinstance(out, dict) and \"logits\" in out else out\n",
        "        prob = torch.sigmoid(logits).cpu().numpy().squeeze()\n",
        "        pred = binarize(prob, THRESH)\n",
        "        gt   = (y.squeeze().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        d, j = dice_iou(pred, gt)\n",
        "        t1 = time.perf_counter()\n",
        "\n",
        "        dices.append(d); ious.append(j)\n",
        "        lat_ms.append((t1 - t0) * 1000.0)\n",
        "        cpu_hist.append(psutil.cpu_percent(interval=None))\n",
        "        ram_hist.append(proc.memory_info().rss)\n",
        "\n",
        "t_end = time.perf_counter()\n",
        "\n",
        "# ---- summary ----\n",
        "def pct(vals, p):\n",
        "    if not vals: return float('nan')\n",
        "    a = sorted(vals)\n",
        "    k = (len(a)-1)*(p/100.0)\n",
        "    f,c = math.floor(k), math.ceil(k)\n",
        "    return a[int(k)] if f==c else a[f]*(c-k)+a[c]*(k-f)\n",
        "\n",
        "n = len(lat_ms)\n",
        "fps = (NUM_SAMPLES - WARMUP) / (t_end - t_start) if (t_end - t_start) > 0 else float('nan')\n",
        "summary = dict(\n",
        "    dice_mean=float(np.mean(dices)) if dices else float('nan'),\n",
        "    iou_mean=float(np.mean(ious)) if ious else float('nan'),\n",
        "    lat_median_ms=float(np.median(lat_ms)) if n else float('nan'),\n",
        "    lat_p90_ms=float(pct(lat_ms, 90)),\n",
        "    lat_p95_ms=float(pct(lat_ms, 95)),\n",
        "    lat_min_ms=float(np.min(lat_ms)) if n else float('nan'),\n",
        "    lat_max_ms=float(np.max(lat_ms)) if n else float('nan'),\n",
        "    wall_time_s=float(t_end - t_start),\n",
        "    fps=float(fps),\n",
        "    peak_ram_mb=float(max(ram_hist)/(1024*1024)) if ram_hist else float('nan'),\n",
        "    cpu_mean_pct=float(np.mean(cpu_hist)) if cpu_hist else float('nan'),\n",
        "    threshold=float(THRESH),\n",
        "    samples=int(NUM_SAMPLES - WARMUP),\n",
        "    threads=dict(\n",
        "        torch_num_threads=torch.get_num_threads(),\n",
        "        torch_num_interop=torch.get_num_interop_threads() if hasattr(torch, \"get_num_interop_threads\") else \"N/A\",\n",
        "        OMP_NUM_THREADS=os.getenv(\"OMP_NUM_THREADS\"),\n",
        "        MKL_NUM_THREADS=os.getenv(\"MKL_NUM_THREADS\"),\n",
        "    ),\n",
        "    ckpt=CKPT_PATH,\n",
        "    data=str(busi_file),\n",
        ")\n",
        "\n",
        "print(json.dumps(summary, indent=2))\n",
        "\n",
        "# ---- save artifacts ----\n",
        "outdir = Path(\"./cpu_eval_runs\"); outdir.mkdir(exist_ok=True, parents=True)\n",
        "stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "pd.DataFrame({\"idx\": list(range(n)), \"latency_ms\": lat_ms, \"dice\": dices, \"iou\": ious}).to_csv(outdir / f\"per_image_{stamp}.csv\", index=False)\n",
        "with open(outdir / f\"summary_{stamp}.json\",\"w\") as f: json.dump(summary, f, indent=2)\n",
        "print(\"Saved:\", outdir / f\"per_image_{stamp}.csv\", \"|\", outdir / f\"summary_{stamp}.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02TjETcyOl36",
        "outputId": "fe3d9a20-2b89-4773-a74f-ab3289088d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"dice_mean\": 0.6606155385251257,\n",
            "  \"iou_mean\": 0.56012027807871,\n",
            "  \"lat_median_ms\": 941.6854940000121,\n",
            "  \"lat_p90_ms\": 1888.6020072000067,\n",
            "  \"lat_p95_ms\": 2106.9869702000688,\n",
            "  \"lat_min_ms\": 915.563807999888,\n",
            "  \"lat_max_ms\": 2785.5348749999393,\n",
            "  \"wall_time_s\": 55.4746082690001,\n",
            "  \"fps\": 0.8111819335756636,\n",
            "  \"peak_ram_mb\": 4271.9296875,\n",
            "  \"cpu_mean_pct\": 67.96444444444444,\n",
            "  \"threshold\": 0.5,\n",
            "  \"samples\": 45,\n",
            "  \"threads\": {\n",
            "    \"torch_num_threads\": 1,\n",
            "    \"torch_num_interop\": 1,\n",
            "    \"OMP_NUM_THREADS\": \"1\",\n",
            "    \"MKL_NUM_THREADS\": \"1\"\n",
            "  },\n",
            "  \"ckpt\": \"/content/drive/MyDrive/setr_model_busi_2/checkpoints/setr_model_busi_IMG256_SEED42_2025-11-04_15-02-28_best.pt\",\n",
            "  \"data\": \"/content/data/MedSegBenchCache/busi_256.npz\"\n",
            "}\n",
            "Saved: cpu_eval_runs/per_image_20251104_160313.csv | cpu_eval_runs/summary_20251104_160313.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd; from pathlib import Path\n",
        "p = sorted(Path(\"cpu_eval_runs\").glob(\"per_image_*.csv\"))[-1]\n",
        "df = pd.read_csv(p)\n",
        "print(df.describe(percentiles=[.5,.9,.95]))\n",
        "print(\"Top 5 slowest:\\n\", df.sort_values(\"latency_ms\", ascending=False).head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAw3zscae5q3",
        "outputId": "f343d8b0-3e63-4a11-d411-f4fd3157c49f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             idx   latency_ms          dice           iou\n",
            "count  45.000000    45.000000  4.500000e+01  4.500000e+01\n",
            "mean   22.000000  1232.416411  6.606155e-01  5.601203e-01\n",
            "std    13.133926   480.173702  3.097398e-01  2.990509e-01\n",
            "min     0.000000   915.563808  5.789382e-12  5.789382e-12\n",
            "50%    22.000000   941.685494  8.004851e-01  6.673407e-01\n",
            "90%    39.600000  1888.602007  9.100715e-01  8.349848e-01\n",
            "95%    41.800000  2106.986970  9.168588e-01  8.464866e-01\n",
            "max    44.000000  2785.534875  9.310612e-01  8.710145e-01\n",
            "Top 5 slowest:\n",
            "     idx   latency_ms      dice       iou\n",
            "6     6  2785.534875  0.151673  0.082060\n",
            "18   18  2744.833276  0.012240  0.006158\n",
            "0     0  2116.153133  0.458124  0.297121\n",
            "1     1  2070.322319  0.911014  0.836570\n",
            "19   19  1999.531380  0.838050  0.721245\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08538750e62d4f1ab0a611407cf0759e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f14c17e672a0417f95c2cdaa7e103c28",
              "IPY_MODEL_a4b2613e43d740c9bbe5da8bc370512f",
              "IPY_MODEL_dce4d7995f8041078ec19bb82c9bb838"
            ],
            "layout": "IPY_MODEL_a26b5b830cee42c9a3b4e1932807c121"
          }
        },
        "f14c17e672a0417f95c2cdaa7e103c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f32e7b612266440482c90c38a62590c8",
            "placeholder": "​",
            "style": "IPY_MODEL_525717ead1f54775868cfcdd24f31558",
            "value": "model.safetensors: 100%"
          }
        },
        "a4b2613e43d740c9bbe5da8bc370512f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b47782afb74042859b01133e35a7694c",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2bca01242c441f2840b5b264b03d021",
            "value": 346284714
          }
        },
        "dce4d7995f8041078ec19bb82c9bb838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0626350e47b1458e921691818e258ea8",
            "placeholder": "​",
            "style": "IPY_MODEL_782a24ec3dea497d8beedc5c2768a703",
            "value": " 346M/346M [00:06&lt;00:00, 49.9MB/s]"
          }
        },
        "a26b5b830cee42c9a3b4e1932807c121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f32e7b612266440482c90c38a62590c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525717ead1f54775868cfcdd24f31558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b47782afb74042859b01133e35a7694c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2bca01242c441f2840b5b264b03d021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0626350e47b1458e921691818e258ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "782a24ec3dea497d8beedc5c2768a703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}