{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "J96icrtqXXpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f83a3ae8-d991-48b1-f50b-a9205f69baa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\n",
        "# Cell 1/9 — Run identifiers, paths, and folders\n",
        "# ------------------------------------------------------------\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- run knobs (same style as yours) ----\n",
        "DATASET    = \"ISIC2016\"\n",
        "IMAGE_SIZE = 256\n",
        "SEED       = 42\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS     = 10\n",
        "AMP_ON     = True\n",
        "MODEL_TAG  = \"SETR_model\"\n",
        "RUN_NAME   = f\"{MODEL_TAG}_{DATASET}_IMG{IMAGE_SIZE}_SEED{SEED}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
        "CONFIG_PATH = \"configs/example.yaml\"\n",
        "\n",
        "# ---- standard folders ----\n",
        "root = Path(\"/content/drive/MyDrive/TransUNetBaseline_model_isic_Test\")\n",
        "for p in [\"logs\", \"checkpoints\", \"figures\", \"runs\", \"summary\"]:\n",
        "    (root / p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "summary_txt_path  = root / \"summary\" / f\"{RUN_NAME}_env.txt\"\n",
        "summary_json_path = root / \"summary\" / f\"{RUN_NAME}_env.json\"\n"
      ],
      "metadata": {
        "id": "ihJQ62HiGoV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 2/9 — Base imports & safe-import helper\n",
        "# ------------------------------------------------------------\n",
        "import os, sys, json, time, platform, importlib, random\n",
        "\n",
        "def try_import(name: str):\n",
        "    try:\n",
        "        mod = importlib.import_module(name)\n",
        "        ver = getattr(mod, \"__version__\", \"unknown\")\n",
        "        if name == \"PIL\": ver = getattr(mod, \"__version__\", ver)\n",
        "        if name == \"cv2\": ver = getattr(mod, \"__version__\", ver)\n",
        "        return mod, ver\n",
        "    except Exception as e:\n",
        "        return None, f\"NOT INSTALLED ({type(e).__name__})\"\n",
        "\n",
        "!pip -q install -U monai torchmetrics thop fvcore timm albumentations==1.4.4 psutil pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu1sollbGoeE",
        "outputId": "b73d175a-445a-41fc-aba7-192352e8226c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.4/150.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 3/9 — Import common stack (DL, data, viz, utils)\n",
        "# ------------------------------------------------------------\n",
        "# Core / data\n",
        "numpy, np_ver         = try_import(\"numpy\")\n",
        "pandas, pd_ver        = try_import(\"pandas\")\n",
        "\n",
        "# Deep Learning\n",
        "torch, torch_ver      = try_import(\"torch\")\n",
        "torchvision, tv_ver   = try_import(\"torchvision\")\n",
        "timm, timm_ver        = try_import(\"timm\")\n",
        "monai, monai_ver      = try_import(\"monai\")\n",
        "torchmetrics, tm_ver  = try_import(\"torchmetrics\")\n",
        "\n",
        "# Aug / IO / Viz\n",
        "albumentations, alb_ver = try_import(\"albumentations\")\n",
        "cv2, cv2_ver            = try_import(\"cv2\")\n",
        "PIL, pil_ver            = try_import(\"PIL\")\n",
        "matplotlib, mpl_ver     = try_import(\"matplotlib\")\n",
        "\n",
        "# Utils\n",
        "yaml, yaml_ver       = try_import(\"yaml\")\n",
        "sklearn, sk_ver      = try_import(\"sklearn\")\n",
        "psutil, psutil_ver   = try_import(\"psutil\")\n",
        "\n",
        "# Profiling\n",
        "thop, thop_ver       = try_import(\"thop\")\n",
        "fvcore, fvcore_ver   = try_import(\"fvcore\")\n"
      ],
      "metadata": {
        "id": "f5VnECLKGohb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 4/9 — Device, CUDA/cuDNN, and GPU VRAM discovery\n",
        "# ------------------------------------------------------------\n",
        "device         = \"cpu\"\n",
        "gpu_name       = \"N/A\"\n",
        "total_vram_mb  = \"N/A\"\n",
        "total_vram_gb  = \"N/A\"\n",
        "cuda_version   = \"N/A\"\n",
        "cudnn_version  = \"N/A\"\n",
        "\n",
        "if torch is not None:\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    device = \"cuda\" if cuda_available else \"cpu\"\n",
        "    cuda_version = getattr(torch.version, \"cuda\", \"N/A\")\n",
        "    try:\n",
        "        cudnn_version = str(torch.backends.cudnn.version()) if torch.backends.cudnn.is_available() else \"N/A\"\n",
        "    except Exception:\n",
        "        cudnn_version = \"N/A\"\n",
        "    if cuda_available:\n",
        "        try:\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            props = torch.cuda.get_device_properties(0)\n",
        "            total_vram_bytes = getattr(props, \"total_memory\", 0)\n",
        "            total_vram_mb = round(total_vram_bytes / (1024**2), 2)\n",
        "            total_vram_gb = round(total_vram_bytes / (1024**3), 2)\n",
        "        except Exception:\n",
        "            gpu_name = \"Unknown (query failed)\"\n",
        "            total_vram_mb = \"Unknown\"\n",
        "            total_vram_gb = \"Unknown\"\n"
      ],
      "metadata": {
        "id": "QVMvrGY_Gok0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 5/9 — Reproducibility (seeds + deterministic flags)\n",
        "# ------------------------------------------------------------\n",
        "random.seed(SEED)\n",
        "if numpy:\n",
        "    numpy.random.seed(SEED)\n",
        "\n",
        "if torch is not None:\n",
        "    torch.manual_seed(SEED)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(SEED)\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    except Exception:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "wqa1EkgIGooP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 6/9 — Assemble environment snapshot dict\n",
        "# ------------------------------------------------------------\n",
        "env_info = {\n",
        "    \"run\": {\n",
        "        \"run_name\": RUN_NAME,\n",
        "        \"datetime\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"dataset\": DATASET,\n",
        "        \"image_size\": IMAGE_SIZE,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"amp_on\": AMP_ON,\n",
        "        \"seed\": SEED,\n",
        "        \"config_path\": CONFIG_PATH if Path(CONFIG_PATH).exists() else f\"{CONFIG_PATH} (not found)\",\n",
        "    },\n",
        "    \"system\": {\n",
        "        \"python\": sys.version.split()[0],\n",
        "        \"platform\": platform.platform(),\n",
        "        \"device\": device,\n",
        "        \"gpu_name\": gpu_name,\n",
        "        \"gpu_total_vram_mb\": total_vram_mb,\n",
        "        \"gpu_total_vram_gb\": total_vram_gb,\n",
        "        \"cuda_version\": cuda_version,\n",
        "        \"cudnn_version\": cudnn_version,\n",
        "    },\n",
        "    \"libraries\": {\n",
        "        \"torch\": torch_ver,\n",
        "        \"torchvision\": tv_ver,\n",
        "        \"timm\": timm_ver,\n",
        "        \"monai\": monai_ver,\n",
        "        \"torchmetrics\": tm_ver,\n",
        "        \"numpy\": np_ver,\n",
        "        \"pandas\": pd_ver,\n",
        "        \"albumentations\": alb_ver,\n",
        "        \"opencv-python (cv2)\": cv2_ver,\n",
        "        \"Pillow (PIL)\": pil_ver,\n",
        "        \"matplotlib\": mpl_ver,\n",
        "        \"pyyaml\": yaml_ver,\n",
        "        \"scikit-learn\": sk_ver,\n",
        "        \"psutil\": psutil_ver,\n",
        "        \"thop\": thop_ver,\n",
        "        \"fvcore\": fvcore_ver,\n",
        "    },\n",
        "}\n"
      ],
      "metadata": {
        "id": "MGEigRc2Gorp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 7/9 — Pretty print snapshot to console\n",
        "# ------------------------------------------------------------\n",
        "border = \"=\" * 70\n",
        "print(border)\n",
        "print(\"STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\")\n",
        "print(border)\n",
        "print(f\"Run Name      : {env_info['run']['run_name']}\")\n",
        "print(f\"Date/Time     : {env_info['run']['datetime']}\")\n",
        "print(f\"Dataset       : {env_info['run']['dataset']}\")\n",
        "print(f\"Image Size    : {env_info['run']['image_size']}\")\n",
        "print(f\"Batch Size    : {env_info['run']['batch_size']}\")\n",
        "print(f\"Epochs        : {env_info['run']['epochs']}\")\n",
        "print(f\"AMP (mixed precision): {env_info['run']['amp_on']}\")\n",
        "print(f\"Seed          : {env_info['run']['seed']}\")\n",
        "print(f\"Config Path   : {env_info['run']['config_path']}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Python        : {env_info['system']['python']}\")\n",
        "print(f\"Platform      : {env_info['system']['platform']}\")\n",
        "print(f\"Device        : {env_info['system']['device']}\")\n",
        "print(f\"GPU           : {env_info['system']['gpu_name']}\")\n",
        "print(f\"GPU VRAM      : {env_info['system']['gpu_total_vram_mb']} MB ({env_info['system']['gpu_total_vram_gb']} GB)\")\n",
        "print(f\"CUDA / cuDNN  : {env_info['system']['cuda_version']} / {env_info['system']['cudnn_version']}\")\n",
        "print(\"-\" * 70)\n",
        "print(\"Libraries:\")\n",
        "for lib, ver in env_info[\"libraries\"].items():\n",
        "    print(f\"  - {lib:<24} {ver}\")\n",
        "print(border)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RCdGFiAGou1",
        "outputId": "beb93ec4-23a9-4610-aaa3-527fbcf2cfa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\n",
            "======================================================================\n",
            "Run Name      : TransUNetBaseline_model_ISIC2016_IMG256_SEED42_2025-11-08_13-34-44\n",
            "Date/Time     : 2025-11-08T13:35:58\n",
            "Dataset       : ISIC2016\n",
            "Image Size    : 256\n",
            "Batch Size    : 8\n",
            "Epochs        : 10\n",
            "AMP (mixed precision): True\n",
            "Seed          : 42\n",
            "Config Path   : configs/example.yaml (not found)\n",
            "----------------------------------------------------------------------\n",
            "Python        : 3.12.12\n",
            "Platform      : Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "Device        : cpu\n",
            "GPU           : N/A\n",
            "GPU VRAM      : N/A MB (N/A GB)\n",
            "CUDA / cuDNN  : 12.6 / 91002\n",
            "----------------------------------------------------------------------\n",
            "Libraries:\n",
            "  - torch                    2.8.0+cu126\n",
            "  - torchvision              0.23.0+cu126\n",
            "  - timm                     1.0.22\n",
            "  - monai                    1.5.1\n",
            "  - torchmetrics             1.8.2\n",
            "  - numpy                    2.0.2\n",
            "  - pandas                   2.3.3\n",
            "  - albumentations           1.4.4\n",
            "  - opencv-python (cv2)      4.12.0\n",
            "  - Pillow (PIL)             11.3.0\n",
            "  - matplotlib               3.10.0\n",
            "  - pyyaml                   6.0.3\n",
            "  - scikit-learn             1.6.1\n",
            "  - psutil                   5.9.5\n",
            "  - thop                     0.1.1\n",
            "  - fvcore                   0.1.5.post20221221\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 8/9 — Save TXT + JSON environment snapshots\n",
        "# ------------------------------------------------------------\n",
        "with open(summary_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(border + \"\\n\")\n",
        "    f.write(\"STEP 0 — ENVIRONMENT & LIBRARIES (IMPORTS + VERSION DUMP)\\n\")\n",
        "    f.write(border + \"\\n\")\n",
        "    for section, payload in env_info.items():\n",
        "        f.write(f\"[{section.UPPER()}]\\n\" if hasattr(section, 'UPPER') else f\"[{section.upper()}]\\n\")\n",
        "        if isinstance(payload, dict):\n",
        "            for k, v in payload.items():\n",
        "                if isinstance(v, dict):\n",
        "                    f.write(f\"  {k}:\\n\")\n",
        "                    for kk, vv in v.items():\n",
        "                        f.write(f\"    - {kk}: {vv}\\n\")\n",
        "                else:\n",
        "                    f.write(f\"  - {k}: {v}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "with open(summary_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(env_info, f, indent=2)\n",
        "\n",
        "print(f\"Saved environment snapshots to:\\n  • {summary_txt_path}\\n  • {summary_json_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeaNK1igGoyH",
        "outputId": "f12af0da-2b2b-4a61-b899-5606b38aa51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved environment snapshots to:\n",
            "  • /content/drive/MyDrive/TransUNetBaseline_model_isic_Test/summary/TransUNetBaseline_model_ISIC2016_IMG256_SEED42_2025-11-08_13-34-44_env.txt\n",
            "  • /content/drive/MyDrive/TransUNetBaseline_model_isic_Test/summary/TransUNetBaseline_model_ISIC2016_IMG256_SEED42_2025-11-08_13-34-44_env.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 0 — ENVIRONMENT & LIBRARIES\n",
        "# Cell 9/9 — Initialize per-run CSV log header\n",
        "# ------------------------------------------------------------\n",
        "csv_path = root / \"logs\" / f\"{RUN_NAME}.csv\"\n",
        "if not csv_path.exists():\n",
        "    with open(csv_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"epoch,lr,train_loss,val_loss,train_dice,val_dice,train_iou,val_iou,epoch_time\\n\")\n",
        "print(f\"Initialized log CSV (if new): {csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4pE758CGo1K",
        "outputId": "d4c36ca6-90cf-4992-85be-528e55e2a01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized log CSV (if new): /content/drive/MyDrive/TransUNetBaseline_model_isic_Test/logs/TransUNetBaseline_model_ISIC2016_IMG256_SEED42_2025-11-08_13-34-44.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD (ISIC 2018, 256px) → MedSegBench cache\n",
        "# Cell 1/6 — Setup: cache dir, env var, and size\n",
        "# ------------------------------------------------------------\n",
        "# Goal:\n",
        "#   • Set SIZE=256 (image resolution).\n",
        "#   • Create MedSegBench cache at ~/.medsegbench.\n",
        "#   • Point MEDSEGBENCH_DIR to the cache so MedSegBench finds the data.\n",
        "# ============================================================\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "SIZE = 256\n",
        "cache_root = Path(\"/content/data/MedSegBenchCache\")\n",
        "cache_root.mkdir(parents=True, exist_ok=True)\n",
        "os.environ[\"MEDSEGBENCH_DIR\"] = str(cache_root)  # ensure MedSegBench reads this\n",
        "\n",
        "print(f\"[INFO] MEDSEGBENCH_DIR = {cache_root.resolve()}\")\n",
        "print(f\"[INFO] Target resolution = {SIZE}px\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBl3jA_rMHZx",
        "outputId": "4a5dfbec-e8ea-4af0-db43-c58c98584caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] MEDSEGBENCH_DIR = /content/data/MedSegBenchCache\n",
            "[INFO] Target resolution = 256px\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medsegbench"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlKnp5ifyd1b",
        "outputId": "663721db-4b27-4b5c-815f-d0a92d73268f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medsegbench\n",
            "  Downloading medsegbench-1.0.0-py3-none-any.whl.metadata (797 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from medsegbench) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from medsegbench) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from medsegbench) (0.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from medsegbench) (11.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from medsegbench) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from medsegbench) (0.23.0+cu126)\n",
            "Collecting segmentation-models-pytorch (from medsegbench)\n",
            "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medsegbench) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medsegbench) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medsegbench) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medsegbench) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medsegbench) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medsegbench) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medsegbench) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medsegbench) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch->medsegbench) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch->medsegbench) (0.6.2)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch->medsegbench) (1.0.22)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch->medsegbench) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->medsegbench) (3.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch->medsegbench) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch->medsegbench) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch->medsegbench) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->medsegbench) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->medsegbench) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch->medsegbench) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch->medsegbench) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch->medsegbench) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch->medsegbench) (2025.10.5)\n",
            "Downloading medsegbench-1.0.0-py3-none-any.whl (18 kB)\n",
            "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: segmentation-models-pytorch, medsegbench\n",
            "Successfully installed medsegbench-1.0.0 segmentation-models-pytorch-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 2/6 — Dataset source details (Zenodo v1 record)\n",
        "# ------------------------------------------------------------\n",
        "# Goal:\n",
        "#   • Define file name, direct download URL, and official MD5 checksum.\n",
        "#   • Keep variables explicit for auditability/reproducibility.\n",
        "# ============================================================\n",
        "target_name = f\"isic2016_{SIZE}.npz\"\n",
        "target_path = cache_root / target_name\n",
        "\n",
        "# Zenodo (MedSegBench v1 record) direct file link:\n",
        "url = f\"https://zenodo.org/records/13358372/files/{target_name}?download=1\"\n",
        "\n",
        "# Official MD5 for isic2016_256.npz (from the Zenodo file list)\n",
        "expected_md5 = \"ee3fc6b5fffdc039e963ab21ff18e42e\"\n",
        "\n",
        "print(f\"[INFO] Target file  : {target_name}\")\n",
        "print(f\"[INFO] Download URL : {url}\")\n",
        "print(f\"[INFO] Expected MD5 : {expected_md5}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6EcLSkJMHWk",
        "outputId": "97cc05e7-03ea-4067-a7ac-558cd006247f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Target file  : isic2016_256.npz\n",
            "[INFO] Download URL : https://zenodo.org/records/13358372/files/isic2016_256.npz?download=1\n",
            "[INFO] Expected MD5 : ee3fc6b5fffdc039e963ab21ff18e42e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 3/6 — Helpers (md5sum + download runners)\n",
        "# ------------------------------------------------------------\n",
        "# Goal:\n",
        "#   • Provide md5sum(path) to verify integrity.\n",
        "#   • Provide a download helper that tries curl, then wget.\n",
        "# ============================================================\n",
        "import hashlib, subprocess, shutil\n",
        "\n",
        "def md5sum(path: Path) -> str:\n",
        "    h = hashlib.md5()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def download_file(url: str, out_path: Path) -> None:\n",
        "    # Try curl first (quiet progress, follow redirects, fail on HTTP errors)\n",
        "    curl = shutil.which(\"curl\")\n",
        "    if curl:\n",
        "        print(\"[INFO] Downloading with curl ...\")\n",
        "        subprocess.run([curl, \"-L\", \"-f\", url, \"-o\", str(out_path)], check=True)\n",
        "        return\n",
        "    # Fallback: wget\n",
        "    wget = shutil.which(\"wget\")\n",
        "    if wget:\n",
        "        print(\"[INFO] curl not found; downloading with wget ...\")\n",
        "        subprocess.run([wget, \"-O\", str(out_path), url], check=True)\n",
        "        return\n",
        "    raise RuntimeError(\"Neither curl nor wget is available on PATH.\")\n"
      ],
      "metadata": {
        "id": "A8jRgZpiMHTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 4/6 — Download (idempotent)\n",
        "# ------------------------------------------------------------\n",
        "# Goal:\n",
        "#   • If file is missing → download to cache.\n",
        "#   • If present → skip download.\n",
        "# ============================================================\n",
        "if not target_path.exists():\n",
        "    print(f\"[INFO] Downloading to {target_path} ...\")\n",
        "    try:\n",
        "        download_file(url, target_path)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        raise RuntimeError(f\"Downloader failed with return code {e.returncode}.\") from e\n",
        "else:\n",
        "    print(f\"[INFO] File already present: {target_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LhTqJv9MHQZ",
        "outputId": "39a23764-b1bc-4c53-c2fa-f2f8da1638af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Downloading to /content/data/MedSegBenchCache/isic2016_256.npz ...\n",
            "[INFO] Downloading with curl ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 5/6 — Integrity check (MD5)\n",
        "# ------------------------------------------------------------\n",
        "# Goal:\n",
        "#   • Verify downloaded file integrity using MD5.\n",
        "#   • Fail fast if checksum mismatches; suggest redownload.\n",
        "# ============================================================\n",
        "got = md5sum(target_path)\n",
        "print(f\"[INFO] MD5 (computed): {got}\")\n",
        "if got != expected_md5:\n",
        "    raise RuntimeError(\n",
        "        f\"MD5 mismatch for {target_name}. Expected {expected_md5}, got {got}.\\n\"\n",
        "        \"Delete the file and rerun this step to redownload.\"\n",
        "    )\n",
        "print(f\"✅ Download + MD5 OK → {target_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gJTKINBMHNS",
        "outputId": "875a4c91-f959-4fe0-d8ef-7d3b7f1e5773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] MD5 (computed): ee3fc6b5fffdc039e963ab21ff18e42e\n",
            "✅ Download + MD5 OK → /content/data/MedSegBenchCache/isic2016_256.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1 — DATASET DOWNLOAD\n",
        "# Cell 6/6 — Ready message\n",
        "# ------------------------------------------------------------\n",
        "# Goal:\n",
        "#   • Confirm dataset is cached and ready for MedSegBench loaders.\n",
        "#   • Next, we proceed to STEP 2 (repro/config) and STEP 3 (print split counts).\n",
        "# ============================================================\n",
        "print(\"[READY] ISIC 2016 (256px) cached in MEDSEGBENCH_DIR.\")\n",
        "print(\"[NEXT] STEP 2: Reproducibility & Config Lock; STEP 3: load predefined splits and print counts.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSfXw79FMVUz",
        "outputId": "03c050d8-5735-48b6-e6b5-f6225314f4dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[READY] ISIC 2016 (256px) cached in MEDSEGBENCH_DIR.\n",
            "[NEXT] STEP 2: Reproducibility & Config Lock; STEP 3: load predefined splits and print counts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 1/5 — Resolve run knobs, paths, and dataset file\n",
        "# ------------------------------------------------------------\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "try: root\n",
        "except NameError: root = Path(\".\")\n",
        "\n",
        "DATASET    = globals().get(\"DATASET\", \"isic\")\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", 256))\n",
        "SEED       = int(globals().get(\"SEED\", 42))\n",
        "BATCH_SIZE = int(globals().get(\"BATCH_SIZE\", 8))\n",
        "EPOCHS     = int(globals().get(\"EPOCHS\", 10))\n",
        "AMP_ON     = bool(globals().get(\"AMP_ON\", True))\n",
        "MODEL_TAG  = globals().get(\"MODEL_TAG\", \"TransUNetLiteTiny_model\")\n",
        "RUN_NAME   = globals().get(\"RUN_NAME\", f\"{MODEL_TAG}_{DATASET}_IMG{IMAGE_SIZE}_SEED{SEED}\")\n",
        "CONFIG_PATH = globals().get(\"CONFIG_PATH\", \"configs/example.yaml\")\n",
        "\n",
        "RESOLUTION = int(globals().get(\"SIZE\", IMAGE_SIZE))\n",
        "\n",
        "msb_dir = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "busi_file = msb_dir / f\"isic2016_{RESOLUTION}.npz\"\n",
        "\n",
        "print(f\"[INFO] Artifacts root        : {root.resolve()}\")\n",
        "print(f\"[INFO] MEDSEGBENCH_DIR       : {msb_dir.resolve()}\")\n",
        "print(f\"[INFO] Expected busi file    : {busi_file}\")\n",
        "print(f\"[INFO] Run                   : {RUN_NAME}\")\n",
        "print(f\"[INFO] Model tag             : {MODEL_TAG}\")\n",
        "print(f\"[INFO] Seed / ImageSize      : {SEED} / {IMAGE_SIZE}\")\n",
        "print(f\"[INFO] Batch / Epochs / AMP  : {BATCH_SIZE} / {EPOCHS} / {AMP_ON}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyrNxgwAMVRp",
        "outputId": "2a8d0d01-974e-4b11-e60e-536dc343aeb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Artifacts root        : /content/drive/MyDrive/TransUNetBaseline_model_isic_Test\n",
            "[INFO] MEDSEGBENCH_DIR       : /content/data/MedSegBenchCache\n",
            "[INFO] Expected busi file    : /content/data/MedSegBenchCache/isic2016_256.npz\n",
            "[INFO] Run                   : TransUNetBaseline_model_ISIC2016_IMG256_SEED42_2025-11-08_13-34-44\n",
            "[INFO] Model tag             : TransUNetBaseline_model\n",
            "[INFO] Seed / ImageSize      : 42 / 256\n",
            "[INFO] Batch / Epochs / AMP  : 8 / 10 / True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 2/5 — Seed + deterministic flags (re-assert)\n",
        "# ------------------------------------------------------------\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "    try: torch.use_deterministic_algorithms(True)\n",
        "    except Exception: pass\n",
        "    try:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    except Exception: pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "print(f\"[OK] Seeds set and deterministic flags applied (seed={SEED}).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH7NZHhtMVOy",
        "outputId": "badc3692-2dfe-4e87-e364-b2a9f993976d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Seeds set and deterministic flags applied (seed=42).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 3/5 — Build default config (if missing) and load it\n",
        "# ------------------------------------------------------------\n",
        "import yaml\n",
        "(root / \"configs\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "cfg_path = Path(CONFIG_PATH)\n",
        "if not cfg_path.exists():\n",
        "    cfg_path = root / \"configs\" / \"default_busi.yaml\"\n",
        "\n",
        "default_cfg = {\n",
        "    \"run\": {\"run_name\": RUN_NAME, \"seed\": SEED, \"amp_on\": AMP_ON},\n",
        "    \"data\": {\"dataset\": DATASET, \"resolution\": RESOLUTION, \"medsegbench_dir\": str(msb_dir), \"predefined_splits\": True},\n",
        "    \"train\": {\n",
        "        \"image_size\": IMAGE_SIZE, \"batch_size\": BATCH_SIZE, \"epochs\": EPOCHS, \"num_workers\": 4,\n",
        "        \"optimizer\": {\"name\": \"adamw\", \"lr\": 3e-4, \"weight_decay\": 1e-4},\n",
        "        \"scheduler\": {\"name\": \"cosine\", \"warmup_epochs\": 5},\n",
        "        \"early_stopping\": {\"monitor\": \"val_dice\", \"patience\": 20},\n",
        "        \"mixed_precision\": AMP_ON\n",
        "    },\n",
        "    \"augment\": {\n",
        "        \"geometric\": {\"flip\": True, \"rotate\": True, \"scale\": True, \"elastic\": False},\n",
        "        \"appearance\": {\"brightness_contrast\": True, \"blur_noise\": True},\n",
        "        \"probabilities\": {\"flip\": 0.5, \"rotate\": 0.3, \"scale\": 0.3, \"brightness_contrast\": 0.3, \"blur_noise\": 0.2}\n",
        "    },\n",
        "    \"loss\": {\"primary\": \"dice_bce\", \"weights\": {\"dice\": 0.7, \"bce\": 0.3}},\n",
        "    \"metrics\": {\"threshold\": 0.5, \"report\": [\"dice\", \"iou\"]},\n",
        "    \"logging\": {\n",
        "        \"artifacts_root\": str(root.resolve()),\n",
        "        \"print_per_epoch_fields\": [\"epoch\",\"lr\",\"train_loss\",\"val_loss\",\"train_dice\",\"val_dice\",\"train_iou\",\"val_iou\",\"epoch_time\"],\n",
        "        \"save_csv_per_epoch\": True,\n",
        "        \"save_best_by\": \"val_dice\"\n",
        "    },\n",
        "    \"model\": {\"name\": MODEL_TAG, \"scale\": \"auto\", \"params\": {}}\n",
        "}\n",
        "\n",
        "if not Path(CONFIG_PATH).exists():\n",
        "    with open(cfg_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        yaml.safe_dump(default_cfg, f, sort_keys=False)\n",
        "    print(f\"[INFO] Created default config at: {cfg_path.resolve()}\")\n",
        "else:\n",
        "    cfg_path = Path(CONFIG_PATH)\n",
        "\n",
        "with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "print(f\"[OK] Loaded config from: {cfg_path.resolve()}\")\n",
        "print(f\"[INFO] Config run_name: {cfg['run'].get('run_name')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6rnSmDxMeTZ",
        "outputId": "fc9d4357-0eb8-4de7-c12f-cfab961410fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Created default config at: /content/drive/MyDrive/TransUNetBaseline_model_isic_Test/configs/default_busi.yaml\n",
            "[OK] Loaded config from: /content/drive/MyDrive/TransUNetBaseline_model_isic_Test/configs/default_busi.yaml\n",
            "[INFO] Config run_name: TransUNetBaseline_model_ISIC2016_IMG256_SEED42_2025-11-08_13-34-44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 4/5 — Sanity checks: dataset presence & key fields\n",
        "# ------------------------------------------------------------\n",
        "problems = []\n",
        "\n",
        "if not busi_file.exists():\n",
        "    problems.append(f\"Missing dataset cache file: {busi_file}\")\n",
        "\n",
        "required_keys = [\n",
        "    (\"run\", \"seed\"), (\"data\", \"medsegbench_dir\"), (\"data\", \"resolution\"),\n",
        "    (\"train\", \"batch_size\"), (\"train\", \"epochs\"),\n",
        "    (\"loss\", \"primary\"), (\"metrics\", \"threshold\"), (\"model\", \"name\"),\n",
        "]\n",
        "for sect, key in required_keys:\n",
        "    if sect not in cfg or key not in cfg[sect]:\n",
        "        problems.append(f\"Config missing: {sect}.{key}\")\n",
        "\n",
        "if problems:\n",
        "    print(\"[WARN] Sanity check issues:\")\n",
        "    for p in problems: print(\" -\", p)\n",
        "else:\n",
        "    print(\"[OK] Dataset file present and config has required keys.\")\n",
        "\n",
        "print(f\"[ECHO] Using dataset cache: {busi_file}\")\n",
        "print(f\"[ECHO] MEDSEGBENCH_DIR   : {msb_dir}\")\n",
        "print(f\"[ECHO] Model name        : {cfg['model']['name']}\")\n",
        "print(f\"[ECHO] Loss              : {cfg['loss']['primary']} (weights={cfg['loss'].get('weights')})\")\n",
        "print(f\"[ECHO] Metrics threshold : {cfg['metrics']['threshold']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-0MG3hAMeQO",
        "outputId": "bfa19ec3-cdd4-434b-e26e-1413a7969d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Dataset file present and config has required keys.\n",
            "[ECHO] Using dataset cache: /content/data/MedSegBenchCache/isic2016_256.npz\n",
            "[ECHO] MEDSEGBENCH_DIR   : /content/data/MedSegBenchCache\n",
            "[ECHO] Model name        : TransUNetBaseline_model\n",
            "[ECHO] Loss              : dice_bce (weights={'dice': 0.7, 'bce': 0.3})\n",
            "[ECHO] Metrics threshold : 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2 — REPRODUCIBILITY & CONFIG LOCK\n",
        "# Cell 5/5 — Snapshot config for this run\n",
        "# ------------------------------------------------------------\n",
        "(root / \"summary\").mkdir(parents=True, exist_ok=True)\n",
        "cfg_snapshot = root / \"summary\" / f\"{RUN_NAME}_config.yaml\"\n",
        "with open(cfg_snapshot, \"w\", encoding=\"utf-8\") as f:\n",
        "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
        "\n",
        "print(f\"[OK] Saved config snapshot to: {cfg_snapshot.resolve()}\")\n",
        "print(\"[NEXT] STEP 3 will load MedSegBench predefined splits and print sample counts per set (no re-splitting).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_7dS00IMeNp",
        "outputId": "3fac29b5-b1b3-40e8-dba3-321c0c39fb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved config snapshot to: /content/drive/MyDrive/TransUNetBaseline_model_isic_Test/summary/TransUNetBaseline_model_ISIC2016_IMG256_SEED42_2025-11-08_13-34-44_config.yaml\n",
            "[NEXT] STEP 3 will load MedSegBench predefined splits and print sample counts per set (no re-splitting).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 1/4 — Resolve paths and open the cached NPZ\n",
        "# ------------------------------------------------------------\n",
        "import numpy as np\n",
        "\n",
        "msb_dir = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "RESOLUTION = int(globals().get(\"RESOLUTION\", globals().get(\"SIZE\", 256)))\n",
        "busi_file = msb_dir / f\"isic2016_{RESOLUTION}.npz\"\n",
        "assert busi_file.exists(), f\"Expected dataset file not found: {busi_file}\"\n",
        "\n",
        "npz = np.load(busi_file, allow_pickle=True)\n",
        "keys = list(npz.keys())\n",
        "print(f\"[INFO] Loaded: {busi_file}\")\n",
        "print(f\"[ECHO] MEDSEGBENCH_DIR: {msb_dir.resolve()}\")\n",
        "print(f\"[INFO] NPZ keys ({len(keys)}): {keys[:12]}{'...' if len(keys)>12 else ''}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OWsTb-XMeKx",
        "outputId": "2ce58c0c-e1bc-473b-8801-307b885b83ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded: /content/data/MedSegBenchCache/isic2016_256.npz\n",
            "[ECHO] MEDSEGBENCH_DIR: /content/data/MedSegBenchCache\n",
            "[INFO] NPZ keys (6): ['train_images', 'train_label', 'test_images', 'test_label', 'val_images', 'val_label']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 2/4 — Infer split format (supports *_label/_labels)\n",
        "# ------------------------------------------------------------\n",
        "def _as_list(x):\n",
        "    if isinstance(x, np.ndarray): x = x.tolist()\n",
        "    return list(x) if isinstance(x, (list, tuple)) else [x]\n",
        "\n",
        "def infer_splits(npz_obj):\n",
        "    k = set(npz_obj.keys())\n",
        "\n",
        "    # Case A: per-split arrays (preferred)\n",
        "    def _find_lbl_key(split):\n",
        "        for suffix in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "            cand = f\"{split}_{suffix}\"\n",
        "            if cand in k: return cand\n",
        "        return None\n",
        "\n",
        "    have_all = True\n",
        "    meta = {}\n",
        "    for s in (\"train\",\"val\",\"test\"):\n",
        "        ik = f\"{s}_images\"; lk = _find_lbl_key(s)\n",
        "        if ik in k and lk in k and len(npz_obj[ik]) == len(npz_obj[lk]):\n",
        "            meta[s] = {\"n\": len(npz_obj[ik]), \"img_key\": ik, \"lbl_key\": lk}\n",
        "        else:\n",
        "            have_all = False; break\n",
        "    if have_all:\n",
        "        counts = {s: meta[s][\"n\"] for s in meta}\n",
        "        idx    = {s: list(range(meta[s][\"n\"])) for s in meta}\n",
        "        return counts, idx, \"A(images+labels)\"\n",
        "\n",
        "    # Case B: global arrays + explicit indices\n",
        "    for tri, vai, tei in [(\"train_idx\",\"val_idx\",\"test_idx\"),\n",
        "                          (\"train_indices\",\"val_indices\",\"test_indices\"),\n",
        "                          (\"split_train\",\"split_val\",\"split_test\")]:\n",
        "        if tri in k and vai in k and tei in k:\n",
        "            tr, va, te = _as_list(npz_obj[tri]), _as_list(npz_obj[vai]), _as_list(npz_obj[tei])\n",
        "            counts = {\"train\": len(tr), \"val\": len(va), \"test\": len(te)}\n",
        "            idx    = {\"train\": tr, \"val\": va, \"test\": te}\n",
        "            return counts, idx, \"B(indices)\"\n",
        "\n",
        "    raise RuntimeError(\"Could not infer predefined splits (need per-split arrays or *_idx lists).\")\n",
        "\n",
        "counts, split_idx, pattern = infer_splits(npz)\n",
        "print(f\"[OK] Split pattern detected: Case {pattern}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR2jkJQdMeH6",
        "outputId": "1bafe747-ba4f-4736-ee93-29e65cdcd9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Split pattern detected: Case A(images+labels)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS (SPEED-UP, OPTIONAL)\n",
        "# Cell 2.5/4 — Materialize arrays to RAM and rebind `npz`\n",
        "# ------------------------------------------------------------\n",
        "npz_ram = {}\n",
        "for k in keys:\n",
        "    obj = npz[k]\n",
        "    try: npz_ram[k] = obj[:] if isinstance(obj, np.ndarray) else obj\n",
        "    except Exception: npz_ram[k] = obj\n",
        "\n",
        "try: npz.close()\n",
        "except Exception: pass\n",
        "npz = npz_ram\n",
        "\n",
        "def _shape(x): return getattr(x, \"shape\", None)\n",
        "print(\"[SPEED] NPZ materialized to RAM. Example shapes:\")\n",
        "for probe in [\"train_images\",\"train_label\",\"train_masks\",\"val_images\",\"val_label\",\"test_images\",\"test_label\"]:\n",
        "    if probe in npz:\n",
        "        print(f\"  • {probe}: {_shape(npz[probe])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwR2CDMlNEWg",
        "outputId": "e0cf2181-92f2-409e-ae71-d05d001d5599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SPEED] NPZ materialized to RAM. Example shapes:\n",
            "  • train_images: (810, 256, 256, 3)\n",
            "  • train_label: (810, 256, 256)\n",
            "  • val_images: (90, 256, 256, 3)\n",
            "  • val_label: (90, 256, 256)\n",
            "  • test_images: (379, 256, 256, 3)\n",
            "  • test_label: (379, 256, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 3/4 — Print counts per set\n",
        "# ------------------------------------------------------------\n",
        "print(\"[COUNTS] Samples per split (predefined by MedSegBench)\")\n",
        "print(f\"  • Train : {counts['train']}\")\n",
        "print(f\"  • Val   : {counts['val']}\")\n",
        "print(f\"  • Test  : {counts['test']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilq_e8DpNET1",
        "outputId": "50a276d6-99d1-4ffd-fd7a-809adb09194d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[COUNTS] Samples per split (predefined by MedSegBench)\n",
            "  • Train : 810\n",
            "  • Val   : 90\n",
            "  • Test  : 379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3 — LOAD PREDEFINED SPLITS & PRINT COUNTS (NO RE-SPLIT)\n",
        "# Cell 4/4 — Save IDs to disk for reproducibility\n",
        "# ------------------------------------------------------------\n",
        "summary_dir = Path(globals().get(\"root\", Path(\".\"))) / \"summary\"\n",
        "summary_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def write_list(path: Path, arr):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for x in arr: f.write(f\"{x}\\n\")\n",
        "\n",
        "train_ids_path = summary_dir / f\"busi_{RESOLUTION}_train_ids.txt\"\n",
        "val_ids_path   = summary_dir / f\"busi_{RESOLUTION}_val_ids.txt\"\n",
        "test_ids_path  = summary_dir / f\"busi_{RESOLUTION}_test_ids.txt\"\n",
        "\n",
        "write_list(train_ids_path, split_idx[\"train\"])\n",
        "write_list(val_ids_path,   split_idx[\"val\"])\n",
        "write_list(test_ids_path,  split_idx[\"test\"])\n",
        "\n",
        "print(\"[OK] Saved split ID lists:\")\n",
        "print(f\"  • {train_ids_path}\")\n",
        "print(f\"  • {val_ids_path}\")\n",
        "print(f\"  • {test_ids_path}\")\n",
        "print(\"[NEXT] STEP 4 will cover preprocessing pipeline (resize/normalize) and identical augmentations.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYL96afWNERC",
        "outputId": "a4418b1e-1a44-4b41-d96f-539daa0d2d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved split ID lists:\n",
            "  • /content/drive/MyDrive/TransUNetBaseline_model_isic_Test/summary/busi_256_train_ids.txt\n",
            "  • /content/drive/MyDrive/TransUNetBaseline_model_isic_Test/summary/busi_256_val_ids.txt\n",
            "  • /content/drive/MyDrive/TransUNetBaseline_model_isic_Test/summary/busi_256_test_ids.txt\n",
            "[NEXT] STEP 4 will cover preprocessing pipeline (resize/normalize) and identical augmentations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS (IDENTICAL POLICY)\n",
        "# Cell 1/5 — Imports, constants, and NPZ reload\n",
        "# ------------------------------------------------------------\n",
        "import numpy as np, torch\n",
        "from pathlib import Path\n",
        "\n",
        "RESOLUTION = int(globals().get(\"RESOLUTION\", globals().get(\"SIZE\", 256)))\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", RESOLUTION))\n",
        "BATCH_SIZE = int(globals().get(\"BATCH_SIZE\", 8))\n",
        "\n",
        "NORM_MEAN = (0.485, 0.456, 0.406)\n",
        "NORM_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "msb_dir   = Path(os.environ.get(\"MEDSEGBENCH_DIR\", os.path.expanduser(\"~/.medsegbench\")))\n",
        "busi_file = msb_dir / f\"isic2016_{RESOLUTION}.npz\"\n",
        "assert busi_file.exists(), f\"Expected dataset file not found: {busi_file}\"\n",
        "\n",
        "npz_l = np.load(busi_file, allow_pickle=True)\n",
        "\n",
        "def _as_list(x):\n",
        "    if isinstance(x, np.ndarray): x = x.tolist()\n",
        "    return list(x) if isinstance(x, (list, tuple)) else [x]\n",
        "\n",
        "def _infer_splits(npz_obj):\n",
        "    k = set(npz_obj.keys())\n",
        "    def _find_lbl_key(split):\n",
        "        for suffix in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "            cand = f\"{split}_{suffix}\"\n",
        "            if cand in k: return cand\n",
        "        return None\n",
        "    have_all = True\n",
        "    meta = {}\n",
        "    for s in (\"train\",\"val\",\"test\"):\n",
        "        ik = f\"{s}_images\"; lk = _find_lbl_key(s)\n",
        "        if ik in k and lk in k:\n",
        "            n = len(npz_obj[ik])\n",
        "            if n != len(npz_obj[lk]): raise RuntimeError(f\"{s}: images != labels length\")\n",
        "            meta[s] = {\"n\": n, \"img_key\": ik, \"lbl_key\": lk}\n",
        "        else:\n",
        "            have_all = False; break\n",
        "    if have_all:\n",
        "        return {s: meta[s][\"n\"] for s in meta}, {s: list(range(meta[s][\"n\"])) for s in meta}\n",
        "    for tri, vai, tei in [(\"train_idx\",\"val_idx\",\"test_idx\"),\n",
        "                          (\"train_indices\",\"val_indices\",\"test_indices\"),\n",
        "                          (\"split_train\",\"split_val\",\"split_test\")]:\n",
        "        if tri in k and vai in k and tei in k:\n",
        "            tr = _as_list(npz_obj[tri]); va = _as_list(npz_obj[vai]); te = _as_list(npz_obj[tei])\n",
        "            return {\"train\": len(tr), \"val\": len(va), \"test\": len(te)}, {\"train\": tr, \"val\": va, \"test\": te}\n",
        "    raise RuntimeError(\"Could not re-infer splits; ensure STEP 3 ran successfully.\")\n",
        "\n",
        "if \"counts\" in globals() and \"split_idx\" in globals():\n",
        "    _counts, _split_idx = counts, split_idx\n",
        "else:\n",
        "    _counts, _split_idx = _infer_splits(npz_l)\n",
        "\n",
        "print(f\"[INFO] Using NPZ: {busi_file}\")\n",
        "print(f\"[INFO] Image size policy: RESOLUTION={RESOLUTION} → NETWORK INPUT={IMAGE_SIZE}\")\n",
        "print(f\"[COUNTS] train={_counts['train']}  val={_counts['val']}  test={_counts['test']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCUg-BK-NEKg",
        "outputId": "ec2c26b7-b037-4d66-877a-52fe00ca0baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using NPZ: /content/data/MedSegBenchCache/isic2016_256.npz\n",
            "[INFO] Image size policy: RESOLUTION=256 → NETWORK INPUT=256\n",
            "[COUNTS] train=810  val=90  test=379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 2/5 — Albumentations transforms (train/val/test)\n",
        "# ------------------------------------------------------------\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "resize_ops = []\n",
        "if IMAGE_SIZE != RESOLUTION:\n",
        "    resize_ops = [A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, interpolation=1)]  # 1=bilinear\n",
        "\n",
        "train_tf = A.Compose([\n",
        "    *resize_ops,\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.15, rotate_limit=15, border_mode=0, p=0.3),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.GaussianBlur(blur_limit=(3,5), p=0.15),\n",
        "    A.GaussNoise(var_limit=(5.0, 20.0), p=0.15),\n",
        "    A.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
        "    ToTensorV2(transpose_mask=True),\n",
        "])\n",
        "\n",
        "val_tf = A.Compose([\n",
        "    *resize_ops,\n",
        "    A.Normalize(mean=NORM_MEAN, std=NORM_STD),\n",
        "    ToTensorV2(transpose_mask=True),\n",
        "])\n",
        "\n",
        "test_tf = val_tf\n",
        "print(\"[OK] Transforms configured (train/val/test).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRltv3HENMhd",
        "outputId": "61f89bc1-bdf8-4662-c7a5-5e34133e0988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Transforms configured (train/val/test).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 3/5 — Dataset that memory-maps the NPZ (ISICNPZDataset-style)\n",
        "# ------------------------------------------------------------\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def _label_key_for(split, npz_obj_or_keys):\n",
        "    k = set(npz_obj_or_keys if isinstance(npz_obj_or_keys, (set,list,tuple)) else npz_obj_or_keys.keys())\n",
        "    for suf in (\"masks\",\"mask\",\"labels\",\"label\"):\n",
        "        cand = f\"{split}_{suf}\"\n",
        "        if cand in k: return cand\n",
        "    raise KeyError(f\"No label key found for split={split}.\")\n",
        "\n",
        "class ISICNPZDataset(Dataset):\n",
        "    def __init__(self, npz_path, split: str, indices, transform=None):\n",
        "        super().__init__()\n",
        "        self.path = str(npz_path)\n",
        "        _peek = np.load(self.path, allow_pickle=True, mmap_mode=\"r\")\n",
        "        self.img_key = f\"{split}_images\"\n",
        "        self.lbl_key = _label_key_for(split, _peek)\n",
        "        self.length = len(_peek[self.img_key])\n",
        "        assert self.length == len(_peek[self.lbl_key]), \"Images/labels length mismatch.\"\n",
        "        _peek.close()\n",
        "\n",
        "        self.split = split\n",
        "        self.indices = list(indices)\n",
        "        self.transform = transform\n",
        "        self._npz = None\n",
        "\n",
        "    def _ensure_open(self):\n",
        "        if self._npz is None:\n",
        "            self._npz = np.load(self.path, allow_pickle=True, mmap_mode=\"r\")\n",
        "\n",
        "    def __len__(self): return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        self._ensure_open()\n",
        "        i = self.indices[idx]\n",
        "        img = self._npz[self.img_key][i]  # HxW or HxWx3\n",
        "        msk = self._npz[self.lbl_key][i]  # HxW\n",
        "\n",
        "        if img.ndim == 2: img = np.stack([img, img, img], axis=-1)\n",
        "        if msk.max() > 1: msk = (msk > 127).astype(np.uint8)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            out = self.transform(image=img, mask=msk)\n",
        "            img_t = out[\"image\"]\n",
        "            msk_t = out[\"mask\"].unsqueeze(0) if out[\"mask\"].ndim == 2 else out[\"mask\"]\n",
        "        else:\n",
        "            img_f = img.astype(np.float32) / 255.0\n",
        "            img_f = (img_f - np.array(NORM_MEAN)) / np.array(NORM_STD)\n",
        "            img_t = torch.from_numpy(img_f).permute(2,0,1).contiguous()\n",
        "            msk_t = torch.from_numpy(msk.astype(np.float32)).unsqueeze(0)\n",
        "\n",
        "        return img_t, msk_t\n",
        "\n",
        "    def __del__(self):\n",
        "        try:\n",
        "            if self._npz is not None: self._npz.close()\n",
        "        except Exception: pass\n"
      ],
      "metadata": {
        "id": "hDWGycNJNMej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 4/5 — DataLoaders with safe settings\n",
        "# ------------------------------------------------------------\n",
        "from torch.utils.data import DataLoader\n",
        "import torch, os\n",
        "\n",
        "train_ds = ISICNPZDataset(busi_file, \"train\", _split_idx[\"train\"], transform=train_tf)\n",
        "val_ds   = ISICNPZDataset(busi_file, \"val\",   _split_idx[\"val\"],   transform=val_tf)\n",
        "test_ds  = ISICNPZDataset(busi_file, \"test\",  _split_idx[\"test\"],  transform=test_tf)\n",
        "\n",
        "num_workers = 2\n",
        "pin = torch.cuda.is_available()\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=True, prefetch_factor=2, persistent_workers=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=False, prefetch_factor=2, persistent_workers=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=1, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin,\n",
        "                          drop_last=False, prefetch_factor=2, persistent_workers=True)\n",
        "\n",
        "xb, yb = next(iter(train_loader))\n",
        "print(f\"[OK] Train batch shapes: images={tuple(xb.shape)} masks={tuple(yb.shape)}\")\n",
        "print(f\"[INFO] num_workers={num_workers}, pin_memory={pin}, batch_size={BATCH_SIZE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JikBr2VLNMb4",
        "outputId": "5333de9d-b5b4-4a87-df68-105589ad79ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Train batch shapes: images=(8, 3, 256, 256) masks=(8, 1, 256, 256)\n",
            "[INFO] num_workers=2, pin_memory=False, batch_size=8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 4 — PREPROCESSING & AUGMENTATIONS\n",
        "# Cell 5/5 — Policy echo (for the paper/log)\n",
        "# ------------------------------------------------------------\n",
        "print(\"[POLICY] Preprocessing/Normalization\")\n",
        "print(f\"  • Resize to: {IMAGE_SIZE}x{IMAGE_SIZE} (if different from NPZ {RESOLUTION})\")\n",
        "print(f\"  • Normalize (ImageNet): mean={NORM_MEAN}, std={NORM_STD}\")\n",
        "print(\"[POLICY] Train augmentations\")\n",
        "print(\"  • HorizontalFlip p=0.5\")\n",
        "print(\"  • ShiftScaleRotate (±2% shift, ±15% scale, ±15° rotate) p=0.3\")\n",
        "print(\"  • Brightness/Contrast p=0.3\")\n",
        "print(\"  • GaussianBlur p=0.15, GaussNoise p=0.15\")\n",
        "print(\"[POLICY] Val/Test: no augmentations (only resize + normalize)\")\n",
        "print(\"[READY] DataLoaders prepared. Next: STEP 5 (Data sanity visuals).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu6Q26YTNMY6",
        "outputId": "68fd7f5f-8bd7-4c0c-c6ed-89810def82a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[POLICY] Preprocessing/Normalization\n",
            "  • Resize to: 256x256 (if different from NPZ 256)\n",
            "  • Normalize (ImageNet): mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
            "[POLICY] Train augmentations\n",
            "  • HorizontalFlip p=0.5\n",
            "  • ShiftScaleRotate (±2% shift, ±15% scale, ±15° rotate) p=0.3\n",
            "  • Brightness/Contrast p=0.3\n",
            "  • GaussianBlur p=0.15, GaussNoise p=0.15\n",
            "[POLICY] Val/Test: no augmentations (only resize + normalize)\n",
            "[READY] DataLoaders prepared. Next: STEP 5 (Data sanity visuals).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3RqUb60LNMWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# Cell 1/4\n",
        "# ------------------------------------------------------------\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "if \"ConvBNReLU\" not in globals():\n",
        "    class ConvBNReLU(nn.Module):\n",
        "        def __init__(self, in_ch, out_ch, k=3, s=1, p=1):\n",
        "            super().__init__()\n",
        "            self.conv = nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)\n",
        "            self.bn   = nn.BatchNorm2d(out_ch)\n",
        "            self.act  = nn.ReLU(inplace=True)\n",
        "        def forward(self, x): return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class SETR_PUP(nn.Module):\n",
        "    \"\"\"\n",
        "    Paper-style SETR (Zheng et al.): pure ViT encoder + Progressive UPsampling (PUP) decoder.\n",
        "      • ViT-B/16 pretrained → tokens @ 1/16 grid (C=768).\n",
        "      • PUP: a stack of conv+upsample stages to reach H×W without CNN encoder skips.\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=256, embed_dim=768):\n",
        "        super().__init__()\n",
        "        self.vit = timm.create_model(\"vit_base_patch16_224\", pretrained=True,\n",
        "                                     num_classes=0, global_pool=\"\", img_size=img_size)\n",
        "        self.embed_dim = getattr(self.vit, \"num_features\", embed_dim)\n",
        "        self.patch = 16\n",
        "\n",
        "        # PUP decoder (progressive upsampling)\n",
        "        self.dec16 = ConvBNReLU(self.embed_dim, 512, 3, 1, 1)   # H/16\n",
        "        self.dec8  = ConvBNReLU(512, 256, 3, 1, 1)              # H/8\n",
        "        self.dec4  = ConvBNReLU(256, 128, 3, 1, 1)              # H/4\n",
        "        self.dec2  = ConvBNReLU(128,  64, 3, 1, 1)              # H/2\n",
        "        self.head  = nn.Conv2d(64, 1, 1)\n",
        "\n",
        "    def _tokens_to_map(self, feats, H, W):\n",
        "        if feats.size(1) == (H//self.patch)*(W//self.patch) + 1:\n",
        "            feats = feats[:, 1:, :]\n",
        "        B, N, C = feats.shape\n",
        "        gh, gw = H//self.patch, W//self.patch\n",
        "        return feats.transpose(1, 2).contiguous().view(B, C, gh, gw)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, _, H, W = x.shape\n",
        "        feats = self.vit.forward_features(x)           # (B, 1+N, 768)\n",
        "        f16  = self._tokens_to_map(feats, H, W)        # (B,768,H/16,W/16)\n",
        "\n",
        "        y = self.dec16(f16)                            # H/16\n",
        "        y = F.interpolate(y, scale_factor=2, mode=\"bilinear\", align_corners=False)  # → H/8\n",
        "        y = self.dec8(y)\n",
        "        y = F.interpolate(y, scale_factor=2, mode=\"bilinear\", align_corners=False)  # → H/4\n",
        "        y = self.dec4(y)\n",
        "        y = F.interpolate(y, scale_factor=2, mode=\"bilinear\", align_corners=False)  # → H/2\n",
        "        y = self.dec2(y)\n",
        "        y = F.interpolate(y, scale_factor=2, mode=\"bilinear\", align_corners=False)  # → H\n",
        "        logits = self.head(y)\n",
        "        return {\"logits\": logits}\n",
        "\n"
      ],
      "metadata": {
        "id": "tldnF90ENMTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# Cell 2/4 — CPU fairness + CKPT path + preload 50 RAW test samples\n",
        "# (SAFE: avoid set_num_interop_threads error if threads already started)\n",
        "# ------------------------------------------------------------\n",
        "import os, psutil, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# ---- CPU fairness (as requested) ----\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"MKL_NUM_THREADS\"]  = \"1\"\n",
        "\n",
        "import torch\n",
        "\n",
        "# Always safe at runtime:\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "# set_num_interop_threads must be called before any parallel work; try, else continue.\n",
        "try:\n",
        "    if hasattr(torch, \"set_num_interop_threads\"):\n",
        "        torch.set_num_interop_threads(1)\n",
        "except RuntimeError as e:\n",
        "    # Already started parallel work; keep current interop setting but log it.\n",
        "    print(f\"[WARN] {e} — continuing with interop_threads={getattr(torch, 'get_num_interop_threads', lambda: 'N/A')()}\")\n",
        "\n",
        "DEVICE = \"cpu\"\n",
        "print(f\"[CPU] threads={torch.get_num_threads()} \"\n",
        "      f\"interop={getattr(torch, 'get_num_interop_threads', lambda: 'N/A')()} \"\n",
        "      f\"OMP={os.getenv('OMP_NUM_THREADS')} MKL={os.getenv('MKL_NUM_THREADS')}\")\n",
        "\n",
        "# ---- threshold from cfg (fallback 0.5) ----\n",
        "THRESH = float(cfg.get(\"metrics\", {}).get(\"threshold\", 0.5)) if \"cfg\" in globals() else 0.5\n",
        "print(f\"[INFO] THRESH={THRESH}\")\n",
        "\n",
        "# ---- your exact trained checkpoint path ----\n",
        "from pathlib import Path\n",
        "CKPT_PATH = \"/content/drive/MyDrive/setr_modelBaseline/checkpoints/setr_model_ISIC2016_IMG256_SEED42_2025-11-01_10-32-35_best.pt\"  # <<< EDIT THIS\n",
        "if not Path(CKPT_PATH).exists():\n",
        "    raise FileNotFoundError(f\"Checkpoint not found: {CKPT_PATH}\")\n",
        "\n",
        "# ---- build a 50-sample test index (first 50 of split) ----\n",
        "NUM_SAMPLES = 50\n",
        "WARMUP = 5\n",
        "test_ids = split_idx[\"test\"]\n",
        "if len(test_ids) < NUM_SAMPLES:\n",
        "    raise ValueError(f\"Test set has {len(test_ids)} samples; need at least {NUM_SAMPLES}.\")\n",
        "sel_ids = test_ids[:NUM_SAMPLES]\n",
        "\n",
        "# ---- preload RAW arrays (avoid disk I/O in timing) ----\n",
        "# Note: transforms/tensorization are INSIDE timing for end-to-end latency.\n",
        "test_img_key = \"test_images\"\n",
        "for lblk in (\"test_masks\",\"test_mask\",\"test_labels\",\"test_label\"):\n",
        "    if lblk in npz: test_lbl_key = lblk; break\n",
        "else:\n",
        "    raise KeyError(\"No test label key among {test_masks, test_mask, test_labels, test_label}.\")\n",
        "\n",
        "raw_samples = []\n",
        "for i in sel_ids:\n",
        "    img = npz[test_img_key][i]\n",
        "    msk = npz[test_lbl_key][i]\n",
        "    raw_samples.append((img, msk))\n",
        "print(f\"[OK] Preloaded RAW {len(raw_samples)} test samples into RAM.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlF04X77Nl7Y",
        "outputId": "74a52932-0778-449c-e0e8-415acc06de45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CPU] threads=1 interop=1 OMP=1 MKL=1\n",
            "[INFO] THRESH=0.5\n",
            "[OK] Preloaded RAW 50 test samples into RAM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e33Z3DrlT-IB",
        "outputId": "735f31ee-ed63-4d3c-ba6d-735534fa1077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVAL\n",
        "# Cell 3/4 (REPLACED) — Instantiate model + CLEAN LOAD (CPU)\n",
        "# ------------------------------------------------------------\n",
        "from pathlib import Path\n",
        "import re, torch\n",
        "\n",
        "IMAGE_SIZE = int(globals().get(\"IMAGE_SIZE\", 256))\n",
        "model = SETR_PUP(img_size=IMAGE_SIZE, embed_dim=768).to(\"cpu\")\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "\n",
        "def unwrap_state(d):\n",
        "    # common wrappers\n",
        "    for k in [\"model_state\",\"state_dict\",\"model\",\"net\",\"ema\",\"model_state_dict\"]:\n",
        "        if isinstance(d, dict) and k in d and isinstance(d[k], dict):\n",
        "            return d[k]\n",
        "    return d if isinstance(d, dict) else {}\n",
        "\n",
        "raw = unwrap_state(ckpt)\n",
        "\n",
        "# 1) strip 'module.' prefix\n",
        "clean = {}\n",
        "for k, v in raw.items():\n",
        "    nk = k[7:] if k.startswith(\"module.\") else k\n",
        "    clean[nk] = v\n",
        "\n",
        "# 2) drop profiling buffers (from thop/fvcore)\n",
        "def is_profile_key(k: str) -> bool:\n",
        "    return k.endswith(\".total_ops\") or k.endswith(\".total_params\")\n",
        "clean = {k:v for k,v in clean.items() if not is_profile_key(k)}\n",
        "\n",
        "# 3) optional prefix remaps (adapt if your training used different names)\n",
        "#    e.g., 'backbone.' -> 'vit.' , 'encoder.' -> 'vit.' , 'transformer.' -> 'vit.'\n",
        "remaps = [\n",
        "    (r\"^backbone\\.\", \"vit.\"),\n",
        "    (r\"^encoder\\.\",  \"vit.\"),\n",
        "    (r\"^transformer\\.\", \"vit.\"),\n",
        "]\n",
        "remapped = {}\n",
        "for k, v in clean.items():\n",
        "    nk = k\n",
        "    for pat, rep in remaps:\n",
        "        nk = re.sub(pat, rep, nk)\n",
        "    remapped[nk] = v\n",
        "clean = remapped\n",
        "\n",
        "# 4) keep only keys that exist in current model (exact-name intersection)\n",
        "model_sd = model.state_dict()\n",
        "intersect = {k:v for k,v in clean.items() if k in model_sd and v.shape == model_sd[k].shape}\n",
        "\n",
        "# 5) report coverage\n",
        "print(f\"[CKPT] total keys in state: {len(raw)}\")\n",
        "print(f\"[CKPT] after strip+drop:     {len(clean)}\")\n",
        "print(f\"[CKPT] intersect (name+shape): {len(intersect)} / model expects {len(model_sd)}\")\n",
        "\n",
        "# 6) load intersect only (others remain as initialized / DeiT pretrained)\n",
        "missing_before = set(model_sd.keys()) - set(intersect.keys())\n",
        "load_res = model_sd.copy()\n",
        "load_res.update(intersect)\n",
        "model.load_state_dict(load_res, strict=False)\n",
        "\n",
        "# sanity: print what we still miss (first 40)\n",
        "still_missing = list(set(model.state_dict().keys()) - set(intersect.keys()))\n",
        "print(f\"[LOAD] missing (after clean) ~ {len(still_missing)} (showing up to 40)\")\n",
        "print(still_missing[:40])\n",
        "\n",
        "model.eval()\n",
        "print(\"[OK] Cleaned checkpoint loaded into model on CPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "41e52467b19941c3b450aa291c6eedb0",
            "3c68c5b21ee5494a8a555cb9bb822e88",
            "7c41d6453e5c4ac3a3601c2e13d925ac",
            "0b1dc3a1f3cb4494be90cdf435a078f2",
            "03a42c47dfdc45d68c27b9a494ce1de9",
            "e5077cc921784fdb8dcf4821b6dfafd6",
            "e149254f3172448c964236ed87af318a",
            "cfe7987786fe430e849af3bc0882c188",
            "e32f690bd7814ea091f864c067b6a2bd",
            "0b7c8c652cfb4d41b8bf9b79e196bf79",
            "f8e6491fa82a44429df1623f59048054"
          ]
        },
        "id": "zp39FVeBePV5",
        "outputId": "a3f51324-13f5-47c1-98b3-5e29e21fdaf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41e52467b19941c3b450aa291c6eedb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CKPT] total keys in state: 538\n",
            "[CKPT] after strip+drop:     178\n",
            "[CKPT] intersect (name+shape): 176 / model expects 176\n",
            "[LOAD] missing (after clean) ~ 0 (showing up to 40)\n",
            "[]\n",
            "[OK] Cleaned checkpoint loaded into model on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torch, re\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "\n",
        "def _unwrap_state(d):\n",
        "    # try common containers\n",
        "    for k in [\"state_dict\",\"model\",\"net\",\"ema\",\"model_state\"]:\n",
        "        if isinstance(d, dict) and k in d and isinstance(d[k], dict):\n",
        "            return d[k]\n",
        "    return d if isinstance(d, dict) else {}\n",
        "\n",
        "raw_state = _unwrap_state(ckpt)\n",
        "\n",
        "print(f\"[CKPT] top-level keys: {list(ckpt.keys())[:20]}\")\n",
        "print(f\"[CKPT] state len: {len(raw_state)}\")\n",
        "\n",
        "# Show a few parameter names to identify architecture/backbone\n",
        "sample_keys = list(raw_state.keys())[:40]\n",
        "print(\"[CKPT] sample param keys:\")\n",
        "for k in sample_keys:\n",
        "    print(\"  \", k)\n",
        "\n",
        "# Also show model keys to compare\n",
        "model_keys = list(model.state_dict().keys())\n",
        "print(f\"[MODEL] expects {len(model_keys)} tensors\")\n",
        "print(\"[MODEL] sample expected keys:\")\n",
        "for k in model_keys[:40]:\n",
        "    print(\"  \", k)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG20hJl3dpAi",
        "outputId": "016e8e94-abe8-40c5-9307-8fa88d217804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CKPT] top-level keys: ['epoch', 'model_state', 'optimizer_state', 'val_dice', 'val_loss', 'cfg']\n",
            "[CKPT] state len: 538\n",
            "[CKPT] sample param keys:\n",
            "   total_ops\n",
            "   total_params\n",
            "   vit.cls_token\n",
            "   vit.pos_embed\n",
            "   vit.total_ops\n",
            "   vit.total_params\n",
            "   vit.patch_embed.total_ops\n",
            "   vit.patch_embed.total_params\n",
            "   vit.patch_embed.proj.weight\n",
            "   vit.patch_embed.proj.bias\n",
            "   vit.patch_embed.norm.total_ops\n",
            "   vit.patch_embed.norm.total_params\n",
            "   vit.patch_drop.total_ops\n",
            "   vit.patch_drop.total_params\n",
            "   vit.norm_pre.total_ops\n",
            "   vit.norm_pre.total_params\n",
            "   vit.blocks.0.total_ops\n",
            "   vit.blocks.0.total_params\n",
            "   vit.blocks.0.norm1.weight\n",
            "   vit.blocks.0.norm1.bias\n",
            "   vit.blocks.0.norm1.total_ops\n",
            "   vit.blocks.0.norm1.total_params\n",
            "   vit.blocks.0.attn.total_ops\n",
            "   vit.blocks.0.attn.total_params\n",
            "   vit.blocks.0.attn.qkv.weight\n",
            "   vit.blocks.0.attn.qkv.bias\n",
            "   vit.blocks.0.attn.q_norm.total_ops\n",
            "   vit.blocks.0.attn.q_norm.total_params\n",
            "   vit.blocks.0.attn.k_norm.total_ops\n",
            "   vit.blocks.0.attn.k_norm.total_params\n",
            "   vit.blocks.0.attn.norm.total_ops\n",
            "   vit.blocks.0.attn.norm.total_params\n",
            "   vit.blocks.0.attn.proj.weight\n",
            "   vit.blocks.0.attn.proj.bias\n",
            "   vit.blocks.0.ls1.total_ops\n",
            "   vit.blocks.0.ls1.total_params\n",
            "   vit.blocks.0.drop_path1.total_ops\n",
            "   vit.blocks.0.drop_path1.total_params\n",
            "   vit.blocks.0.norm2.weight\n",
            "   vit.blocks.0.norm2.bias\n",
            "[MODEL] expects 176 tensors\n",
            "[MODEL] sample expected keys:\n",
            "   vit.cls_token\n",
            "   vit.pos_embed\n",
            "   vit.patch_embed.proj.weight\n",
            "   vit.patch_embed.proj.bias\n",
            "   vit.blocks.0.norm1.weight\n",
            "   vit.blocks.0.norm1.bias\n",
            "   vit.blocks.0.attn.qkv.weight\n",
            "   vit.blocks.0.attn.qkv.bias\n",
            "   vit.blocks.0.attn.proj.weight\n",
            "   vit.blocks.0.attn.proj.bias\n",
            "   vit.blocks.0.norm2.weight\n",
            "   vit.blocks.0.norm2.bias\n",
            "   vit.blocks.0.mlp.fc1.weight\n",
            "   vit.blocks.0.mlp.fc1.bias\n",
            "   vit.blocks.0.mlp.fc2.weight\n",
            "   vit.blocks.0.mlp.fc2.bias\n",
            "   vit.blocks.1.norm1.weight\n",
            "   vit.blocks.1.norm1.bias\n",
            "   vit.blocks.1.attn.qkv.weight\n",
            "   vit.blocks.1.attn.qkv.bias\n",
            "   vit.blocks.1.attn.proj.weight\n",
            "   vit.blocks.1.attn.proj.bias\n",
            "   vit.blocks.1.norm2.weight\n",
            "   vit.blocks.1.norm2.bias\n",
            "   vit.blocks.1.mlp.fc1.weight\n",
            "   vit.blocks.1.mlp.fc1.bias\n",
            "   vit.blocks.1.mlp.fc2.weight\n",
            "   vit.blocks.1.mlp.fc2.bias\n",
            "   vit.blocks.2.norm1.weight\n",
            "   vit.blocks.2.norm1.bias\n",
            "   vit.blocks.2.attn.qkv.weight\n",
            "   vit.blocks.2.attn.qkv.bias\n",
            "   vit.blocks.2.attn.proj.weight\n",
            "   vit.blocks.2.attn.proj.bias\n",
            "   vit.blocks.2.norm2.weight\n",
            "   vit.blocks.2.norm2.bias\n",
            "   vit.blocks.2.mlp.fc1.weight\n",
            "   vit.blocks.2.mlp.fc1.bias\n",
            "   vit.blocks.2.mlp.fc2.weight\n",
            "   vit.blocks.2.mlp.fc2.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing, unexpected = model.load_state_dict(raw_state, strict=False)\n",
        "print(f\"[DIFF] missing ({len(missing)}):\")\n",
        "print(missing[:50])\n",
        "print(f\"[DIFF] unexpected ({len(unexpected)}):\")\n",
        "print(unexpected[:50])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuEkE7Rzd2HR",
        "outputId": "83fec9e6-8b36-4c68-d048-7ed87e7f849d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DIFF] missing (0):\n",
            "[]\n",
            "[DIFF] unexpected (362):\n",
            "['total_ops', 'total_params', 'vit.total_ops', 'vit.total_params', 'vit.patch_embed.total_ops', 'vit.patch_embed.total_params', 'vit.patch_embed.norm.total_ops', 'vit.patch_embed.norm.total_params', 'vit.patch_drop.total_ops', 'vit.patch_drop.total_params', 'vit.norm_pre.total_ops', 'vit.norm_pre.total_params', 'vit.blocks.0.total_ops', 'vit.blocks.0.total_params', 'vit.blocks.0.norm1.total_ops', 'vit.blocks.0.norm1.total_params', 'vit.blocks.0.attn.total_ops', 'vit.blocks.0.attn.total_params', 'vit.blocks.0.attn.q_norm.total_ops', 'vit.blocks.0.attn.q_norm.total_params', 'vit.blocks.0.attn.k_norm.total_ops', 'vit.blocks.0.attn.k_norm.total_params', 'vit.blocks.0.attn.norm.total_ops', 'vit.blocks.0.attn.norm.total_params', 'vit.blocks.0.ls1.total_ops', 'vit.blocks.0.ls1.total_params', 'vit.blocks.0.drop_path1.total_ops', 'vit.blocks.0.drop_path1.total_params', 'vit.blocks.0.norm2.total_ops', 'vit.blocks.0.norm2.total_params', 'vit.blocks.0.mlp.total_ops', 'vit.blocks.0.mlp.total_params', 'vit.blocks.0.mlp.act.total_ops', 'vit.blocks.0.mlp.act.total_params', 'vit.blocks.0.mlp.norm.total_ops', 'vit.blocks.0.mlp.norm.total_params', 'vit.blocks.0.ls2.total_ops', 'vit.blocks.0.ls2.total_params', 'vit.blocks.0.drop_path2.total_ops', 'vit.blocks.0.drop_path2.total_params', 'vit.blocks.1.total_ops', 'vit.blocks.1.total_params', 'vit.blocks.1.norm1.total_ops', 'vit.blocks.1.norm1.total_params', 'vit.blocks.1.attn.total_ops', 'vit.blocks.1.attn.total_params', 'vit.blocks.1.attn.q_norm.total_ops', 'vit.blocks.1.attn.q_norm.total_params', 'vit.blocks.1.attn.k_norm.total_ops', 'vit.blocks.1.attn.k_norm.total_params']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6 — CPU EVALUATION\n",
        "# Cell 4/4 — Warm-up, timed run, metrics, save CSV+JSON\n",
        "# (FIX: added `import math`)\n",
        "# ------------------------------------------------------------\n",
        "import time, numpy as np, math, json, os, psutil, pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- helpers ----\n",
        "def apply_test_transform(img, msk):\n",
        "    # Ensure 3-ch image & binary mask; then apply test_tf (resize+norm+tensor)\n",
        "    if img.ndim == 2: img = np.stack([img, img, img], axis=-1)\n",
        "    if msk.max() > 1: msk = (msk > 127).astype(np.uint8)\n",
        "    out = test_tf(image=img, mask=msk)  # includes resize+normalize\n",
        "    x = out[\"image\"]                           # [C,H,W] float32\n",
        "    y = out[\"mask\"].unsqueeze(0) if out[\"mask\"].ndim==2 else out[\"mask\"]  # [1,H,W]\n",
        "    return x, y\n",
        "\n",
        "def binarize(prob, thr): return (prob >= thr).astype(np.uint8)\n",
        "\n",
        "def dice_iou(pred, mask, eps=1e-7):\n",
        "    inter = (pred & mask).sum()\n",
        "    union = (pred | mask).sum()\n",
        "    dice = (2*inter + eps) / (pred.sum() + mask.sum() + eps)\n",
        "    iou  = (inter + eps) / (union + eps)\n",
        "    return float(dice), float(iou)\n",
        "\n",
        "# ---- warm-up (excluded) ----\n",
        "with torch.no_grad():\n",
        "    for i in range(WARMUP):\n",
        "        img, msk = raw_samples[i]\n",
        "        x, y = apply_test_transform(img, msk)\n",
        "        _ = model(x.unsqueeze(0))\n",
        "\n",
        "# ---- timed run ----\n",
        "lat_ms, dices, ious = [], [], []\n",
        "cpu_hist, ram_hist  = [], []\n",
        "proc = psutil.Process(os.getpid())\n",
        "t_start = time.perf_counter()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(WARMUP, NUM_SAMPLES):\n",
        "        img, msk = raw_samples[i]\n",
        "\n",
        "        t0 = time.perf_counter()\n",
        "        x, y = apply_test_transform(img, msk)       # include resize+normalize in timing\n",
        "        out = model(x.unsqueeze(0))                 # forward\n",
        "        logits = out[\"logits\"] if isinstance(out, dict) and \"logits\" in out else out\n",
        "        prob = torch.sigmoid(logits).cpu().numpy().squeeze()\n",
        "        pred = binarize(prob, THRESH)\n",
        "        gt   = (y.squeeze().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        d, j = dice_iou(pred, gt)\n",
        "        t1 = time.perf_counter()\n",
        "\n",
        "        dices.append(d); ious.append(j)\n",
        "        lat_ms.append((t1 - t0) * 1000.0)\n",
        "        cpu_hist.append(psutil.cpu_percent(interval=None))\n",
        "        ram_hist.append(proc.memory_info().rss)\n",
        "\n",
        "t_end = time.perf_counter()\n",
        "\n",
        "# ---- summary ----\n",
        "def pct(vals, p):\n",
        "    if not vals: return float('nan')\n",
        "    a = sorted(vals)\n",
        "    k = (len(a)-1)*(p/100.0)\n",
        "    f,c = math.floor(k), math.ceil(k)\n",
        "    return a[int(k)] if f==c else a[f]*(c-k)+a[c]*(k-f)\n",
        "\n",
        "n = len(lat_ms)\n",
        "fps = (NUM_SAMPLES - WARMUP) / (t_end - t_start) if (t_end - t_start) > 0 else float('nan')\n",
        "summary = dict(\n",
        "    dice_mean=float(np.mean(dices)) if dices else float('nan'),\n",
        "    iou_mean=float(np.mean(ious)) if ious else float('nan'),\n",
        "    lat_median_ms=float(np.median(lat_ms)) if n else float('nan'),\n",
        "    lat_p90_ms=float(pct(lat_ms, 90)),\n",
        "    lat_p95_ms=float(pct(lat_ms, 95)),\n",
        "    lat_min_ms=float(np.min(lat_ms)) if n else float('nan'),\n",
        "    lat_max_ms=float(np.max(lat_ms)) if n else float('nan'),\n",
        "    wall_time_s=float(t_end - t_start),\n",
        "    fps=float(fps),\n",
        "    peak_ram_mb=float(max(ram_hist)/(1024*1024)) if ram_hist else float('nan'),\n",
        "    cpu_mean_pct=float(np.mean(cpu_hist)) if cpu_hist else float('nan'),\n",
        "    threshold=float(THRESH),\n",
        "    samples=int(NUM_SAMPLES - WARMUP),\n",
        "    threads=dict(\n",
        "        torch_num_threads=torch.get_num_threads(),\n",
        "        torch_num_interop=torch.get_num_interop_threads() if hasattr(torch, \"get_num_interop_threads\") else \"N/A\",\n",
        "        OMP_NUM_THREADS=os.getenv(\"OMP_NUM_THREADS\"),\n",
        "        MKL_NUM_THREADS=os.getenv(\"MKL_NUM_THREADS\"),\n",
        "    ),\n",
        "    ckpt=CKPT_PATH,\n",
        "    data=str(busi_file),\n",
        ")\n",
        "\n",
        "print(json.dumps(summary, indent=2))\n",
        "\n",
        "# ---- save artifacts ----\n",
        "outdir = Path(\"./cpu_eval_runs\"); outdir.mkdir(exist_ok=True, parents=True)\n",
        "stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "pd.DataFrame({\"idx\": list(range(n)), \"latency_ms\": lat_ms, \"dice\": dices, \"iou\": ious}).to_csv(outdir / f\"per_image_{stamp}.csv\", index=False)\n",
        "with open(outdir / f\"summary_{stamp}.json\",\"w\") as f: json.dump(summary, f, indent=2)\n",
        "print(\"Saved:\", outdir / f\"per_image_{stamp}.csv\", \"|\", outdir / f\"summary_{stamp}.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02TjETcyOl36",
        "outputId": "da034314-d966-48a5-ce5b-1ecc64af59fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"dice_mean\": 0.9223769621688679,\n",
            "  \"iou_mean\": 0.8635375714210766,\n",
            "  \"lat_median_ms\": 769.1182849999905,\n",
            "  \"lat_p90_ms\": 912.6574345999871,\n",
            "  \"lat_p95_ms\": 945.1890777999779,\n",
            "  \"lat_min_ms\": 717.7869079999937,\n",
            "  \"lat_max_ms\": 992.3258580000152,\n",
            "  \"wall_time_s\": 35.71234448299998,\n",
            "  \"fps\": 1.2600684903625183,\n",
            "  \"peak_ram_mb\": 4488.02734375,\n",
            "  \"cpu_mean_pct\": 59.59555555555554,\n",
            "  \"threshold\": 0.5,\n",
            "  \"samples\": 45,\n",
            "  \"threads\": {\n",
            "    \"torch_num_threads\": 1,\n",
            "    \"torch_num_interop\": 1,\n",
            "    \"OMP_NUM_THREADS\": \"1\",\n",
            "    \"MKL_NUM_THREADS\": \"1\"\n",
            "  },\n",
            "  \"ckpt\": \"/content/drive/MyDrive/setr_modelBaseline/checkpoints/setr_model_ISIC2016_IMG256_SEED42_2025-11-01_10-32-35_best.pt\",\n",
            "  \"data\": \"/content/data/MedSegBenchCache/isic2016_256.npz\"\n",
            "}\n",
            "Saved: cpu_eval_runs/per_image_20251108_133835.csv | cpu_eval_runs/summary_20251108_133835.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd; from pathlib import Path\n",
        "p = sorted(Path(\"cpu_eval_runs\").glob(\"per_image_*.csv\"))[-1]\n",
        "df = pd.read_csv(p)\n",
        "print(df.describe(percentiles=[.5,.9,.95]))\n",
        "print(\"Top 5 slowest:\\n\", df.sort_values(\"latency_ms\", ascending=False).head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAw3zscae5q3",
        "outputId": "53124a47-a644-4e7c-b3e7-3b744efa71e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             idx  latency_ms       dice        iou\n",
            "count  45.000000   45.000000  45.000000  45.000000\n",
            "mean   22.000000  793.378917   0.922377   0.863538\n",
            "std    13.133926   70.467757   0.076306   0.110441\n",
            "min     0.000000  717.786908   0.562718   0.391516\n",
            "50%    22.000000  769.118285   0.946644   0.898694\n",
            "90%    39.600000  912.657435   0.973606   0.948571\n",
            "95%    41.800000  945.189078   0.976091   0.953300\n",
            "max    44.000000  992.325858   0.983775   0.968068\n",
            "Top 5 slowest:\n",
            "     idx  latency_ms      dice       iou\n",
            "5     5  992.325858  0.885903  0.795176\n",
            "20   20  963.094084  0.902442  0.822227\n",
            "36   36  945.717776  0.968562  0.939041\n",
            "21   21  943.074285  0.926141  0.862442\n",
            "35   35  940.777575  0.958511  0.920328\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41e52467b19941c3b450aa291c6eedb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c68c5b21ee5494a8a555cb9bb822e88",
              "IPY_MODEL_7c41d6453e5c4ac3a3601c2e13d925ac",
              "IPY_MODEL_0b1dc3a1f3cb4494be90cdf435a078f2"
            ],
            "layout": "IPY_MODEL_03a42c47dfdc45d68c27b9a494ce1de9"
          }
        },
        "3c68c5b21ee5494a8a555cb9bb822e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5077cc921784fdb8dcf4821b6dfafd6",
            "placeholder": "​",
            "style": "IPY_MODEL_e149254f3172448c964236ed87af318a",
            "value": "model.safetensors: 100%"
          }
        },
        "7c41d6453e5c4ac3a3601c2e13d925ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfe7987786fe430e849af3bc0882c188",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e32f690bd7814ea091f864c067b6a2bd",
            "value": 346284714
          }
        },
        "0b1dc3a1f3cb4494be90cdf435a078f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b7c8c652cfb4d41b8bf9b79e196bf79",
            "placeholder": "​",
            "style": "IPY_MODEL_f8e6491fa82a44429df1623f59048054",
            "value": " 346M/346M [00:04&lt;00:00, 168MB/s]"
          }
        },
        "03a42c47dfdc45d68c27b9a494ce1de9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5077cc921784fdb8dcf4821b6dfafd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e149254f3172448c964236ed87af318a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfe7987786fe430e849af3bc0882c188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32f690bd7814ea091f864c067b6a2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b7c8c652cfb4d41b8bf9b79e196bf79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8e6491fa82a44429df1623f59048054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}